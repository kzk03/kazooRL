#!/usr/bin/env python3
"""
æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰
clickã‚’ä½¿ã‚ãšã«æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã¿ã§å®Ÿè£…
"""

import argparse
import json
import os
import shutil
from datetime import datetime
from typing import Dict, List

import yaml


def load_backlog_data(filepath: str) -> List[Dict]:
    """ãƒãƒƒã‚¯ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    print(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {filepath}")
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    print(f"   ç·ã‚¿ã‚¹ã‚¯æ•°: {len(data):,}")
    return data


def split_data_by_year(data: List[Dict]) -> Dict[str, List[Dict]]:
    """å¹´åˆ¥ã«ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²"""
    print("ğŸ“… å¹´åˆ¥ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ä¸­...")
    
    year_data = {
        '2019': [],
        '2020': [],
        '2021': [],
        '2022': [],
        '2023': []
    }
    
    for task in data:
        created_at = task.get('created_at', '')
        if created_at:
            year = created_at[:4]
            if year in year_data:
                year_data[year].append(task)
    
    # çµ±è¨ˆè¡¨ç¤º
    print("   å¹´åˆ¥ã‚¿ã‚¹ã‚¯æ•°:")
    for year, tasks in year_data.items():
        print(f"     {year}å¹´: {len(tasks):,}ã‚¿ã‚¹ã‚¯")
    
    return year_data


def create_split_datasets(year_data: Dict[str, List[Dict]], output_dir: str):
    """åˆ†å‰²ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ"""
    print(f"ğŸ“¦ åˆ†å‰²ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆä¸­... (å‡ºåŠ›å…ˆ: {output_dir})")
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    os.makedirs(output_dir, exist_ok=True)
    
    # 1. IRLç”¨ãƒ‡ãƒ¼ã‚¿ (2019-2021å¹´)
    irl_data = []
    for year in ['2019', '2020', '2021']:
        irl_data.extend(year_data[year])
    
    irl_path = os.path.join(output_dir, 'backlog_irl_2019_2021.json')
    with open(irl_path, 'w', encoding='utf-8') as f:
        json.dump(irl_data, f, ensure_ascii=False, indent=2)
    print(f"   âœ… IRLç”¨ãƒ‡ãƒ¼ã‚¿: {len(irl_data):,}ã‚¿ã‚¹ã‚¯ -> {irl_path}")
    
    # 2. RLè¨“ç·´ç”¨ãƒ‡ãƒ¼ã‚¿ (2022å¹´)
    rl_data = year_data['2022']
    rl_path = os.path.join(output_dir, 'backlog_training_2022.json')
    with open(rl_path, 'w', encoding='utf-8') as f:
        json.dump(rl_data, f, ensure_ascii=False, indent=2)
    print(f"   âœ… RLè¨“ç·´ç”¨ãƒ‡ãƒ¼ã‚¿: {len(rl_data):,}ã‚¿ã‚¹ã‚¯ -> {rl_path}")
    
    # 3. ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ (2023å¹´)
    test_data = year_data['2023']
    test_path = os.path.join(output_dir, 'backlog_test_2023.json')
    with open(test_path, 'w', encoding='utf-8') as f:
        json.dump(test_data, f, ensure_ascii=False, indent=2)
    print(f"   âœ… ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿: {len(test_data):,}ã‚¿ã‚¹ã‚¯ -> {test_path}")
    
    return {
        'irl': irl_path,
        'training': rl_path,
        'test': test_path
    }


def backup_existing_files(backup_dir: str):
    """æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
    print(f"ğŸ’¾ æ—¢å­˜è¨­å®šã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸­... (ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å…ˆ: {backup_dir})")
    
    os.makedirs(backup_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    backup_files = [
        'configs/unified_rl.yaml',
        'data/backlog_training.json'
    ]
    
    for filepath in backup_files:
        if os.path.exists(filepath):
            filename = os.path.basename(filepath)
            backup_path = os.path.join(backup_dir, f"{filename}.backup_{timestamp}")
            shutil.copy2(filepath, backup_path)
            print(f"   âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {filepath} -> {backup_path}")


def update_config_file(new_paths: Dict[str, str], config_path: str):
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°"""
    print(f"âš™ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°ä¸­: {config_path}")
    
    # æ—¢å­˜è¨­å®šã‚’èª­ã¿è¾¼ã¿
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ã‚’æ›´æ–°
    config['env']['backlog_path'] = new_paths['training']
    
    # è©•ä¾¡ç”¨è¨­å®šã‚’è¿½åŠ 
    if 'evaluation' not in config:
        config['evaluation'] = {}
    config['evaluation']['test_data_path'] = new_paths['test']
    
    # è¨­å®šã‚’ä¿å­˜
    with open(config_path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
    
    print(f"   âœ… è¨­å®šæ›´æ–°å®Œäº†")
    print(f"      - è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {new_paths['training']}")
    print(f"      - ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {new_paths['test']}")


def create_migration_report(year_data: Dict[str, List[Dict]], new_paths: Dict[str, str], output_dir: str):
    """ç§»è¡Œãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ"""
    report_path = os.path.join(output_dir, 'temporal_split_report.md')
    
    print(f"ğŸ“Š ç§»è¡Œãƒ¬ãƒãƒ¼ãƒˆä½œæˆä¸­: {report_path}")
    
    total_tasks = sum(len(tasks) for tasks in year_data.values())
    irl_count = len(year_data['2019']) + len(year_data['2020']) + len(year_data['2021'])
    
    report_content = f"""# æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ãƒ¬ãƒãƒ¼ãƒˆ

ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")}

## åˆ†å‰²æ¦‚è¦

### ç›®çš„
ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯é˜²æ­¢ã®ãŸã‚ã®æ™‚ç³»åˆ—åˆ†å‰²ã‚’å®Ÿè¡Œã—ã¾ã—ãŸã€‚

### åˆ†å‰²æ–¹é‡
- **IRLå­¦ç¿’**: 2019-2021å¹´ã®ãƒ‡ãƒ¼ã‚¿ã§expert trajectoriesã‹ã‚‰å ±é…¬é–¢æ•°ã‚’å­¦ç¿’
- **RLè¨“ç·´**: 2022å¹´ã®ãƒ‡ãƒ¼ã‚¿ã§å¼·åŒ–å­¦ç¿’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨“ç·´
- **ãƒ†ã‚¹ãƒˆ**: 2023å¹´ã®ãƒ‡ãƒ¼ã‚¿ã§æœ€çµ‚æ€§èƒ½ã‚’è©•ä¾¡

## ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ

### å¹´åˆ¥ã‚¿ã‚¹ã‚¯æ•°
"""
    
    for year, tasks in year_data.items():
        count = len(tasks)
        percentage = (count / total_tasks * 100) if total_tasks > 0 else 0
        report_content += f"- **{year}å¹´**: {count:,}ã‚¿ã‚¹ã‚¯ ({percentage:.1f}%)\n"
    
    report_content += f"""
### åˆ†å‰²çµæœ
- **IRLç”¨ãƒ‡ãƒ¼ã‚¿**: {irl_count:,}ã‚¿ã‚¹ã‚¯ (2019-2021å¹´)
- **RLè¨“ç·´ç”¨ãƒ‡ãƒ¼ã‚¿**: {len(year_data['2022']):,}ã‚¿ã‚¹ã‚¯ (2022å¹´)
- **ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿**: {len(year_data['2023']):,}ã‚¿ã‚¹ã‚¯ (2023å¹´)

## ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«

### ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«
- `{new_paths['irl']}` - IRLå­¦ç¿’ç”¨
- `{new_paths['training']}` - RLè¨“ç·´ç”¨  
- `{new_paths['test']}` - ãƒ†ã‚¹ãƒˆç”¨

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. IRLå­¦ç¿’ã®å†å®Ÿè¡Œ (2019-2021å¹´ãƒ‡ãƒ¼ã‚¿)
2. æ–°ã—ã„è¨­å®šã§ã®RLè¨“ç·´ (2022å¹´ãƒ‡ãƒ¼ã‚¿)
3. 2023å¹´ãƒ‡ãƒ¼ã‚¿ã§ã®æœ€çµ‚è©•ä¾¡

## å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰

```bash
# 1. IRLå­¦ç¿’ã®å†å®Ÿè¡Œï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
python scripts/create_expert_trajectories.py --data-path {new_paths['irl']}

# 2. RLè¨“ç·´ã®å®Ÿè¡Œ
python scripts/train_simple_unified_rl.py

# 3. 2023å¹´ãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡
python scripts/evaluate_temporal_split.py --test-data {new_paths['test']}
```
"""
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"   âœ… ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†")


def main():
    parser = argparse.ArgumentParser(description='æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã‚¹ã‚¯ãƒªãƒ—ãƒˆ')
    parser.add_argument('--input-file', default='data/backlog_with_2023.json',
                       help='2023å¹´ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--output-dir', default='data/temporal_split',
                       help='åˆ†å‰²ãƒ‡ãƒ¼ã‚¿ã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--backup-dir', default='backups/temporal_split',
                       help='æ—¢å­˜è¨­å®šã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--config-path', default='configs/unified_rl.yaml',
                       help='æ›´æ–°ã™ã‚‹è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--dry-run', action='store_true',
                       help='å®Ÿéš›ã®å¤‰æ›´ã‚’è¡Œã‚ãšã«ç¢ºèªã®ã¿')
    
    args = parser.parse_args()
    
    print("ğŸš€ æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã‚¹ã‚¯ãƒªãƒ—ãƒˆé–‹å§‹")
    print("=" * 60)
    
    if args.dry_run:
        print("âš ï¸ DRY RUN ãƒ¢ãƒ¼ãƒ‰ - å®Ÿéš›ã®å¤‰æ›´ã¯è¡Œã„ã¾ã›ã‚“")
        print()
    
    try:
        # 1. å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        if not os.path.exists(args.input_file):
            print(f"âŒ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.input_file}")
            print("   2023å¹´ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ãƒãƒƒã‚¯ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æº–å‚™ã—ã¦ãã ã•ã„ã€‚")
            return
        
        # 2. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨åˆ†å‰²
        data = load_backlog_data(args.input_file)
        year_data = split_data_by_year(data)
        
        # 3. 2023å¹´ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
        if len(year_data['2023']) == 0:
            print("âš ï¸ 2023å¹´ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            print("   2023å¹´ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return
        
        if args.dry_run:
            print("ğŸ“Š åˆ†å‰²çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:")
            irl_count = len(year_data['2019']) + len(year_data['2020']) + len(year_data['2021'])
            print(f"   IRLç”¨ (2019-2021): {irl_count:,}ã‚¿ã‚¹ã‚¯")
            print(f"   RLè¨“ç·´ç”¨ (2022): {len(year_data['2022']):,}ã‚¿ã‚¹ã‚¯")
            print(f"   ãƒ†ã‚¹ãƒˆç”¨ (2023): {len(year_data['2023']):,}ã‚¿ã‚¹ã‚¯")
            print("\n   å®Ÿéš›ã«å®Ÿè¡Œã™ã‚‹ã«ã¯ --dry-run ãƒ•ãƒ©ã‚°ã‚’å¤–ã—ã¦ãã ã•ã„ã€‚")
            return
        
        # 4. æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        backup_existing_files(args.backup_dir)
        
        # 5. åˆ†å‰²ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ
        new_paths = create_split_datasets(year_data, args.output_dir)
        
        # 6. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°
        update_config_file(new_paths, args.config_path)
        
        # 7. ç§»è¡Œãƒ¬ãƒãƒ¼ãƒˆã®ä½œæˆ
        create_migration_report(year_data, new_paths, args.output_dir)
        
        print("\nâœ… æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†ï¼")
        print("=" * 60)
        print("ğŸ“‹ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("   1. IRLå­¦ç¿’ã®å†å®Ÿè¡Œ (2019-2021å¹´ãƒ‡ãƒ¼ã‚¿)")
        print("   2. æ–°ã—ã„è¨­å®šã§ã®RLè¨“ç·´ (2022å¹´ãƒ‡ãƒ¼ã‚¿)")
        print("   3. 2023å¹´ãƒ‡ãƒ¼ã‚¿ã§ã®æœ€çµ‚è©•ä¾¡")
        print(f"\nğŸ“Š è©³ç´°ã¯ç§»è¡Œãƒ¬ãƒãƒ¼ãƒˆã‚’ç¢ºèª: {args.output_dir}/temporal_split_report.md")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
