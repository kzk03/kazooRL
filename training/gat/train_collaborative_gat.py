#!/usr/bin/env python3
"""
å”åŠ›ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯¾å¿œã®æ–°ã—ã„GATãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ãƒ»ä¿å­˜ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import sys
from pathlib import Path

import torch
import torch.nn.functional as F
from tqdm import tqdm

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))

from kazoo.GAT.GAT_model import GATModel


def train_collaborative_gat():
    """å”åŠ›ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯¾å¿œã®GATãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´"""

    print("=== Training Collaborative GAT Model ===")

    # ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰
    graph_path = Path("data/graph_training.pt")
    if not graph_path.exists():
        print(f"Error: Graph data not found: {graph_path}")
        return

    data = torch.load(graph_path, weights_only=False)
    print(f"Graph loaded: {data}")

    # é–‹ç™ºè€…å”åŠ›ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ãƒ­ãƒ¼ãƒ‰
    network_path = Path("data/developer_collaboration_network.pt")
    if not network_path.exists():
        print(f"Error: Developer collaboration network not found: {network_path}")
        return

    dev_network = torch.load(network_path, weights_only=False)
    print(
        f"Collaboration network loaded: {dev_network['num_developers']} developers, {dev_network['network_stats']['num_edges']} edges"
    )

    # ã‚¨ãƒƒã‚¸è¾æ›¸ã‚’æº–å‚™ï¼ˆå”åŠ›ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å«ã‚€ï¼‰
    edge_index_dict = {
        ("dev", "writes", "task"): data[("dev", "writes", "task")].edge_index,
        ("task", "written_by", "dev"): data[("dev", "writes", "task")].edge_index.flip(
            [0]
        ),
        ("dev", "collaborates", "dev"): dev_network["dev_collaboration_edge_index"],
    }

    print("Edge types:")
    for edge_type, edge_index in edge_index_dict.items():
        print(f"  {edge_type}: {edge_index.shape}")

    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    in_channels_dict = {"dev": 8, "task": 9}
    model = GATModel(in_channels_dict=in_channels_dict, out_channels=32)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

    print(f"Model architecture:\n{model}")

    # è¨“ç·´ãƒ«ãƒ¼ãƒ—
    print("\n=== Training Loop ===")
    model.train()

    epoch_progress = tqdm(
        range(200),  # æœ¬æ ¼çš„ãªè¨“ç·´ã®ãŸã‚200ã‚¨ãƒãƒƒã‚¯ï¼ˆ50â†’200ï¼‰
        desc="ğŸ§  GAT è¨“ç·´",
        unit="epoch",
        colour="cyan",
        leave=True,
    )

    for epoch in epoch_progress:
        optimizer.zero_grad()

        try:
            # ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹
            embeddings = model(data.x_dict, edge_index_dict)

            # 1. ãƒªãƒ³ã‚¯äºˆæ¸¬æå¤±ï¼ˆdev-task ã‚¨ãƒƒã‚¸ï¼‰
            dev_task_edges = edge_index_dict[("dev", "writes", "task")]
            if dev_task_edges.size(1) > 0:
                # æ­£ä¾‹: å®Ÿéš›ã«å­˜åœ¨ã™ã‚‹ã‚¨ãƒƒã‚¸
                src_embeds = embeddings["dev"][dev_task_edges[0]]
                dst_embeds = embeddings["task"][dev_task_edges[1]]
                pos_scores = F.cosine_similarity(src_embeds, dst_embeds)

                # è² ä¾‹: ãƒ©ãƒ³ãƒ€ãƒ ã«é¸ã‚“ã å­˜åœ¨ã—ãªã„ã‚¨ãƒƒã‚¸
                num_neg = min(dev_task_edges.size(1), 100)  # è² ä¾‹æ•°ã‚’åˆ¶é™
                neg_dev_idx = torch.randint(0, embeddings["dev"].size(0), (num_neg,))
                neg_task_idx = torch.randint(0, embeddings["task"].size(0), (num_neg,))
                neg_src_embeds = embeddings["dev"][neg_dev_idx]
                neg_dst_embeds = embeddings["task"][neg_task_idx]
                neg_scores = F.cosine_similarity(neg_src_embeds, neg_dst_embeds)

                # ãƒã‚¤ãƒŠãƒªã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æå¤±
                pos_loss = F.binary_cross_entropy_with_logits(
                    pos_scores, torch.ones_like(pos_scores)
                )
                neg_loss = F.binary_cross_entropy_with_logits(
                    neg_scores, torch.zeros_like(neg_scores)
                )
                link_loss = pos_loss + neg_loss
            else:
                link_loss = torch.tensor(0.0)

            # 2. å”åŠ›ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒƒã‚¸ã«åŸºã¥ãæå¤±
            collab_edges = edge_index_dict[("dev", "collaborates", "dev")]
            if collab_edges.size(1) > 0:
                # å”åŠ›ã—ã¦ã„ã‚‹é–‹ç™ºè€…ãƒšã‚¢ã®åŸ‹ã‚è¾¼ã¿ã‚’è¿‘ã¥ã‘ã‚‹
                src_embeds = embeddings["dev"][collab_edges[0]]
                dst_embeds = embeddings["dev"][collab_edges[1]]
                collab_similarity = F.cosine_similarity(src_embeds, dst_embeds)
                collab_loss = -collab_similarity.mean()  # é¡ä¼¼åº¦ã‚’æœ€å¤§åŒ–
            else:
                collab_loss = torch.tensor(0.0)

            # 3. åŸ‹ã‚è¾¼ã¿æ­£å‰‡åŒ–æå¤±ï¼ˆL2æ­£å‰‡åŒ–ï¼‰
            dev_reg = torch.norm(embeddings["dev"], p=2, dim=1).mean()
            task_reg = torch.norm(embeddings["task"], p=2, dim=1).mean()
            reg_loss = 0.001 * (dev_reg + task_reg)

            # ç·æå¤±
            total_loss = link_loss + 0.1 * collab_loss + reg_loss

            total_loss.backward()
            optimizer.step()

            # é€²æ—ãƒãƒ¼ã®æƒ…å ±æ›´æ–°
            epoch_progress.set_postfix(
                {
                    "Loss": f"{total_loss.item():.4f}",
                    "Link": f"{link_loss.item():.4f}",
                    "Collab": f"{collab_loss.item():.4f}",
                    "Reg": f"{reg_loss.item():.4f}",
                }
            )

            if (epoch + 1) % 20 == 0:
                print(
                    f"\nEpoch {epoch+1:3d}: Loss = {total_loss.item():.4f} "
                    f"(link: {link_loss.item():.4f}, collab: {collab_loss.item():.4f}, reg: {reg_loss.item():.4f})"
                )

        except Exception as e:
            epoch_progress.set_postfix({"Error": str(e)[:20]})
            print(f"Error in epoch {epoch}: {e}")
            break

    # ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
    model.eval()

    # æœ€çµ‚çš„ãªåŸ‹ã‚è¾¼ã¿ã‚’è¨ˆç®—
    with torch.no_grad():
        final_embeddings = model(data.x_dict, edge_index_dict)

    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    model_save_path = "data/gnn_model_collaborative.pt"
    torch.save(model.state_dict(), model_save_path)
    print(f"âœ… Collaborative GAT model saved: {model_save_path}")

    # æ›´æ–°ã•ã‚ŒãŸã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚‚ä¿å­˜ï¼ˆå”åŠ›ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒƒã‚¸ã‚’å«ã‚€ï¼‰
    enhanced_data = data.clone()
    enhanced_data[("dev", "collaborates", "dev")].edge_index = dev_network[
        "dev_collaboration_edge_index"
    ]
    enhanced_data[("dev", "collaborates", "dev")].edge_attr = dev_network[
        "dev_collaboration_edge_weights"
    ]

    graph_save_path = "data/graph_collaborative.pt"
    torch.save(enhanced_data, graph_save_path)
    print(f"âœ… Enhanced graph data saved: {graph_save_path}")

    print("\n=== Training Completed ===")
    print(f"Final embeddings:")
    print(f"  - Developer embeddings: {final_embeddings['dev'].shape}")
    print(f"  - Task embeddings: {final_embeddings['task'].shape}")


if __name__ == "__main__":
    train_collaborative_gat()
