#!/usr/bin/env python3
"""
è¦³æ¸¬ç©ºé–“ã®è¤‡é›‘ã•æ¯”è¼ƒåˆ†æ
è¤‡é›‘ãªDictè¦³æ¸¬ç©ºé–“ã¨ã‚·ãƒ³ãƒ—ãƒ«ãªBoxè¦³æ¸¬ç©ºé–“ã®è©³ç´°æ¯”è¼ƒ
"""

from typing import Any, Dict

import gymnasium as gym
import numpy as np


def analyze_observation_spaces():
    """è¦³æ¸¬ç©ºé–“ã®è¤‡é›‘ã•ã‚’è©³ç´°æ¯”è¼ƒ"""

    print("ğŸ” è¦³æ¸¬ç©ºé–“ã®è¤‡é›‘ã•æ¯”è¼ƒåˆ†æ")
    print("=" * 80)

    # ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨çŠ¶æ³ã®åˆ†æã‚’è¿½åŠ 
    print("\n0ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨çŠ¶æ³ã®ç¢ºèª")
    print("=" * 50)
    analyze_data_usage()

    print("\n1ï¸âƒ£ è¤‡é›‘ãªè¦³æ¸¬ç©ºé–“ (OSSSimpleEnv)")
    print("=" * 50)

    # è¤‡é›‘ãªè¦³æ¸¬ç©ºé–“ã®ä¾‹
    num_tasks = 20
    complex_obs_space = gym.spaces.Dict(
        {
            "simple_obs": gym.spaces.Box(
                low=-np.inf,
                high=np.inf,
                shape=(num_tasks * 3,),  # 60æ¬¡å…ƒ
                dtype=np.float32,
            ),
            "gnn_embeddings": gym.spaces.Box(
                low=-np.inf, high=np.inf, shape=(64,), dtype=np.float32  # 64æ¬¡å…ƒ
            ),
        }
    )

    print(f"ğŸ“Š æ§‹é€ :")
    print(f"   ã‚¿ã‚¤ãƒ—: gym.spaces.Dict")
    print(f"   è¦ç´ æ•°: 2å€‹")
    print(f"   simple_obs: {complex_obs_space['simple_obs'].shape}")
    print(f"   gnn_embeddings: {complex_obs_space['gnn_embeddings'].shape}")
    print(
        f"   ç·æ¬¡å…ƒ: {num_tasks * 3 + 64} = {complex_obs_space['simple_obs'].shape[0]} + {complex_obs_space['gnn_embeddings'].shape[0]}"
    )

    # ã‚µãƒ³ãƒ—ãƒ«è¦³æ¸¬ã®ç”Ÿæˆ
    complex_sample = complex_obs_space.sample()
    print(f"\nğŸ“¦ ã‚µãƒ³ãƒ—ãƒ«è¦³æ¸¬:")
    print(f"   simple_obs[0:5]: {complex_sample['simple_obs'][:5]}")
    print(f"   gnn_embeddings[0:5]: {complex_sample['gnn_embeddings'][:5]}")
    print(f"   ãƒ‡ãƒ¼ã‚¿å‹: {type(complex_sample)}")

    print(f"\nâŒ å•é¡Œç‚¹:")
    problems = [
        "Stable-Baselines3ã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„",
        "ãƒã‚¹ãƒˆã—ãŸè¦³æ¸¬ç©ºé–“ï¼ˆDictå†…ã«Boxï¼‰",
        "ç‰¹å¾´é‡ã®çµåˆå‡¦ç†ãŒè¤‡é›‘",
        "ã‚¿ã‚¹ã‚¯æ•°å¤‰æ›´æ™‚ã®è¦³æ¸¬ç©ºé–“å†å®šç¾©ãŒå¿…è¦",
        "PPOã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã®ç›´æ¥å‡¦ç†ãŒå›°é›£",
    ]

    for i, problem in enumerate(problems, 1):
        print(f"   {i}. {problem}")

    print(f"\n2ï¸âƒ£ ã‚·ãƒ³ãƒ—ãƒ«è¦³æ¸¬ç©ºé–“ (SimpleTaskAssignmentEnv)")
    print("=" * 50)

    # ã‚·ãƒ³ãƒ—ãƒ«è¦³æ¸¬ç©ºé–“ã®ä¾‹
    feature_dim = 62  # FeatureExtractorã®å‡ºåŠ›æ¬¡å…ƒ
    simple_obs_space = gym.spaces.Box(
        low=-np.inf, high=np.inf, shape=(feature_dim,), dtype=np.float32
    )

    print(f"ğŸ“Š æ§‹é€ :")
    print(f"   ã‚¿ã‚¤ãƒ—: gym.spaces.Box")
    print(f"   æ¬¡å…ƒ: {simple_obs_space.shape}")
    print(f"   è¦ç´ æ•°: 1å€‹ï¼ˆçµ±åˆãƒ™ã‚¯ãƒˆãƒ«ï¼‰")
    print(f"   ç·æ¬¡å…ƒ: {feature_dim}")

    # ã‚µãƒ³ãƒ—ãƒ«è¦³æ¸¬ã®ç”Ÿæˆ
    simple_sample = simple_obs_space.sample()
    print(f"\nğŸ“¦ ã‚µãƒ³ãƒ—ãƒ«è¦³æ¸¬:")
    print(f"   è¦³æ¸¬[0:5]: {simple_sample[:5]}")
    print(f"   è¦³æ¸¬[-5:]: {simple_sample[-5:]}")
    print(f"   ãƒ‡ãƒ¼ã‚¿å‹: {type(simple_sample)}")

    print(f"\nâœ… åˆ©ç‚¹:")
    advantages = [
        "Stable-Baselines3ã§å®Œå…¨ã‚µãƒãƒ¼ãƒˆ",
        "å˜ä¸€ãƒ™ã‚¯ãƒˆãƒ«ã€ãƒã‚¹ãƒˆãªã—",
        "PPOã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ç›´æ¥å‡¦ç†å¯èƒ½",
        "ç‰¹å¾´é‡æŠ½å‡ºå™¨ã«ã‚ˆã‚‹æŸ”è»Ÿãªå†…å®¹å¤‰æ›´",
        "ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒè‰¯ã„",
    ]

    for i, advantage in enumerate(advantages, 1):
        print(f"   {i}. {advantage}")

    print(f"\n3ï¸âƒ£ ç‰¹å¾´é‡ã®å†…å®¹æ¯”è¼ƒ")
    print("=" * 50)

    print(f"\nğŸ”¸ è¤‡é›‘ãªè¦³æ¸¬ç©ºé–“ã®å†…å®¹:")
    complex_features = {
        "simple_obs (60æ¬¡å…ƒ)": [
            "ã‚¿ã‚¹ã‚¯1: [status, complexity, deadline]",
            "ã‚¿ã‚¹ã‚¯2: [status, complexity, deadline]",
            "...",
            "ã‚¿ã‚¹ã‚¯20: [status, complexity, deadline]",
        ],
        "gnn_embeddings (64æ¬¡å…ƒ)": [
            "GATåŸ‹ã‚è¾¼ã¿ã®Global Average Pooling",
            "é–‹ç™ºè€…+ã‚¿ã‚¹ã‚¯ã‚°ãƒ©ãƒ•ã®ç·åˆè¡¨ç¾",
            "å›ºå®š64æ¬¡å…ƒ",
        ],
    }

    for feature_type, details in complex_features.items():
        print(f"   {feature_type}:")
        for detail in details:
            print(f"     - {detail}")

    print(f"\nğŸ”¸ ã‚·ãƒ³ãƒ—ãƒ«è¦³æ¸¬ç©ºé–“ã®å†…å®¹ (FeatureExtractorå‡ºåŠ›):")
    simple_features = {
        "ã‚¿ã‚¹ã‚¯ç‰¹å¾´é‡ (9æ¬¡å…ƒ)": [
            "task_days_since_last_activity",
            "task_discussion_activity",
            "task_text_length",
            "task_code_block_count",
            "task_label_* (5ç¨®é¡)",
        ],
        "é–‹ç™ºè€…ç‰¹å¾´é‡ (6æ¬¡å…ƒ)": [
            "dev_recent_activity_count",
            "dev_current_workload",
            "dev_total_lines_changed",
            "dev_collaboration_network_size",
            "dev_comment_interactions",
            "dev_cross_issue_activity",
        ],
        "ãƒãƒƒãƒãƒ³ã‚°ç‰¹å¾´é‡ (10æ¬¡å…ƒ)": [
            "match_collaborated_with_task_author",
            "match_collaborator_overlap_count",
            "match_has_prior_collaboration",
            "match_skill_intersection_count",
            "match_file_experience_count",
            "match_affinity_* (5ç¨®é¡)",
        ],
        "GATç‰¹å¾´é‡ (37æ¬¡å…ƒ)": [
            "gat_similarity",
            "gat_dev_expertise",
            "gat_task_popularity",
            "gat_collaboration_strength",
            "gat_network_centrality",
            "gat_dev_emb_* (32æ¬¡å…ƒåŸ‹ã‚è¾¼ã¿)",
        ],
    }

    for feature_type, details in simple_features.items():
        print(f"   {feature_type}:")
        for detail in details:
            print(f"     - {detail}")

    print(f"\n4ï¸âƒ£ Stable-Baselines3å¯¾å¿œã®é•ã„")
    print("=" * 50)

    print(f"\nâŒ è¤‡é›‘ãªè¦³æ¸¬ç©ºé–“ã§ã®ã‚¨ãƒ©ãƒ¼:")
    error_message = """
NotImplementedError: Nested observation spaces are not supported 
(Tuple/Dict space inside Tuple/Dict space).
    """
    print(f"   {error_message.strip()}")

    print(f"\nâœ… ã‚·ãƒ³ãƒ—ãƒ«è¦³æ¸¬ç©ºé–“ã§ã®æ­£å¸¸å‹•ä½œ:")
    success_messages = [
        "PPO('MlpPolicy', env) â† æ­£å¸¸ã«åˆæœŸåŒ–",
        "model.learn(total_timesteps=5000) â† æ­£å¸¸ã«è¨“ç·´",
        "model.predict(obs) â† æ­£å¸¸ã«æ¨è«–",
        "EvalCallback(...) â† æ­£å¸¸ã«è©•ä¾¡",
    ]

    for message in success_messages:
        print(f"   {message}")

    print(f"\n5ï¸âƒ£ ãƒ¡ãƒ¢ãƒªã¨è¨ˆç®—åŠ¹ç‡ã®æ¯”è¼ƒ")
    print("=" * 50)

    # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æ¯”è¼ƒ
    complex_memory = calculate_memory_usage(complex_obs_space, "è¤‡é›‘")
    simple_memory = calculate_memory_usage(simple_obs_space, "ã‚·ãƒ³ãƒ—ãƒ«")

    print(f"\nğŸ’¾ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡:")
    print(f"   è¤‡é›‘ãªè¦³æ¸¬ç©ºé–“: {complex_memory['total']:.2f} KB")
    print(f"     - simple_obs: {complex_memory['simple_obs']:.2f} KB")
    print(f"     - gnn_embeddings: {complex_memory['gnn_embeddings']:.2f} KB")
    print(f"     - ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {complex_memory['metadata']:.2f} KB")

    print(f"\n   ã‚·ãƒ³ãƒ—ãƒ«è¦³æ¸¬ç©ºé–“: {simple_memory['total']:.2f} KB")
    print(f"     - è¦³æ¸¬ãƒ™ã‚¯ãƒˆãƒ«: {simple_memory['obs_vector']:.2f} KB")
    print(f"     - ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {simple_memory['metadata']:.2f} KB")

    efficiency = (
        (complex_memory["total"] - simple_memory["total"])
        / complex_memory["total"]
        * 100
    )
    print(f"\n   åŠ¹ç‡æ”¹å–„: {efficiency:.1f}% ãƒ¡ãƒ¢ãƒªå‰Šæ¸›")

    print(f"\n6ï¸âƒ£ å®Ÿè£…ã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒ")
    print("=" * 50)

    print(f"\nğŸ”¸ è¤‡é›‘ãªè¦³æ¸¬ç©ºé–“ã§ã®å‡¦ç†:")
    complex_code = """
# è¦³æ¸¬ã®å–å¾—ï¼ˆè¤‡é›‘ï¼‰
obs = env.reset()
simple_part = obs['simple_obs']        # (60,)
gnn_part = obs['gnn_embeddings']       # (64,)

# PPOã§å‡¦ç†ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰
model = PPO("MlpPolicy", env)  # âŒ NotImplementedError

# æ‰‹å‹•ã§çµåˆãŒå¿…è¦
combined_obs = np.concatenate([simple_part, gnn_part])  # (124,)
"""

    print(f"   {complex_code.strip()}")

    print(f"\nğŸ”¸ ã‚·ãƒ³ãƒ—ãƒ«è¦³æ¸¬ç©ºé–“ã§ã®å‡¦ç†:")
    simple_code = """
# è¦³æ¸¬ã®å–å¾—ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ï¼‰
obs = env.reset()                      # (62,) ç›´æ¥å–å¾—

# PPOã§å‡¦ç†ï¼ˆæ­£å¸¸ï¼‰
model = PPO("MlpPolicy", env)          # âœ… æ­£å¸¸å‹•ä½œ
action = model.predict(obs)            # âœ… ç›´æ¥æ¨è«–å¯èƒ½

# çµåˆå‡¦ç†ä¸è¦
# obs ã¯ã™ã§ã«çµ±åˆæ¸ˆã¿ã®ç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«
"""

    print(f"   {simple_code.strip()}")

    print(f"\n7ï¸âƒ£ ã¾ã¨ã‚")
    print("=" * 50)

    summary = {
        "è¤‡é›‘ãªè¦³æ¸¬ç©ºé–“": {
            "åˆ©ç‚¹": ["æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®äº’æ›æ€§", "è¦ç´ åˆ¥ã®æ˜ç¢ºãªåˆ†é›¢"],
            "æ¬ ç‚¹": ["Stable-Baselines3éå¯¾å¿œ", "å®Ÿè£…ãŒè¤‡é›‘", "ãƒ¡ãƒ¢ãƒªåŠ¹ç‡æ‚ª"],
        },
        "ã‚·ãƒ³ãƒ—ãƒ«è¦³æ¸¬ç©ºé–“": {
            "åˆ©ç‚¹": ["Stable-Baselines3å¯¾å¿œ", "å®Ÿè£…ãŒç°¡å˜", "ãƒ¡ãƒ¢ãƒªåŠ¹ç‡è‰¯"],
            "æ¬ ç‚¹": ["è¦ç´ ã®åˆ†é›¢ãŒä¸æ˜ç¢º", "ãƒ‡ãƒãƒƒã‚°ãŒå›°é›£"],
        },
    }

    for space_type, pros_cons in summary.items():
        print(f"\n{space_type}:")
        print(f"   åˆ©ç‚¹: {', '.join(pros_cons['åˆ©ç‚¹'])}")
        print(f"   æ¬ ç‚¹: {', '.join(pros_cons['æ¬ ç‚¹'])}")

    print(f"\nğŸ¯ æ¨å¥¨:")
    print(f"   - æ–°è¦ã‚·ã‚¹ãƒ†ãƒ : ã‚·ãƒ³ãƒ—ãƒ«è¦³æ¸¬ç©ºé–“ã‚’ä½¿ç”¨")
    print(f"   - æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ : è¤‡é›‘â†’ã‚·ãƒ³ãƒ—ãƒ«ã«æ®µéšçš„ç§»è¡Œ")
    print(f"   - ç ”ç©¶ãƒ»å®Ÿé¨“: ã‚·ãƒ³ãƒ—ãƒ«è¦³æ¸¬ç©ºé–“ã§é«˜é€Ÿãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°")


def calculate_memory_usage(obs_space, space_type):
    """è¦³æ¸¬ç©ºé–“ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’è¨ˆç®—"""

    if space_type == "è¤‡é›‘":
        simple_obs_size = obs_space["simple_obs"].shape[0] * 4  # float32 = 4 bytes
        gnn_emb_size = obs_space["gnn_embeddings"].shape[0] * 4
        metadata_size = 100  # Dictæ§‹é€ ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰

        return {
            "simple_obs": simple_obs_size / 1024,  # KB
            "gnn_embeddings": gnn_emb_size / 1024,
            "metadata": metadata_size / 1024,
            "total": (simple_obs_size + gnn_emb_size + metadata_size) / 1024,
        }

    else:  # ã‚·ãƒ³ãƒ—ãƒ«
        obs_vector_size = obs_space.shape[0] * 4  # float32 = 4 bytes
        metadata_size = 20  # Boxæ§‹é€ ã®è»½é‡ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰

        return {
            "obs_vector": obs_vector_size / 1024,  # KB
            "metadata": metadata_size / 1024,
            "total": (obs_vector_size + metadata_size) / 1024,
        }


def analyze_data_usage():
    """ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨çŠ¶æ³ã®åˆ†æ"""
    import json
    from datetime import datetime

    try:
        print(f"ğŸ“… ãƒ‡ãƒ¼ã‚¿æœŸé–“ã®åˆ†æ:")

        # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        data_files = {
            "å…¨ãƒ‡ãƒ¼ã‚¿": "data/backlog.json",
            "RLè¨“ç·´ç”¨(2022)": "data/backlog_training_2022.json",
            "æ—§è¨“ç·´ç”¨(2019-2021)": "data/backlog_training.json",
            "ãƒ†ã‚¹ãƒˆç”¨": "data/backlog_test_2022.json",
        }

        for name, filepath in data_files.items():
            try:
                with open(filepath, "r", encoding="utf-8") as f:
                    data = json.load(f)

                if data:
                    start_date = data[0]["created_at"][:10]
                    end_date = data[-1]["created_at"][:10]
                    count = len(data)

                    print(f"   {name}: {count:,}ã‚¿ã‚¹ã‚¯ ({start_date} ï½ {end_date})")
                else:
                    print(f"   {name}: ãƒ‡ãƒ¼ã‚¿ãªã—")

            except FileNotFoundError:
                print(f"   {name}: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ ({filepath})")
            except Exception as e:
                print(f"   {name}: ã‚¨ãƒ©ãƒ¼ ({e})")

        print(f"\nğŸ¯ ç¾åœ¨ã®ä½¿ç”¨æ–¹æ³•:")
        print(f"   - IRLå­¦ç¿’: 2019-2021å¹´ã®expert trajectoriesï¼ˆå­¦ç¿’æ¸ˆã¿ï¼‰")
        print(f"   - RLè¨“ç·´: 2022å¹´ã®backlog_training_2022.json")
        print(f"   - è©•ä¾¡: 2022å¹´ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ")

        print(f"\nâœ… æ”¹å–„ç‚¹:")
        print(f"   - IRLã¨RLã§ç•°ãªã‚‹æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨")
        print(f"   - æ™‚ç³»åˆ—é †åº: IRL(2019-2021) â†’ RL(2022)")
        print(f"   - ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã®ãƒªã‚¹ã‚¯ã‚’å¤§å¹…ã«è»½æ¸›")

        print(f"\nğŸ”§ ã•ã‚‰ãªã‚‹æ”¹å–„æ¡ˆï¼ˆ2023å¹´ãƒ‡ãƒ¼ã‚¿è¿½åŠ å¾Œï¼‰:")
        print(f"   - IRLå­¦ç¿’: 2019-2021å¹´ï¼ˆç¾åœ¨ï¼‰")
        print(f"   - RLè¨“ç·´: 2022å¹´ï¼ˆç¾åœ¨ï¼‰")
        print(f"   - ãƒ†ã‚¹ãƒˆ: 2023å¹´ï¼ˆè¿½åŠ äºˆå®šï¼‰")
        print(f"   å®Ÿè¡Œ: python scripts/split_temporal_data_simple.py")

    except Exception as e:
        print(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨çŠ¶æ³ã®åˆ†æã§ã‚¨ãƒ©ãƒ¼: {e}")


if __name__ == "__main__":
    analyze_observation_spaces()
