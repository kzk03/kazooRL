#!/usr/bin/env python3
"""
IRLå…¨é‡ã¿è©³ç´°åˆ†æ - å…¨ã¦ã®ç‰¹å¾´é‡é‡ã¿ã‚’è©³ç´°ã«è¡¨ç¤ºãƒ»åˆ†æ
"""

import sys
from datetime import datetime
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

sys.path.append("src")


def get_all_feature_names_and_descriptions():
    """å…¨ç‰¹å¾´é‡åã¨èª¬æ˜ã®å¯¾å¿œã‚’å–å¾—"""

    # åŸºæœ¬ç‰¹å¾´é‡ï¼ˆ25æ¬¡å…ƒï¼‰
    base_features = [
        ("task_days_since_last_activity", "ã‚¿ã‚¹ã‚¯ã®æœ€çµ‚æ´»å‹•ã‹ã‚‰ã®æ—¥æ•°"),
        ("task_discussion_activity", "ã‚¿ã‚¹ã‚¯ã®ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³æ´»å‹•åº¦"),
        ("task_text_length", "ã‚¿ã‚¹ã‚¯ãƒ†ã‚­ã‚¹ãƒˆã®é•·ã•"),
        ("task_code_block_count", "ã‚¿ã‚¹ã‚¯å†…ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯æ•°"),
        ("task_label_bug", "ãƒã‚°ãƒ©ãƒ™ãƒ«ã®æœ‰ç„¡"),
        ("task_label_enhancement", "æ©Ÿèƒ½å¼·åŒ–ãƒ©ãƒ™ãƒ«ã®æœ‰ç„¡"),
        ("task_label_documentation", "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ©ãƒ™ãƒ«ã®æœ‰ç„¡"),
        ("task_label_question", "è³ªå•ãƒ©ãƒ™ãƒ«ã®æœ‰ç„¡"),
        ("task_label_help wanted", "ãƒ˜ãƒ«ãƒ—å‹Ÿé›†ãƒ©ãƒ™ãƒ«ã®æœ‰ç„¡"),
        ("dev_recent_activity_count", "é–‹ç™ºè€…ã®æœ€è¿‘ã®æ´»å‹•æ•°"),
        ("dev_current_workload", "é–‹ç™ºè€…ã®ç¾åœ¨ã®ä½œæ¥­è² è·"),
        ("dev_total_lines_changed", "é–‹ç™ºè€…ã®ç·å¤‰æ›´è¡Œæ•°"),
        ("dev_collaboration_network_size", "é–‹ç™ºè€…ã®å”åŠ›ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚µã‚¤ã‚º"),
        ("dev_comment_interactions", "é–‹ç™ºè€…ã®ã‚³ãƒ¡ãƒ³ãƒˆç›¸äº’ä½œç”¨æ•°"),
        ("dev_cross_issue_activity", "é–‹ç™ºè€…ã®ã‚¯ãƒ­ã‚¹ã‚¤ã‚·ãƒ¥ãƒ¼æ´»å‹•"),
        ("match_collaborated_with_task_author", "ã‚¿ã‚¹ã‚¯ä½œæˆè€…ã¨ã®å”åŠ›å±¥æ­´"),
        ("match_collaborator_overlap_count", "å…±é€šå”åŠ›è€…æ•°"),
        ("match_has_prior_collaboration", "éå»ã®å”åŠ›é–¢ä¿‚ã®æœ‰ç„¡"),
        ("match_skill_intersection_count", "ã‚¹ã‚­ãƒ«äº¤å·®æ•°"),
        ("match_file_experience_count", "ãƒ•ã‚¡ã‚¤ãƒ«çµŒé¨“æ•°"),
        ("match_affinity_for_bug", "ãƒã‚°å¯¾å¿œã¸ã®è¦ªå’Œæ€§"),
        ("match_affinity_for_enhancement", "æ©Ÿèƒ½å¼·åŒ–ã¸ã®è¦ªå’Œæ€§"),
        ("match_affinity_for_documentation", "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæ¥­ã¸ã®è¦ªå’Œæ€§"),
        ("match_affinity_for_question", "è³ªå•å¯¾å¿œã¸ã®è¦ªå’Œæ€§"),
        ("match_affinity_for_help wanted", "ãƒ˜ãƒ«ãƒ—å¯¾å¿œã¸ã®è¦ªå’Œæ€§"),
    ]

    # GATç‰¹å¾´é‡ï¼ˆ37æ¬¡å…ƒï¼‰
    gat_features = [
        ("gat_similarity", "GATé¡ä¼¼åº¦"),
        ("gat_dev_expertise", "GATé–‹ç™ºè€…å°‚é–€æ€§"),
        ("gat_task_popularity", "GATã‚¿ã‚¹ã‚¯äººæ°—åº¦"),
        ("gat_collaboration_strength", "GATå”åŠ›é–¢ä¿‚å¼·åº¦"),
        ("gat_network_centrality", "GATãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸­å¿ƒæ€§"),
    ]

    # GATåŸ‹ã‚è¾¼ã¿ï¼ˆ32æ¬¡å…ƒï¼‰
    for i in range(32):
        gat_features.append((f"gat_dev_emb_{i}", f"GATé–‹ç™ºè€…åŸ‹ã‚è¾¼ã¿ç¬¬{i}æ¬¡å…ƒ"))

    return base_features + gat_features


def load_irl_weights():
    """IRLé‡ã¿ã‚’èª­ã¿è¾¼ã¿"""
    weight_files = [
        "data/learned_weights_training.npy",
        "reward_weights.npy",
        "learned_reward_weights.npy",
        "data/learned_reward_weights.npy",
        "data/reward_weights.npy",
    ]

    for weight_file in weight_files:
        if Path(weight_file).exists():
            try:
                weights = np.load(weight_file)
                print(f"âœ… IRLé‡ã¿ã‚’èª­ã¿è¾¼ã¿: {weight_file}")
                print(f"   é‡ã¿æ•°: {len(weights)}")
                return weights, weight_file
            except Exception as e:
                print(f"âŒ {weight_file} ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    print("âŒ IRLé‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    return None, None


def analyze_all_weights(weights, feature_descriptions):
    """å…¨é‡ã¿ã®è©³ç´°åˆ†æ"""
    print(f"\n" + "=" * 80)
    print("ğŸ“Š IRLå…¨é‡ã¿è©³ç´°åˆ†æ")
    print("=" * 80)

    # åŸºæœ¬çµ±è¨ˆ
    print(f"\nã€åŸºæœ¬çµ±è¨ˆã€‘")
    print(f"é‡ã¿æ•°: {len(weights)}")
    print(f"å¹³å‡å€¤: {np.mean(weights):.6f}")
    print(f"æ¨™æº–åå·®: {np.std(weights):.6f}")
    print(f"æœ€å°å€¤: {np.min(weights):.6f}")
    print(f"æœ€å¤§å€¤: {np.max(weights):.6f}")
    print(f"çµ¶å¯¾å€¤ã®å¹³å‡: {np.mean(np.abs(weights)):.6f}")

    # ã‚¼ãƒ­é‡ã¿ã®æ•°
    zero_weights = np.sum(np.abs(weights) < 1e-6)
    print(
        f"ã»ã¼ã‚¼ãƒ­ã®é‡ã¿æ•°: {zero_weights}/{len(weights)} ({zero_weights/len(weights)*100:.1f}%)"
    )

    # æ­£è² ã®åˆ†å¸ƒ
    positive_weights = np.sum(weights > 0)
    negative_weights = np.sum(weights < 0)
    print(f"æ­£ã®é‡ã¿: {positive_weights} ({positive_weights/len(weights)*100:.1f}%)")
    print(f"è² ã®é‡ã¿: {negative_weights} ({negative_weights/len(weights)*100:.1f}%)")

    # â˜… å…¨é‡ã¿ã®è©³ç´°è¡¨ç¤ºã‚’è¿½åŠ 
    print_all_weights_detailed(weights, feature_descriptions)


def print_all_weights_detailed(weights, feature_descriptions):
    """å…¨é‡ã¿ã®è©³ç´°è¡¨ç¤º"""
    print(f"\n" + "=" * 100)
    print("ğŸ“‹ ã€å…¨é‡ã¿è©³ç´°ä¸€è¦§ã€‘")
    print("=" * 100)
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«æ•´ç†
    categories = {
        "ã‚¿ã‚¹ã‚¯ç‰¹å¾´é‡": list(range(0, 9)),
        "é–‹ç™ºè€…ç‰¹å¾´é‡": list(range(9, 15)), 
        "ãƒãƒƒãƒãƒ³ã‚°ç‰¹å¾´é‡": list(range(15, 25)),
        "GATçµ±è¨ˆç‰¹å¾´é‡": list(range(25, 30)),
        "GATåŸ‹ã‚è¾¼ã¿": list(range(30, 62))
    }
    
    for category, indices in categories.items():
        print(f"\nğŸ¯ {category} ({len(indices)}æ¬¡å…ƒ)")
        print("-" * 80)
        
        for i in indices:
            if i < len(weights) and i < len(feature_descriptions):
                feature_name, description = feature_descriptions[i]
                weight = weights[i]
                
                # é‡è¦åº¦ãƒ¬ãƒ™ãƒ«
                abs_weight = abs(weight)
                if abs_weight > 1.5:
                    importance = "ğŸ”¥æ¥µé‡è¦"
                elif abs_weight > 1.0:
                    importance = "â­éå¸¸ã«é‡è¦"
                elif abs_weight > 0.5:
                    importance = "ğŸ“Šé‡è¦"
                elif abs_weight > 0.1:
                    importance = "ğŸ“ˆè»½å¾®"
                else:
                    importance = "â–ç„¡è¦–"
                
                # æ–¹å‘æ€§
                direction = "âœ…å¥½ã‚€" if weight > 0 else "âŒé¿ã‘ã‚‹" if weight < 0 else "ğŸ”„ä¸­ç«‹"
                
                print(f"{i+1:2d}. {feature_name:<35} | {weight:8.6f} | {importance:8s} | {direction:6s} | {description}")
    
    # é‡è¦åº¦é †ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    print(f"\n" + "=" * 100)
    print("ğŸ† ã€é‡è¦åº¦é †ãƒ©ãƒ³ã‚­ãƒ³ã‚° - å…¨62æ¬¡å…ƒã€‘")
    print("=" * 100)
    
    # é‡è¦åº¦ã§ã‚½ãƒ¼ãƒˆ
    weight_data = []
    for i, (feature_name, description) in enumerate(feature_descriptions):
        if i < len(weights):
            weight_data.append((i, feature_name, description, weights[i], abs(weights[i])))
    
    weight_data.sort(key=lambda x: x[4], reverse=True)  # çµ¶å¯¾å€¤ã§ã‚½ãƒ¼ãƒˆ
    
    print(f"{'é †ä½':>3} | {'ç‰¹å¾´é‡å':<35} | {'é‡ã¿å€¤':>10} | {'çµ¶å¯¾å€¤':>8} | {'èª¬æ˜'}")
    print("-" * 100)
    
    for rank, (idx, name, desc, weight, abs_weight) in enumerate(weight_data, 1):
        direction = "+" if weight > 0 else "-"
        print(f"{rank:3d} | {name:<35} | {direction}{abs_weight:9.6f} | {abs_weight:8.6f} | {desc}")
    
    # çµ±è¨ˆã‚µãƒãƒªãƒ¼
    print(f"\n" + "=" * 100)
    print("ğŸ“Š ã€ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆã‚µãƒãƒªãƒ¼ã€‘")
    print("=" * 100)
    
    for category, indices in categories.items():
        if indices:
            cat_weights = [weights[i] for i in indices if i < len(weights)]
            if cat_weights:
                print(f"\n{category}:")
                print(f"  æ¬¡å…ƒæ•°: {len(cat_weights)}")
                print(f"  å¹³å‡é‡ã¿: {np.mean(cat_weights):8.6f}")
                print(f"  æ¨™æº–åå·®: {np.std(cat_weights):8.6f}")
                print(f"  æœ€å¤§å€¤: {np.max(cat_weights):8.6f}")
                print(f"  æœ€å°å€¤: {np.min(cat_weights):8.6f}")
                print(f"  çµ¶å¯¾å€¤å¹³å‡: {np.mean(np.abs(cat_weights)):8.6f}")
                print(f"  æ­£ã®é‡ã¿æ•°: {np.sum(np.array(cat_weights) > 0):3d}")
                print(f"  è² ã®é‡ã¿æ•°: {np.sum(np.array(cat_weights) < 0):3d}")
                print(f"  é‡è¦é‡ã¿æ•° (|w|>0.5): {np.sum(np.abs(cat_weights) > 0.5):3d}")


def create_complete_weight_table(weights, feature_descriptions, output_dir="outputs"):
    """å…¨é‡ã¿ã®å®Œå…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ"""
    print(f"\nã€å…¨é‡ã¿è©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«ã€‘")

    # ã‚«ãƒ†ã‚´ãƒªæƒ…å ±
    categories = {
        "ã‚¿ã‚¹ã‚¯ç‰¹å¾´é‡": list(range(0, 9)),
        "é–‹ç™ºè€…ç‰¹å¾´é‡": list(range(9, 15)), 
        "ãƒãƒƒãƒãƒ³ã‚°ç‰¹å¾´é‡": list(range(15, 25)),
        "GATçµ±è¨ˆç‰¹å¾´é‡": list(range(25, 30)),
        "GATåŸ‹ã‚è¾¼ã¿": list(range(30, 62))
    }
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªã‚’å–å¾—
    def get_category(idx):
        for cat_name, indices in categories.items():
            if idx in indices:
                return cat_name
        return "ãã®ä»–"

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
    data = []
    for i, (feature_name, description) in enumerate(feature_descriptions):
        if i < len(weights):
            weight_val = weights[i]
            abs_weight = abs(weight_val)
            sign = "+" if weight_val > 0 else "-" if weight_val < 0 else "0"
            
            # é‡è¦åº¦ãƒ¬ãƒ™ãƒ«
            if abs_weight > 1.5:
                importance = "æ¥µé‡è¦"
            elif abs_weight > 1.0:
                importance = "éå¸¸ã«é‡è¦"
            elif abs_weight > 0.5:
                importance = "é‡è¦"
            elif abs_weight > 0.1:
                importance = "è»½å¾®"
            else:
                importance = "ç„¡è¦–"

            data.append(
                {
                    "ç•ªå·": i + 1,
                    "ã‚«ãƒ†ã‚´ãƒª": get_category(i),
                    "ç‰¹å¾´é‡å": feature_name,
                    "èª¬æ˜": description,
                    "é‡ã¿å€¤": weight_val,
                    "çµ¶å¯¾å€¤": abs_weight,
                    "ç¬¦å·": sign,
                    "é‡è¦åº¦": importance,
                    "é‡è¦åº¦ãƒ©ãƒ³ã‚¯": 0,  # å¾Œã§è¨­å®š
                }
            )

    df = pd.DataFrame(data)

    # é‡è¦åº¦ãƒ©ãƒ³ã‚¯ã‚’è¨­å®š
    df_sorted = df.sort_values("çµ¶å¯¾å€¤", ascending=False)
    df_sorted["é‡è¦åº¦ãƒ©ãƒ³ã‚¯"] = range(1, len(df_sorted) + 1)
    
    # å…ƒã®é †åºã«æˆ»ã™ãŸã‚ã«ç•ªå·ã§ã‚½ãƒ¼ãƒˆ
    df = df_sorted.sort_values("ç•ªå·")

    # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºï¼ˆé‡è¦åº¦é †ï¼‰
    df_display = df_sorted.copy()
    pd.set_option("display.max_rows", None)
    pd.set_option("display.max_columns", None)
    pd.set_option("display.width", None)
    pd.set_option("display.max_colwidth", 40)

    print("\nğŸ† é‡è¦åº¦é †:")
    print(df_display[["é‡è¦åº¦ãƒ©ãƒ³ã‚¯", "ç‰¹å¾´é‡å", "é‡ã¿å€¤", "é‡è¦åº¦", "ã‚«ãƒ†ã‚´ãƒª", "èª¬æ˜"]].to_string(index=False, float_format="%.6f"))

    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ï¼ˆé‡è¦åº¦é †ï¼‰
    import os

    os.makedirs(output_dir, exist_ok=True)
    csv_path = f"{output_dir}/irl_all_weights_complete_table.csv"
    df_display.to_csv(csv_path, index=False, encoding="utf-8")
    print(f"\nâœ… å…¨é‡ã¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’CSVã§ä¿å­˜: {csv_path}")
    
    # ç•ªå·é †ã§ã‚‚ä¿å­˜
    csv_path_ordered = f"{output_dir}/irl_all_weights_ordered_table.csv"
    df.to_csv(csv_path_ordered, index=False, encoding="utf-8")
    print(f"âœ… ç•ªå·é †ãƒ†ãƒ¼ãƒ–ãƒ«ã‚‚CSVã§ä¿å­˜: {csv_path_ordered}")

    return df_display, df


def analyze_by_feature_category(weights, feature_descriptions):
    """ç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®åˆ†æ"""
    print(f"\nã€ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æã€‘")

    # ã‚«ãƒ†ã‚´ãƒªåˆ†ã‘
    categories = {
        "ã‚¿ã‚¹ã‚¯ç‰¹å¾´é‡": [],
        "é–‹ç™ºè€…ç‰¹å¾´é‡": [],
        "ãƒãƒƒãƒãƒ³ã‚°ç‰¹å¾´é‡": [],
        "GATçµ±è¨ˆç‰¹å¾´é‡": [],
        "GATåŸ‹ã‚è¾¼ã¿": [],
    }

    for i, (feature_name, description) in enumerate(feature_descriptions):
        if i >= len(weights):
            continue

        weight_val = weights[i]

        if feature_name.startswith("task_"):
            categories["ã‚¿ã‚¹ã‚¯ç‰¹å¾´é‡"].append((feature_name, weight_val, description))
        elif feature_name.startswith("dev_"):
            categories["é–‹ç™ºè€…ç‰¹å¾´é‡"].append((feature_name, weight_val, description))
        elif feature_name.startswith("match_"):
            categories["ãƒãƒƒãƒãƒ³ã‚°ç‰¹å¾´é‡"].append(
                (feature_name, weight_val, description)
            )
        elif feature_name.startswith("gat_") and not "emb" in feature_name:
            categories["GATçµ±è¨ˆç‰¹å¾´é‡"].append((feature_name, weight_val, description))
        elif "gat_dev_emb" in feature_name:
            categories["GATåŸ‹ã‚è¾¼ã¿"].append((feature_name, weight_val, description))

    # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
    for category_name, features in categories.items():
        if not features:
            continue

        weights_in_category = [w for _, w, _ in features]
        print(f"\nğŸ“ {category_name} ({len(features)}å€‹)")
        print(f"   å¹³å‡é‡ã¿: {np.mean(weights_in_category):.6f}")
        print(
            f"   é‡ã¿ç¯„å›²: [{np.min(weights_in_category):.6f}, {np.max(weights_in_category):.6f}]"
        )
        print(f"   çµ¶å¯¾å€¤å¹³å‡: {np.mean(np.abs(weights_in_category)):.6f}")

        # ä¸Šä½3ã¤ã®é‡ã¿
        sorted_features = sorted(features, key=lambda x: abs(x[1]), reverse=True)
        print(f"   é‡è¦ãªç‰¹å¾´é‡ï¼ˆä¸Šä½3ã¤ï¼‰:")
        for i, (fname, weight, desc) in enumerate(sorted_features[:3]):
            print(f"     {i+1}. {fname}: {weight:.6f} ({desc})")


def create_comprehensive_visualizations(
    weights, feature_descriptions, output_dir="outputs"
):
    """åŒ…æ‹¬çš„ãªå¯è¦–åŒ–"""
    print(f"\nã€å¯è¦–åŒ–ç”Ÿæˆä¸­ã€‘")

    import os

    os.makedirs(output_dir, exist_ok=True)

    # 1. å…¨é‡ã¿ã®ãƒãƒ¼ãƒ—ãƒ­ãƒƒãƒˆ
    plt.figure(figsize=(20, 12))

    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ1: å…¨é‡ã¿ã®ãƒãƒ¼ãƒ—ãƒ­ãƒƒãƒˆ
    plt.subplot(3, 2, 1)
    indices = range(len(weights))
    colors = ["red" if w < 0 else "blue" if w > 0 else "gray" for w in weights]
    plt.bar(indices, weights, color=colors, alpha=0.7)
    plt.title("å…¨IRLé‡ã¿")
    plt.xlabel("ç‰¹å¾´é‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹")
    plt.ylabel("é‡ã¿å€¤")
    plt.grid(True, alpha=0.3)

    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ2: çµ¶å¯¾å€¤é‡ã¿ã®ãƒãƒ¼ãƒ—ãƒ­ãƒƒãƒˆ
    plt.subplot(3, 2, 2)
    abs_weights = np.abs(weights)
    plt.bar(indices, abs_weights, alpha=0.7)
    plt.title("é‡ã¿çµ¶å¯¾å€¤")
    plt.xlabel("ç‰¹å¾´é‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹")
    plt.ylabel("é‡ã¿çµ¶å¯¾å€¤")
    plt.grid(True, alpha=0.3)

    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ3: é‡ã¿ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
    plt.subplot(3, 2, 3)
    plt.hist(weights, bins=30, alpha=0.7, edgecolor="black")
    plt.title("é‡ã¿åˆ†å¸ƒ")
    plt.xlabel("é‡ã¿å€¤")
    plt.ylabel("é »åº¦")
    plt.grid(True, alpha=0.3)

    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ4: ä¸Šä½20é‡è¦ç‰¹å¾´é‡
    plt.subplot(3, 2, 4)
    sorted_indices = np.argsort(np.abs(weights))[-20:]
    top_weights = weights[sorted_indices]
    top_labels = [f"{i}:{feature_descriptions[i][0][:15]}" for i in sorted_indices]

    colors = ["red" if w < 0 else "blue" for w in top_weights]
    plt.barh(range(len(top_weights)), top_weights, color=colors, alpha=0.7)
    plt.yticks(range(len(top_weights)), top_labels, fontsize=8)
    plt.title("é‡è¦ç‰¹å¾´é‡ Top20")
    plt.xlabel("é‡ã¿å€¤")
    plt.grid(True, alpha=0.3)

    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ5: ã‚«ãƒ†ã‚´ãƒªåˆ¥å¹³å‡é‡ã¿
    plt.subplot(3, 2, 5)
    category_weights = {}

    for i, (feature_name, description) in enumerate(feature_descriptions):
        if i >= len(weights):
            continue

        if feature_name.startswith("task_"):
            category = "ã‚¿ã‚¹ã‚¯"
        elif feature_name.startswith("dev_"):
            category = "é–‹ç™ºè€…"
        elif feature_name.startswith("match_"):
            category = "ãƒãƒƒãƒãƒ³ã‚°"
        elif feature_name.startswith("gat_") and not "emb" in feature_name:
            category = "GATçµ±è¨ˆ"
        elif "gat_dev_emb" in feature_name:
            category = "GATåŸ‹ã‚è¾¼ã¿"
        else:
            category = "ãã®ä»–"

        if category not in category_weights:
            category_weights[category] = []
        category_weights[category].append(abs(weights[i]))

    categories = list(category_weights.keys())
    avg_weights = [np.mean(category_weights[cat]) for cat in categories]

    plt.bar(categories, avg_weights, alpha=0.7)
    plt.title("ã‚«ãƒ†ã‚´ãƒªåˆ¥å¹³å‡é‡ã¿çµ¶å¯¾å€¤")
    plt.xlabel("ã‚«ãƒ†ã‚´ãƒª")
    plt.ylabel("å¹³å‡é‡ã¿çµ¶å¯¾å€¤")
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)

    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ6: ç´¯ç©é‡è¦åº¦
    plt.subplot(3, 2, 6)
    sorted_abs_weights = np.sort(np.abs(weights))[::-1]
    cumsum_weights = np.cumsum(sorted_abs_weights)
    cumsum_ratio = cumsum_weights / cumsum_weights[-1]

    plt.plot(range(1, len(cumsum_ratio) + 1), cumsum_ratio, "o-", markersize=2)
    plt.title("ç´¯ç©é‡è¦åº¦")
    plt.xlabel("ç‰¹å¾´é‡æ•°")
    plt.ylabel("ç´¯ç©é‡è¦åº¦æ¯”ç‡")
    plt.grid(True, alpha=0.3)

    # 80%ãƒ©ã‚¤ãƒ³
    plt.axhline(y=0.8, color="red", linestyle="--", alpha=0.7, label="80%")
    plt.legend()

    plt.tight_layout()

    # ç”»åƒä¿å­˜
    plot_path = f"{output_dir}/irl_all_weights_comprehensive_analysis.png"
    plt.savefig(plot_path, dpi=300, bbox_inches="tight")
    plt.close()

    print(f"âœ… åŒ…æ‹¬çš„å¯è¦–åŒ–ã‚’ä¿å­˜: {plot_path}")


def generate_summary_report(weights, feature_descriptions, df, output_dir="outputs"):
    """ç·åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    import os

    os.makedirs(output_dir, exist_ok=True)

    report_path = f"{output_dir}/irl_all_weights_summary_report.txt"

    with open(report_path, "w", encoding="utf-8") as f:
        f.write("=" * 80 + "\n")
        f.write("IRLå…¨é‡ã¿è©³ç´°åˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n")
        f.write(f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write("=" * 80 + "\n\n")

        # åŸºæœ¬çµ±è¨ˆ
        f.write("ã€åŸºæœ¬çµ±è¨ˆã€‘\n")
        f.write(f"é‡ã¿æ•°: {len(weights)}\n")
        f.write(f"å¹³å‡å€¤: {np.mean(weights):.6f}\n")
        f.write(f"æ¨™æº–åå·®: {np.std(weights):.6f}\n")
        f.write(f"æœ€å°å€¤: {np.min(weights):.6f}\n")
        f.write(f"æœ€å¤§å€¤: {np.max(weights):.6f}\n")
        f.write(f"çµ¶å¯¾å€¤ã®å¹³å‡: {np.mean(np.abs(weights)):.6f}\n\n")

        # ä¸Šä½é‡è¦ç‰¹å¾´é‡
        f.write("ã€æœ€é‡è¦ç‰¹å¾´é‡ Top20ã€‘\n")
        top_20 = df.sort_values("çµ¶å¯¾å€¤", ascending=False).head(20)
        for _, row in top_20.iterrows():
            f.write(
                f"{row['é‡è¦åº¦ãƒ©ãƒ³ã‚¯']:2d}. {row['ç‰¹å¾´é‡å']:<30} | {row['é‡ã¿å€¤']:>10.6f} | {row['èª¬æ˜']}\n"
            )

        f.write("\nã€æœ€ã‚‚æ­£ã®é‡ã¿ Top10ã€‘\n")
        top_positive = df.sort_values("é‡ã¿å€¤", ascending=False).head(10)
        for _, row in top_positive.iterrows():
            f.write(
                f"    {row['ç‰¹å¾´é‡å']:<30} | {row['é‡ã¿å€¤']:>10.6f} | {row['èª¬æ˜']}\n"
            )

        f.write("\nã€æœ€ã‚‚è² ã®é‡ã¿ Top10ã€‘\n")
        top_negative = df.sort_values("é‡ã¿å€¤", ascending=True).head(10)
        for _, row in top_negative.iterrows():
            f.write(
                f"    {row['ç‰¹å¾´é‡å']:<30} | {row['é‡ã¿å€¤']:>10.6f} | {row['èª¬æ˜']}\n"
            )

        # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆã‚’ãƒ¬ãƒãƒ¼ãƒˆã«è¿½åŠ 
        f.write("\nã€ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆã€‘\n")
        categories = {}
        for _, row in df.iterrows():
            feature_name = row["ç‰¹å¾´é‡å"]
            if feature_name.startswith("task_"):
                category = "ã‚¿ã‚¹ã‚¯ç‰¹å¾´é‡"
            elif feature_name.startswith("dev_"):
                category = "é–‹ç™ºè€…ç‰¹å¾´é‡"
            elif feature_name.startswith("match_"):
                category = "ãƒãƒƒãƒãƒ³ã‚°ç‰¹å¾´é‡"
            elif feature_name.startswith("gat_") and not "emb" in feature_name:
                category = "GATçµ±è¨ˆç‰¹å¾´é‡"
            elif "gat_dev_emb" in feature_name:
                category = "GATåŸ‹ã‚è¾¼ã¿"
            else:
                category = "ãã®ä»–"

            if category not in categories:
                categories[category] = []
            categories[category].append(row["é‡ã¿å€¤"])

        for category, cat_weights in categories.items():
            f.write(f"\n{category} ({len(cat_weights)}å€‹):\n")
            f.write(f"  å¹³å‡é‡ã¿: {np.mean(cat_weights):.6f}\n")
            f.write(
                f"  é‡ã¿ç¯„å›²: [{np.min(cat_weights):.6f}, {np.max(cat_weights):.6f}]\n"
            )
            f.write(f"  çµ¶å¯¾å€¤å¹³å‡: {np.mean(np.abs(cat_weights)):.6f}\n")

    print(f"âœ… ç·åˆãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {report_path}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ” IRLå…¨é‡ã¿è©³ç´°åˆ†æ")

    # IRLé‡ã¿èª­ã¿è¾¼ã¿
    weights, weight_file = load_irl_weights()
    if weights is None:
        return

    # ç‰¹å¾´é‡åã¨èª¬æ˜ã‚’å–å¾—
    feature_descriptions = get_all_feature_names_and_descriptions()

    # æ¬¡å…ƒæ•°ã®ç¢ºèª
    if len(weights) != len(feature_descriptions):
        print(
            f"âš ï¸  é‡ã¿æ•°({len(weights)})ã¨ç‰¹å¾´é‡æ•°({len(feature_descriptions)})ãŒä¸€è‡´ã—ã¾ã›ã‚“"
        )
        min_len = min(len(weights), len(feature_descriptions))
        weights = weights[:min_len]
        feature_descriptions = feature_descriptions[:min_len]
        print(f"   æœ€åˆã®{min_len}æ¬¡å…ƒã§åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™")

    # å…¨é‡ã¿åˆ†æ
    analyze_all_weights(weights, feature_descriptions)

    # å®Œå…¨ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
    df_importance, df_ordered = create_complete_weight_table(weights, feature_descriptions)

    # ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ
    analyze_by_feature_category(weights, feature_descriptions)

    # åŒ…æ‹¬çš„å¯è¦–åŒ–
    create_comprehensive_visualizations(weights, feature_descriptions)

    # ç·åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    generate_summary_report(weights, feature_descriptions, df_importance)

    print("\nâœ… IRLå…¨é‡ã¿è©³ç´°åˆ†æå®Œäº†ï¼")
    print("ğŸ“ ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
    print("   - outputs/irl_all_weights_complete_table.csv (é‡è¦åº¦é †)")
    print("   - outputs/irl_all_weights_ordered_table.csv (ç•ªå·é †)")
    print("   - outputs/irl_all_weights_comprehensive_analysis.png")
    print("   - outputs/irl_all_weights_summary_report.txt")


if __name__ == "__main__":
    main()
