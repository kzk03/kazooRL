#!/usr/bin/env python3
"""
IRLå…¨é‡ã¿è©³ç´°åˆ†æ - å…¨ã¦ã®ç‰¹å¾´é‡é‡ã¿ã‚’è©³ç´°ã«è¡¨ç¤ºãƒ»åˆ†æ
"""

import sys
from datetime import datetime
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

sys.path.append("src")


def get_all_feature_names_and_descriptions():
    """å…¨ç‰¹å¾´é‡åã¨èª¬æ˜ã®å¯¾å¿œã‚’å–å¾—"""

    # åŸºæœ¬ç‰¹å¾´é‡ï¼ˆ25æ¬¡å…ƒï¼‰
    base_features = [
        ("task_days_since_last_activity", "ã‚¿ã‚¹ã‚¯ã®æœ€çµ‚æ´»å‹•ã‹ã‚‰ã®æ—¥æ•°"),
        ("task_discussion_activity", "ã‚¿ã‚¹ã‚¯ã®ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³æ´»å‹•åº¦"),
        ("task_text_length", "ã‚¿ã‚¹ã‚¯ãƒ†ã‚­ã‚¹ãƒˆã®é•·ã•"),
        ("task_code_block_count", "ã‚¿ã‚¹ã‚¯å†…ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯æ•°"),
        ("task_label_bug", "ãƒã‚°ãƒ©ãƒ™ãƒ«ã®æœ‰ç„¡"),
        ("task_label_enhancement", "æ©Ÿèƒ½å¼·åŒ–ãƒ©ãƒ™ãƒ«ã®æœ‰ç„¡"),
        ("task_label_documentation", "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ©ãƒ™ãƒ«ã®æœ‰ç„¡"),
        ("task_label_question", "è³ªå•ãƒ©ãƒ™ãƒ«ã®æœ‰ç„¡"),
        ("task_label_help wanted", "ãƒ˜ãƒ«ãƒ—å‹Ÿé›†ãƒ©ãƒ™ãƒ«ã®æœ‰ç„¡"),
        ("dev_recent_activity_count", "é–‹ç™ºè€…ã®æœ€è¿‘ã®æ´»å‹•æ•°"),
        ("dev_current_workload", "é–‹ç™ºè€…ã®ç¾åœ¨ã®ä½œæ¥­è² è·"),
        ("dev_total_lines_changed", "é–‹ç™ºè€…ã®ç·å¤‰æ›´è¡Œæ•°"),
        ("dev_collaboration_network_size", "é–‹ç™ºè€…ã®å”åŠ›ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚µã‚¤ã‚º"),
        ("dev_comment_interactions", "é–‹ç™ºè€…ã®ã‚³ãƒ¡ãƒ³ãƒˆç›¸äº’ä½œç”¨æ•°"),
        ("dev_cross_issue_activity", "é–‹ç™ºè€…ã®ã‚¯ãƒ­ã‚¹ã‚¤ã‚·ãƒ¥ãƒ¼æ´»å‹•"),
        ("match_collaborated_with_task_author", "ã‚¿ã‚¹ã‚¯ä½œæˆè€…ã¨ã®å”åŠ›å±¥æ­´"),
        ("match_collaborator_overlap_count", "å…±é€šå”åŠ›è€…æ•°"),
        ("match_has_prior_collaboration", "éå»ã®å”åŠ›é–¢ä¿‚ã®æœ‰ç„¡"),
        ("match_skill_intersection_count", "ã‚¹ã‚­ãƒ«äº¤å·®æ•°"),
        ("match_file_experience_count", "ãƒ•ã‚¡ã‚¤ãƒ«çµŒé¨“æ•°"),
        ("match_affinity_for_bug", "ãƒã‚°å¯¾å¿œã¸ã®è¦ªå’Œæ€§"),
        ("match_affinity_for_enhancement", "æ©Ÿèƒ½å¼·åŒ–ã¸ã®è¦ªå’Œæ€§"),
        ("match_affinity_for_documentation", "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæ¥­ã¸ã®è¦ªå’Œæ€§"),
        ("match_affinity_for_question", "è³ªå•å¯¾å¿œã¸ã®è¦ªå’Œæ€§"),
        ("match_affinity_for_help wanted", "ãƒ˜ãƒ«ãƒ—å¯¾å¿œã¸ã®è¦ªå’Œæ€§"),
    ]

    # GATç‰¹å¾´é‡ï¼ˆ37æ¬¡å…ƒï¼‰
    gat_features = [
        ("gat_similarity", "GATé¡ä¼¼åº¦"),
        ("gat_dev_expertise", "GATé–‹ç™ºè€…å°‚é–€æ€§"),
        ("gat_task_popularity", "GATã‚¿ã‚¹ã‚¯äººæ°—åº¦"),
        ("gat_collaboration_strength", "GATå”åŠ›é–¢ä¿‚å¼·åº¦"),
        ("gat_network_centrality", "GATãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸­å¿ƒæ€§"),
    ]
    
    # GATåŸ‹ã‚è¾¼ã¿ï¼ˆ32æ¬¡å…ƒï¼‰
    for i in range(32):
        gat_features.append((f"gat_dev_emb_{i}", f"GATé–‹ç™ºè€…åŸ‹ã‚è¾¼ã¿ç¬¬{i}æ¬¡å…ƒ"))

    return base_features + gat_features


def load_irl_weights():
    """IRLé‡ã¿ã‚’èª­ã¿è¾¼ã¿"""
    weight_files = [
        "data/learned_weights_training.npy",
        "reward_weights.npy",
        "learned_reward_weights.npy",
        "data/learned_reward_weights.npy",
        "data/reward_weights.npy"
    ]
    
    for weight_file in weight_files:
        if Path(weight_file).exists():
            try:
                weights = np.load(weight_file)
                print(f"âœ… IRLé‡ã¿ã‚’èª­ã¿è¾¼ã¿: {weight_file}")
                print(f"   é‡ã¿æ•°: {len(weights)}")
                return weights, weight_file
            except Exception as e:
                print(f"âŒ {weight_file} ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    print("âŒ IRLé‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    return None, None


def analyze_all_weights(weights, feature_descriptions):
    """å…¨é‡ã¿ã®è©³ç´°åˆ†æ"""
    print(f"\n" + "="*80)
    print("ğŸ“Š IRLå…¨é‡ã¿è©³ç´°åˆ†æ")
    print("="*80)
    
    # åŸºæœ¬çµ±è¨ˆ
    print(f"\nã€åŸºæœ¬çµ±è¨ˆã€‘")
    print(f"é‡ã¿æ•°: {len(weights)}")
    print(f"å¹³å‡å€¤: {np.mean(weights):.6f}")
    print(f"æ¨™æº–åå·®: {np.std(weights):.6f}")
    print(f"æœ€å°å€¤: {np.min(weights):.6f}")
    print(f"æœ€å¤§å€¤: {np.max(weights):.6f}")
    print(f"çµ¶å¯¾å€¤ã®å¹³å‡: {np.mean(np.abs(weights)):.6f}")
    
    # ã‚¼ãƒ­é‡ã¿ã®æ•°
    zero_weights = np.sum(np.abs(weights) < 1e-6)
    print(f"ã»ã¼ã‚¼ãƒ­ã®é‡ã¿æ•°: {zero_weights}/{len(weights)} ({zero_weights/len(weights)*100:.1f}%)")
    
    # æ­£è² ã®åˆ†å¸ƒ
    positive_weights = np.sum(weights > 0)
    negative_weights = np.sum(weights < 0)
    print(f"æ­£ã®é‡ã¿: {positive_weights} ({positive_weights/len(weights)*100:.1f}%)")
    print(f"è² ã®é‡ã¿: {negative_weights} ({negative_weights/len(weights)*100:.1f}%)")


def create_complete_weight_table(weights, feature_descriptions, output_dir="outputs"):
    """å…¨é‡ã¿ã®å®Œå…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ"""
    print(f"\nã€å…¨é‡ã¿è©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«ã€‘")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
    data = []
    for i, (feature_name, description) in enumerate(feature_descriptions):
        if i < len(weights):
            weight_val = weights[i]
            abs_weight = abs(weight_val)
            sign = "+" if weight_val > 0 else "-" if weight_val < 0 else "0"
            
            data.append({
                "ç•ªå·": i,
                "ç‰¹å¾´é‡å": feature_name,
                "èª¬æ˜": description,
                "é‡ã¿å€¤": weight_val,
                "çµ¶å¯¾å€¤": abs_weight,
                "ç¬¦å·": sign,
                "é‡è¦åº¦ãƒ©ãƒ³ã‚¯": 0  # å¾Œã§è¨­å®š
            })
    
    df = pd.DataFrame(data)
    
    # é‡è¦åº¦ãƒ©ãƒ³ã‚¯ã‚’è¨­å®š
    df = df.sort_values("çµ¶å¯¾å€¤", ascending=False)
    df["é‡è¦åº¦ãƒ©ãƒ³ã‚¯"] = range(1, len(df) + 1)
    df = df.sort_values("ç•ªå·")  # å…ƒã®é †åºã«æˆ»ã™
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
    pd.set_option('display.max_rows', None)
    pd.set_option('display.max_columns', None)
    pd.set_option('display.width', None)
    pd.set_option('display.max_colwidth', 50)
    
    print(df.to_string(index=False, float_format='%.6f'))
    
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
    import os
    os.makedirs(output_dir, exist_ok=True)
    csv_path = f"{output_dir}/irl_all_weights_table.csv"
    df.to_csv(csv_path, index=False, encoding='utf-8')
    print(f"\nâœ… å…¨é‡ã¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’CSVã§ä¿å­˜: {csv_path}")
    
    return df


def analyze_by_feature_category(weights, feature_descriptions):
    """ç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®åˆ†æ"""
    print(f"\nã€ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æã€‘")
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ†ã‘
    categories = {
        "ã‚¿ã‚¹ã‚¯ç‰¹å¾´é‡": [],
        "é–‹ç™ºè€…ç‰¹å¾´é‡": [],
        "ãƒãƒƒãƒãƒ³ã‚°ç‰¹å¾´é‡": [],
        "GATçµ±è¨ˆç‰¹å¾´é‡": [],
        "GATåŸ‹ã‚è¾¼ã¿": []
    }
    
    for i, (feature_name, description) in enumerate(feature_descriptions):
        if i >= len(weights):
            continue
            
        weight_val = weights[i]
        
        if feature_name.startswith("task_"):
            categories["ã‚¿ã‚¹ã‚¯ç‰¹å¾´é‡"].append((feature_name, weight_val, description))
        elif feature_name.startswith("dev_"):
            categories["é–‹ç™ºè€…ç‰¹å¾´é‡"].append((feature_name, weight_val, description))
        elif feature_name.startswith("match_"):
            categories["ãƒãƒƒãƒãƒ³ã‚°ç‰¹å¾´é‡"].append((feature_name, weight_val, description))
        elif feature_name.startswith("gat_") and not "emb" in feature_name:
            categories["GATçµ±è¨ˆç‰¹å¾´é‡"].append((feature_name, weight_val, description))
        elif "gat_dev_emb" in feature_name:
            categories["GATåŸ‹ã‚è¾¼ã¿"].append((feature_name, weight_val, description))
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
    for category_name, features in categories.items():
        if not features:
            continue
            
        weights_in_category = [w for _, w, _ in features]
        print(f"\nğŸ“ {category_name} ({len(features)}å€‹)")
        print(f"   å¹³å‡é‡ã¿: {np.mean(weights_in_category):.6f}")
        print(f"   é‡ã¿ç¯„å›²: [{np.min(weights_in_category):.6f}, {np.max(weights_in_category):.6f}]")
        print(f"   çµ¶å¯¾å€¤å¹³å‡: {np.mean(np.abs(weights_in_category)):.6f}")
        
        # ä¸Šä½3ã¤ã®é‡ã¿
        sorted_features = sorted(features, key=lambda x: abs(x[1]), reverse=True)
        print(f"   é‡è¦ãªç‰¹å¾´é‡ï¼ˆä¸Šä½3ã¤ï¼‰:")
        for i, (fname, weight, desc) in enumerate(sorted_features[:3]):
            print(f"     {i+1}. {fname}: {weight:.6f} ({desc})")


def create_comprehensive_visualizations(weights, feature_descriptions, output_dir="outputs"):
    """åŒ…æ‹¬çš„ãªå¯è¦–åŒ–"""
    print(f"\nã€å¯è¦–åŒ–ç”Ÿæˆä¸­ã€‘")
    
    import os
    os.makedirs(output_dir, exist_ok=True)
    
    # 1. å…¨é‡ã¿ã®ãƒãƒ¼ãƒ—ãƒ­ãƒƒãƒˆ
    plt.figure(figsize=(20, 12))
    
    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ1: å…¨é‡ã¿ã®ãƒãƒ¼ãƒ—ãƒ­ãƒƒãƒˆ
    plt.subplot(3, 2, 1)
    indices = range(len(weights))
    colors = ['red' if w < 0 else 'blue' if w > 0 else 'gray' for w in weights]
    plt.bar(indices, weights, color=colors, alpha=0.7)
    plt.title('å…¨IRLé‡ã¿')
    plt.xlabel('ç‰¹å¾´é‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹')
    plt.ylabel('é‡ã¿å€¤')
    plt.grid(True, alpha=0.3)
    
    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ2: çµ¶å¯¾å€¤é‡ã¿ã®ãƒãƒ¼ãƒ—ãƒ­ãƒƒãƒˆ
    plt.subplot(3, 2, 2)
    abs_weights = np.abs(weights)
    plt.bar(indices, abs_weights, alpha=0.7)
    plt.title('é‡ã¿çµ¶å¯¾å€¤')
    plt.xlabel('ç‰¹å¾´é‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹')
    plt.ylabel('é‡ã¿çµ¶å¯¾å€¤')
    plt.grid(True, alpha=0.3)
    
    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ3: é‡ã¿ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
    plt.subplot(3, 2, 3)
    plt.hist(weights, bins=30, alpha=0.7, edgecolor='black')
    plt.title('é‡ã¿åˆ†å¸ƒ')
    plt.xlabel('é‡ã¿å€¤')
    plt.ylabel('é »åº¦')
    plt.grid(True, alpha=0.3)
    
    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ4: ä¸Šä½20é‡è¦ç‰¹å¾´é‡
    plt.subplot(3, 2, 4)
    sorted_indices = np.argsort(np.abs(weights))[-20:]
    top_weights = weights[sorted_indices]
    top_labels = [f"{i}:{feature_descriptions[i][0][:15]}" for i in sorted_indices]
    
    colors = ['red' if w < 0 else 'blue' for w in top_weights]
    plt.barh(range(len(top_weights)), top_weights, color=colors, alpha=0.7)
    plt.yticks(range(len(top_weights)), top_labels, fontsize=8)
    plt.title('é‡è¦ç‰¹å¾´é‡ Top20')
    plt.xlabel('é‡ã¿å€¤')
    plt.grid(True, alpha=0.3)
    
    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ5: ã‚«ãƒ†ã‚´ãƒªåˆ¥å¹³å‡é‡ã¿
    plt.subplot(3, 2, 5)
    category_weights = {}
    
    for i, (feature_name, description) in enumerate(feature_descriptions):
        if i >= len(weights):
            continue
            
        if feature_name.startswith("task_"):
            category = "ã‚¿ã‚¹ã‚¯"
        elif feature_name.startswith("dev_"):
            category = "é–‹ç™ºè€…"
        elif feature_name.startswith("match_"):
            category = "ãƒãƒƒãƒãƒ³ã‚°"
        elif feature_name.startswith("gat_") and not "emb" in feature_name:
            category = "GATçµ±è¨ˆ"
        elif "gat_dev_emb" in feature_name:
            category = "GATåŸ‹ã‚è¾¼ã¿"
        else:
            category = "ãã®ä»–"
        
        if category not in category_weights:
            category_weights[category] = []
        category_weights[category].append(abs(weights[i]))
    
    categories = list(category_weights.keys())
    avg_weights = [np.mean(category_weights[cat]) for cat in categories]
    
    plt.bar(categories, avg_weights, alpha=0.7)
    plt.title('ã‚«ãƒ†ã‚´ãƒªåˆ¥å¹³å‡é‡ã¿çµ¶å¯¾å€¤')
    plt.xlabel('ã‚«ãƒ†ã‚´ãƒª')
    plt.ylabel('å¹³å‡é‡ã¿çµ¶å¯¾å€¤')
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)
    
    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ6: ç´¯ç©é‡è¦åº¦
    plt.subplot(3, 2, 6)
    sorted_abs_weights = np.sort(np.abs(weights))[::-1]
    cumsum_weights = np.cumsum(sorted_abs_weights)
    cumsum_ratio = cumsum_weights / cumsum_weights[-1]
    
    plt.plot(range(1, len(cumsum_ratio) + 1), cumsum_ratio, 'o-', markersize=2)
    plt.title('ç´¯ç©é‡è¦åº¦')
    plt.xlabel('ç‰¹å¾´é‡æ•°')
    plt.ylabel('ç´¯ç©é‡è¦åº¦æ¯”ç‡')
    plt.grid(True, alpha=0.3)
    
    # 80%ãƒ©ã‚¤ãƒ³
    plt.axhline(y=0.8, color='red', linestyle='--', alpha=0.7, label='80%')
    plt.legend()
    
    plt.tight_layout()
    
    # ç”»åƒä¿å­˜
    plot_path = f"{output_dir}/irl_all_weights_comprehensive_analysis.png"
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… åŒ…æ‹¬çš„å¯è¦–åŒ–ã‚’ä¿å­˜: {plot_path}")


def generate_summary_report(weights, feature_descriptions, df, output_dir="outputs"):
    """ç·åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    import os
    os.makedirs(output_dir, exist_ok=True)
    
    report_path = f"{output_dir}/irl_all_weights_summary_report.txt"
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write("IRLå…¨é‡ã¿è©³ç´°åˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n")
        f.write(f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write("="*80 + "\n\n")
        
        # åŸºæœ¬çµ±è¨ˆ
        f.write("ã€åŸºæœ¬çµ±è¨ˆã€‘\n")
        f.write(f"é‡ã¿æ•°: {len(weights)}\n")
        f.write(f"å¹³å‡å€¤: {np.mean(weights):.6f}\n")
        f.write(f"æ¨™æº–åå·®: {np.std(weights):.6f}\n")
        f.write(f"æœ€å°å€¤: {np.min(weights):.6f}\n")
        f.write(f"æœ€å¤§å€¤: {np.max(weights):.6f}\n")
        f.write(f"çµ¶å¯¾å€¤ã®å¹³å‡: {np.mean(np.abs(weights)):.6f}\n\n")
        
        # ä¸Šä½é‡è¦ç‰¹å¾´é‡
        f.write("ã€æœ€é‡è¦ç‰¹å¾´é‡ Top20ã€‘\n")
        top_20 = df.sort_values("çµ¶å¯¾å€¤", ascending=False).head(20)
        for _, row in top_20.iterrows():
            f.write(f"{row['é‡è¦åº¦ãƒ©ãƒ³ã‚¯']:2d}. {row['ç‰¹å¾´é‡å']:<30} | {row['é‡ã¿å€¤']:>10.6f} | {row['èª¬æ˜']}\n")
        
        f.write("\nã€æœ€ã‚‚æ­£ã®é‡ã¿ Top10ã€‘\n")
        top_positive = df.sort_values("é‡ã¿å€¤", ascending=False).head(10)
        for _, row in top_positive.iterrows():
            f.write(f"    {row['ç‰¹å¾´é‡å']:<30} | {row['é‡ã¿å€¤']:>10.6f} | {row['èª¬æ˜']}\n")
        
        f.write("\nã€æœ€ã‚‚è² ã®é‡ã¿ Top10ã€‘\n")
        top_negative = df.sort_values("é‡ã¿å€¤", ascending=True).head(10)
        for _, row in top_negative.iterrows():
            f.write(f"    {row['ç‰¹å¾´é‡å']:<30} | {row['é‡ã¿å€¤']:>10.6f} | {row['èª¬æ˜']}\n")
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆã‚’ãƒ¬ãƒãƒ¼ãƒˆã«è¿½åŠ 
        f.write("\nã€ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆã€‘\n")
        categories = {}
        for _, row in df.iterrows():
            feature_name = row['ç‰¹å¾´é‡å']
            if feature_name.startswith("task_"):
                category = "ã‚¿ã‚¹ã‚¯ç‰¹å¾´é‡"
            elif feature_name.startswith("dev_"):
                category = "é–‹ç™ºè€…ç‰¹å¾´é‡"
            elif feature_name.startswith("match_"):
                category = "ãƒãƒƒãƒãƒ³ã‚°ç‰¹å¾´é‡"
            elif feature_name.startswith("gat_") and not "emb" in feature_name:
                category = "GATçµ±è¨ˆç‰¹å¾´é‡"
            elif "gat_dev_emb" in feature_name:
                category = "GATåŸ‹ã‚è¾¼ã¿"
            else:
                category = "ãã®ä»–"
            
            if category not in categories:
                categories[category] = []
            categories[category].append(row['é‡ã¿å€¤'])
        
        for category, cat_weights in categories.items():
            f.write(f"\n{category} ({len(cat_weights)}å€‹):\n")
            f.write(f"  å¹³å‡é‡ã¿: {np.mean(cat_weights):.6f}\n")
            f.write(f"  é‡ã¿ç¯„å›²: [{np.min(cat_weights):.6f}, {np.max(cat_weights):.6f}]\n")
            f.write(f"  çµ¶å¯¾å€¤å¹³å‡: {np.mean(np.abs(cat_weights)):.6f}\n")
    
    print(f"âœ… ç·åˆãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {report_path}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ” IRLå…¨é‡ã¿è©³ç´°åˆ†æ")
    
    # IRLé‡ã¿èª­ã¿è¾¼ã¿
    weights, weight_file = load_irl_weights()
    if weights is None:
        return
    
    # ç‰¹å¾´é‡åã¨èª¬æ˜ã‚’å–å¾—
    feature_descriptions = get_all_feature_names_and_descriptions()
    
    # æ¬¡å…ƒæ•°ã®ç¢ºèª
    if len(weights) != len(feature_descriptions):
        print(f"âš ï¸  é‡ã¿æ•°({len(weights)})ã¨ç‰¹å¾´é‡æ•°({len(feature_descriptions)})ãŒä¸€è‡´ã—ã¾ã›ã‚“")
        min_len = min(len(weights), len(feature_descriptions))
        weights = weights[:min_len]
        feature_descriptions = feature_descriptions[:min_len]
        print(f"   æœ€åˆã®{min_len}æ¬¡å…ƒã§åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™")
    
    # å…¨é‡ã¿åˆ†æ
    analyze_all_weights(weights, feature_descriptions)
    
    # å®Œå…¨ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
    df = create_complete_weight_table(weights, feature_descriptions)
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ
    analyze_by_feature_category(weights, feature_descriptions)
    
    # åŒ…æ‹¬çš„å¯è¦–åŒ–
    create_comprehensive_visualizations(weights, feature_descriptions)
    
    # ç·åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    generate_summary_report(weights, feature_descriptions, df)
    
    print("\nâœ… IRLå…¨é‡ã¿è©³ç´°åˆ†æå®Œäº†ï¼")
    print("ğŸ“ ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
    print("   - outputs/irl_all_weights_table.csv")
    print("   - outputs/irl_all_weights_comprehensive_analysis.png")
    print("   - outputs/irl_all_weights_summary_report.txt")


if __name__ == "__main__":
    main()
