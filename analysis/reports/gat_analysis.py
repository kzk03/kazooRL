#!/usr/bin/env python3
"""
GATç‰¹å¾´é‡ã®åˆ†æ - å”åŠ›é–¢ä¿‚ã®åŸ‹ã‚è¾¼ã¿è¡¨ç¾ã‚’è§£æ
"""

import sys
from datetime import datetime
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import torch

sys.path.append("src")


def analyze_gat_embeddings():
    """GATåŸ‹ã‚è¾¼ã¿è¡¨ç¾ã®åˆ†æ"""
    print("ğŸ§  GATç‰¹å¾´é‡åˆ†æ")
    print("=" * 60)

    # GATãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
    gat_model_path = Path("data/gnn_model_collaborative.pt")
    if not gat_model_path.exists():
        print(f"âŒ GATãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {gat_model_path}")
        return None

    try:
        # weights_only=Falseã‚’æŒ‡å®šã—ã¦torch_geometricã®ã‚¯ãƒ©ã‚¹ã‚‚èª­ã¿è¾¼ã¿å¯èƒ½ã«ã™ã‚‹
        gat_model = torch.load(gat_model_path, map_location="cpu", weights_only=False)
        print(f"âœ… GATãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ")

        if isinstance(gat_model, dict):
            print(f"ğŸ“Š ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹è¾æ›¸ã®ã‚­ãƒ¼æ•°: {len(gat_model)}")

            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è©³ç´°åˆ†æ
            layer_info = {}
            for name, param in gat_model.items():
                if isinstance(param, torch.Tensor):
                    layer_type = name.split(".")[0] if "." in name else name
                    if layer_type not in layer_info:
                        layer_info[layer_type] = []
                    layer_info[layer_type].append((name, param.shape, param.numel()))

            print(f"\nğŸ“‹ ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æƒ…å ±:")
            total_params = 0
            for layer_type, params in layer_info.items():
                layer_params = sum([p[2] for p in params])
                total_params += layer_params
                print(f"  {layer_type}: {layer_params:,} parameters")
                for name, shape, count in params:
                    print(f"    - {name}: {shape}")

            print(f"\nğŸ”¢ ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")

            # ç‰¹å®šã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®é‡ã¿åˆ†æ
            analyze_attention_weights(gat_model)

        return gat_model

    except Exception as e:
        print(f"âŒ GATãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def analyze_attention_weights(model_dict):
    """ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³é‡ã¿ã®åˆ†æ"""
    print(f"\nğŸ¯ ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³æ©Ÿæ§‹åˆ†æ:")

    attention_layers = {}
    linear_layers = {}

    for name, param in model_dict.items():
        if "att" in name.lower() or "attention" in name.lower():
            attention_layers[name] = param
        elif "linear" in name.lower() or "lin" in name.lower():
            linear_layers[name] = param

    print(f"  - ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³é–¢é€£ãƒ¬ã‚¤ãƒ¤ãƒ¼æ•°: {len(attention_layers)}")
    print(f"  - ç·šå½¢å¤‰æ›ãƒ¬ã‚¤ãƒ¤ãƒ¼æ•°: {len(linear_layers)}")

    # ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³é‡ã¿ã®çµ±è¨ˆ
    for name, weights in attention_layers.items():
        if isinstance(weights, torch.Tensor):
            w_np = weights.detach().numpy()
            print(f"\nğŸ“Š {name}:")
            print(f"    å½¢çŠ¶: {weights.shape}")
            print(f"    å¹³å‡: {w_np.mean():.6f}")
            print(f"    æ¨™æº–åå·®: {w_np.std():.6f}")
            print(f"    æœ€å°å€¤: {w_np.min():.6f}")
            print(f"    æœ€å¤§å€¤: {w_np.max():.6f}")

    # ç·šå½¢å¤‰æ›é‡ã¿ã®åˆ†æ
    for name, weights in linear_layers.items():
        if isinstance(weights, torch.Tensor) and len(weights.shape) == 2:
            w_np = weights.detach().numpy()
            print(f"\nğŸ“Š {name}:")
            print(f"    å½¢çŠ¶: {weights.shape}")
            print(f"    å…¥åŠ›æ¬¡å…ƒ: {weights.shape[1]}")
            print(f"    å‡ºåŠ›æ¬¡å…ƒ: {weights.shape[0]}")
            print(f"    é‡ã¿å¹³å‡: {w_np.mean():.6f}")
            print(f"    é‡ã¿æ¨™æº–åå·®: {w_np.std():.6f}")


def analyze_graph_structure():
    """ã‚°ãƒ©ãƒ•æ§‹é€ ã®åˆ†æ"""
    print(f"\nğŸ•¸ï¸ ã‚°ãƒ©ãƒ•æ§‹é€ åˆ†æ:")
    print("=" * 50)

    # å”åŠ›ã‚°ãƒ©ãƒ•ã®èª­ã¿è¾¼ã¿
    graph_path = Path("data/graph_collaborative.pt")
    if not graph_path.exists():
        print(f"âŒ å”åŠ›ã‚°ãƒ©ãƒ•ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {graph_path}")
        return None

    try:
        graph_data = torch.load(graph_path, map_location="cpu", weights_only=False)
        print(f"âœ… å”åŠ›ã‚°ãƒ©ãƒ•èª­ã¿è¾¼ã¿æˆåŠŸ")
        print(f"ğŸ“Š ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒ—: {type(graph_data)}")

        if hasattr(graph_data, "x"):
            print(f"  - ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡: {graph_data.x.shape}")
            print(f"  - ãƒãƒ¼ãƒ‰æ•°: {graph_data.x.shape[0]}")
            print(f"  - å„ãƒãƒ¼ãƒ‰ã®ç‰¹å¾´é‡æ¬¡å…ƒ: {graph_data.x.shape[1]}")

            # ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã®çµ±è¨ˆ
            node_features = graph_data.x.detach().numpy()
            print(f"  - ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡çµ±è¨ˆ:")
            print(f"    å¹³å‡: {node_features.mean():.6f}")
            print(f"    æ¨™æº–åå·®: {node_features.std():.6f}")
            print(f"    æœ€å°å€¤: {node_features.min():.6f}")
            print(f"    æœ€å¤§å€¤: {node_features.max():.6f}")

        if hasattr(graph_data, "edge_index"):
            edge_index = graph_data.edge_index
            print(f"  - ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {edge_index.shape}")
            print(f"  - ã‚¨ãƒƒã‚¸æ•°: {edge_index.shape[1]}")

            # ã‚¨ãƒƒã‚¸ã®åˆ†æ
            unique_nodes = torch.unique(edge_index).numpy()
            print(f"  - ã‚°ãƒ©ãƒ•ã«å«ã¾ã‚Œã‚‹ãƒãƒ¼ãƒ‰æ•°: {len(unique_nodes)}")

            # æ¬¡æ•°åˆ†æ
            from collections import Counter

            source_nodes = edge_index[0].numpy()
            target_nodes = edge_index[1].numpy()

            source_counts = Counter(source_nodes)
            target_counts = Counter(target_nodes)

            out_degrees = list(source_counts.values())
            in_degrees = list(target_counts.values())

            print(f"  - å‡ºæ¬¡æ•°çµ±è¨ˆ:")
            print(f"    å¹³å‡: {np.mean(out_degrees):.2f}")
            print(f"    æœ€å¤§: {max(out_degrees)}")
            print(f"    æœ€å°: {min(out_degrees)}")

            print(f"  - å…¥æ¬¡æ•°çµ±è¨ˆ:")
            print(f"    å¹³å‡: {np.mean(in_degrees):.2f}")
            print(f"    æœ€å¤§: {max(in_degrees)}")
            print(f"    æœ€å°: {min(in_degrees)}")

        if hasattr(graph_data, "edge_attr"):
            print(f"  - ã‚¨ãƒƒã‚¸å±æ€§: {graph_data.edge_attr.shape}")
            edge_attr = graph_data.edge_attr.detach().numpy()
            print(f"  - ã‚¨ãƒƒã‚¸å±æ€§çµ±è¨ˆ:")
            print(f"    å¹³å‡: {edge_attr.mean():.6f}")
            print(f"    æ¨™æº–åå·®: {edge_attr.std():.6f}")

        return graph_data

    except Exception as e:
        print(f"âŒ å”åŠ›ã‚°ãƒ©ãƒ•èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def visualize_gat_analysis(gat_model, graph_data, irl_weights):
    """GATåˆ†æã®å¯è¦–åŒ–"""
    print(f"\nğŸ“Š GATåˆ†æå¯è¦–åŒ–ç”Ÿæˆä¸­...")

    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))

    # 1. IRLé‡ã¿ã®GATéƒ¨åˆ†ã«ç„¦ç‚¹
    if len(irl_weights) > 25:
        gat_weights = irl_weights[25:]

        ax1.bar(range(len(gat_weights)), gat_weights, alpha=0.7)
        ax1.set_xlabel("GAT Feature Index")
        ax1.set_ylabel("IRL Weight")
        ax1.set_title("IRL Weights for GAT Features")
        ax1.grid(True, alpha=0.3)

        # é‡è¦ãªGATç‰¹å¾´é‡ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
        top_gat_indices = np.argsort(np.abs(gat_weights))[-5:]
        for idx in top_gat_indices:
            ax1.bar(idx, gat_weights[idx], color="red", alpha=0.8)

    # 2. ãƒãƒ¼ãƒ‰æ¬¡æ•°åˆ†å¸ƒï¼ˆã‚°ãƒ©ãƒ•æ§‹é€ ï¼‰
    if graph_data and hasattr(graph_data, "edge_index"):
        edge_index = graph_data.edge_index.numpy()
        degrees = np.bincount(edge_index.flatten())
        degrees = degrees[degrees > 0]  # 0æ¬¡æ•°ãƒãƒ¼ãƒ‰ã‚’é™¤å¤–

        ax2.hist(degrees, bins=30, alpha=0.7, edgecolor="black")
        ax2.set_xlabel("Node Degree")
        ax2.set_ylabel("Frequency")
        ax2.set_title("Node Degree Distribution")
        ax2.set_yscale("log")
        ax2.grid(True, alpha=0.3)

    # 3. GATå±¤ã®é‡ã¿åˆ†å¸ƒï¼ˆæœ€åˆã®ç·šå½¢å±¤ï¼‰
    if gat_model and isinstance(gat_model, dict):
        # æœ€åˆã®ç·šå½¢å±¤ã‚’æ¢ã™
        first_linear = None
        for name, param in gat_model.items():
            if (
                "lin" in name.lower()
                and "weight" in name
                and isinstance(param, torch.Tensor)
            ):
                first_linear = param.detach().numpy()
                break

        if first_linear is not None:
            ax3.hist(first_linear.flatten(), bins=50, alpha=0.7, edgecolor="black")
            ax3.set_xlabel("Weight Value")
            ax3.set_ylabel("Frequency")
            ax3.set_title("GAT Layer Weight Distribution")
            ax3.grid(True, alpha=0.3)

    # 4. GATç‰¹å¾´é‡ã®é‡è¦åº¦ï¼ˆIRLé‡ã¿ã®çµ¶å¯¾å€¤ï¼‰
    if len(irl_weights) > 25:
        gat_importance = np.abs(irl_weights[25:])
        cumsum_gat = np.cumsum(np.sort(gat_importance)[::-1])
        cumsum_gat_norm = cumsum_gat / cumsum_gat[-1] * 100

        ax4.plot(range(1, len(gat_importance) + 1), cumsum_gat_norm, "g-", linewidth=2)
        ax4.axhline(80, color="red", linestyle="--", alpha=0.7, label="80%")
        ax4.axhline(95, color="orange", linestyle="--", alpha=0.7, label="95%")
        ax4.set_xlabel("Number of GAT Features")
        ax4.set_ylabel("Cumulative Importance (%)")
        ax4.set_title("GAT Feature Importance (Cumulative)")
        ax4.legend()
        ax4.grid(True, alpha=0.3)

    plt.tight_layout()

    # ä¿å­˜
    output_path = (
        Path("outputs") / f"gat_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
    )
    output_path.parent.mkdir(exist_ok=True)
    plt.savefig(output_path, dpi=300, bbox_inches="tight")
    print(f"âœ… GATåˆ†æã‚°ãƒ©ãƒ•ä¿å­˜: {output_path}")
    plt.close()


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸ” GATç‰¹å¾´é‡è©³ç´°åˆ†æ")
    print(f"ğŸ“… å®Ÿè¡Œæ—¥æ™‚: {datetime.now()}")
    print("=" * 60)

    try:
        # GATãƒ¢ãƒ‡ãƒ«åˆ†æ
        gat_model = analyze_gat_embeddings()

        # ã‚°ãƒ©ãƒ•æ§‹é€ åˆ†æ
        graph_data = analyze_graph_structure()

        # IRLé‡ã¿ã®èª­ã¿è¾¼ã¿
        weights_path = Path("data/learned_weights_training.npy")
        irl_weights = None
        if weights_path.exists():
            irl_weights = np.load(weights_path)
            print(f"âœ… IRLé‡ã¿èª­ã¿è¾¼ã¿: {irl_weights.shape}")

        # å¯è¦–åŒ–
        if gat_model or graph_data or irl_weights is not None:
            visualize_gat_analysis(gat_model, graph_data, irl_weights)

        print(f"\nğŸ‰ GATåˆ†æå®Œäº†!")

    except Exception as e:
        print(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
