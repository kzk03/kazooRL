#!/usr/bin/env python3
"""
IRLé‡ã¿ã®è©³ç´°åˆ†æ - å„ç‰¹å¾´é‡ãŒä½•ã‚’è¡¨ã—ã¦ã„ã‚‹ã‹ã‚’åˆ†æ
"""

import sys
from datetime import datetime
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import torch

sys.path.append("src")


def get_feature_names_and_descriptions():
    """ç‰¹å¾´é‡åã¨èª¬æ˜ã®å¯¾å¿œã‚’å–å¾—"""

    # åŸºæœ¬ç‰¹å¾´é‡ï¼ˆ25æ¬¡å…ƒï¼‰
    base_features = [
        ("login_length", "ãƒ­ã‚°ã‚¤ãƒ³åã®é•·ã•"),
        ("name_exists", "åå‰ã®æœ‰ç„¡"),
        ("name_length", "åå‰ã®é•·ã•"),
        ("company_exists", "ä¼šç¤¾æƒ…å ±ã®æœ‰ç„¡"),
        ("company_length", "ä¼šç¤¾åã®é•·ã•"),
        ("location_exists", "å ´æ‰€æƒ…å ±ã®æœ‰ç„¡"),
        ("location_length", "å ´æ‰€æƒ…å ±ã®é•·ã•"),
        ("bio_exists", "ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æ–‡ã®æœ‰ç„¡"),
        ("bio_length", "ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æ–‡ã®é•·ã•"),
        ("public_repos", "å…¬é–‹ãƒªãƒã‚¸ãƒˆãƒªæ•°"),
        ("public_repos_log", "å…¬é–‹ãƒªãƒã‚¸ãƒˆãƒªæ•°ï¼ˆå¯¾æ•°ï¼‰"),
        ("followers", "ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°"),
        ("followers_log", "ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°ï¼ˆå¯¾æ•°ï¼‰"),
        ("following", "ãƒ•ã‚©ãƒ­ãƒ¼æ•°"),
        ("following_log", "ãƒ•ã‚©ãƒ­ãƒ¼æ•°ï¼ˆå¯¾æ•°ï¼‰"),
        ("account_age_days", "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå¹´æ•°ï¼ˆæ—¥ï¼‰"),
        ("account_age_years", "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå¹´æ•°ï¼ˆå¹´ï¼‰"),
        ("followers_following_ratio", "ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼/ãƒ•ã‚©ãƒ­ãƒ¼æ¯”"),
        ("repos_per_year", "å¹´é–“ãƒªãƒã‚¸ãƒˆãƒªä½œæˆæ•°"),
        ("popularity_score", "äººæ°—åº¦ã‚¹ã‚³ã‚¢"),
        ("activity_score", "æ´»å‹•åº¦ã‚¹ã‚³ã‚¢"),
        ("influence_score", "å½±éŸ¿åŠ›ã‚¹ã‚³ã‚¢"),
        ("experience_score", "çµŒé¨“å€¤ã‚¹ã‚³ã‚¢"),
        ("social_score", "ç¤¾äº¤æ€§ã‚¹ã‚³ã‚¢"),
        ("profile_completeness", "ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å®Œæˆåº¦"),
    ]

    # GATç‰¹å¾´é‡ï¼ˆ37æ¬¡å…ƒï¼‰
    gat_features = []
    for i in range(37):
        gat_features.append((f"gat_feature_{i}", f"GATç‰¹å¾´é‡{i}ï¼ˆå”åŠ›é–¢ä¿‚åŸ‹ã‚è¾¼ã¿ï¼‰"))

    return base_features + gat_features


def analyze_irl_weights_detailed():
    """IRLé‡ã¿ã®è©³ç´°åˆ†æ"""
    print("ğŸ¯ IRLé‡ã¿è©³ç´°åˆ†æ")
    print("=" * 60)

    # IRLé‡ã¿ã®èª­ã¿è¾¼ã¿
    weights_path = Path("data/learned_weights_training.npy")
    if not weights_path.exists():
        print(f"âŒ IRLé‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {weights_path}")
        return

    weights = np.load(weights_path)
    print(f"âœ… IRLé‡ã¿èª­ã¿è¾¼ã¿æˆåŠŸ: {weights.shape}")

    # ç‰¹å¾´é‡åã¨ãã®èª¬æ˜ã‚’å–å¾—
    feature_info = get_feature_names_and_descriptions()

    if len(weights) != len(feature_info):
        print(
            f"âš ï¸ é‡ã¿æ•°({len(weights)})ã¨ç‰¹å¾´é‡å®šç¾©æ•°({len(feature_info)})ãŒä¸€è‡´ã—ã¾ã›ã‚“"
        )
        # é‡ã¿ã®æ•°ã«åˆã‚ã›ã¦èª¿æ•´
        if len(weights) < len(feature_info):
            feature_info = feature_info[: len(weights)]
        else:
            # è¶³ã‚Šãªã„åˆ†ã¯æ±ç”¨çš„ãªåå‰ã§è£œå®Œ
            for i in range(len(feature_info), len(weights)):
                feature_info.append((f"unknown_feature_{i}", f"æœªå®šç¾©ç‰¹å¾´é‡{i}"))

    print(f"ğŸ“Š åˆ†æå¯¾è±¡ç‰¹å¾´é‡æ•°: {len(weights)}")

    # é‡ã¿ã®çµ±è¨ˆæƒ…å ±
    print(f"\nğŸ“ˆ é‡ã¿çµ±è¨ˆ:")
    print(f"  - å¹³å‡: {weights.mean():.6f}")
    print(f"  - æ¨™æº–åå·®: {weights.std():.6f}")
    print(f"  - æœ€å°å€¤: {weights.min():.6f}")
    print(f"  - æœ€å¤§å€¤: {weights.max():.6f}")

    # é‡è¦ãªç‰¹å¾´é‡ã®åˆ†æï¼ˆçµ¶å¯¾å€¤é †ï¼‰
    print(f"\nğŸ” é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆçµ¶å¯¾å€¤é †ï¼‰:")
    importance_indices = np.argsort(np.abs(weights))[::-1]  # é™é †

    print("é †ä½ | é‡ã¿å€¤    | ç‰¹å¾´é‡å                | èª¬æ˜")
    print("-" * 70)
    for rank, idx in enumerate(importance_indices[:15], 1):
        weight_val = weights[idx]
        feature_name, description = feature_info[idx]
        print(f"{rank:2d}ä½ | {weight_val:8.4f} | {feature_name:20s} | {description}")

    # æ­£ã®é‡ã¿ã¨è² ã®é‡ã¿ã®åˆ†æ
    positive_weights = weights[weights > 0]
    negative_weights = weights[weights < 0]
    zero_weights = weights[weights == 0]

    print(f"\nğŸ“Š é‡ã¿ã®ç¬¦å·åˆ†æ:")
    print(
        f"  - æ­£ã®é‡ã¿: {len(positive_weights)}å€‹ (å¹³å‡: {positive_weights.mean():.4f})"
    )
    print(
        f"  - è² ã®é‡ã¿: {len(negative_weights)}å€‹ (å¹³å‡: {negative_weights.mean():.4f})"
    )
    print(f"  - ã‚¼ãƒ­ã®é‡ã¿: {len(zero_weights)}å€‹")

    # æ­£ã®é‡ã¿ãƒˆãƒƒãƒ—10
    print(f"\nâœ… æ­£ã®å½±éŸ¿ãŒå¤§ãã„ç‰¹å¾´é‡ Top 10:")
    positive_indices = np.where(weights > 0)[0]
    positive_sorted = positive_indices[np.argsort(weights[positive_indices])[::-1]]

    for rank, idx in enumerate(positive_sorted[:10], 1):
        weight_val = weights[idx]
        feature_name, description = feature_info[idx]
        print(f"{rank:2d}. {weight_val:6.4f} | {feature_name:20s} | {description}")

    # è² ã®é‡ã¿ãƒˆãƒƒãƒ—10
    print(f"\nâŒ è² ã®å½±éŸ¿ãŒå¤§ãã„ç‰¹å¾´é‡ Top 10:")
    negative_indices = np.where(weights < 0)[0]
    negative_sorted = negative_indices[
        np.argsort(weights[negative_indices])
    ]  # æ˜‡é †ï¼ˆæœ€ã‚‚è² ã®å€¤ï¼‰

    for rank, idx in enumerate(negative_sorted[:10], 1):
        weight_val = weights[idx]
        feature_name, description = feature_info[idx]
        print(f"{rank:2d}. {weight_val:6.4f} | {feature_name:20s} | {description}")

    # ç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ
    analyze_by_category(weights, feature_info)

    # å¯è¦–åŒ–
    create_detailed_visualization(weights, feature_info)

    return weights, feature_info


def analyze_by_category(weights, feature_info):
    """ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®é‡ã¿åˆ†æ"""
    print(f"\nğŸ·ï¸ ã‚«ãƒ†ã‚´ãƒªåˆ¥é‡ã¿åˆ†æ:")
    print("-" * 50)

    # åŸºæœ¬ç‰¹å¾´é‡ vs GATç‰¹å¾´é‡
    base_weights = weights[:25]  # æœ€åˆã®25å€‹
    gat_weights = weights[25:] if len(weights) > 25 else np.array([])

    print(f"ğŸ“‹ åŸºæœ¬ç‰¹å¾´é‡ï¼ˆ25æ¬¡å…ƒï¼‰:")
    print(f"  - å¹³å‡é‡ã¿: {base_weights.mean():.4f}")
    print(f"  - æ¨™æº–åå·®: {base_weights.std():.4f}")
    print(f"  - æœ€å¤§å€¤: {base_weights.max():.4f}")
    print(f"  - æœ€å°å€¤: {base_weights.min():.4f}")

    if len(gat_weights) > 0:
        print(f"ğŸ§  GATç‰¹å¾´é‡ï¼ˆ{len(gat_weights)}æ¬¡å…ƒï¼‰:")
        print(f"  - å¹³å‡é‡ã¿: {gat_weights.mean():.4f}")
        print(f"  - æ¨™æº–åå·®: {gat_weights.std():.4f}")
        print(f"  - æœ€å¤§å€¤: {gat_weights.max():.4f}")
        print(f"  - æœ€å°å€¤: {gat_weights.min():.4f}")

    # ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªåˆ†æï¼ˆåŸºæœ¬ç‰¹å¾´é‡å†…ã§ï¼‰
    categories = {
        "ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±": list(range(0, 9)),  # loginï½bioé–¢é€£
        "æ´»å‹•æŒ‡æ¨™": list(range(9, 17)),  # repos, followers, followingé–¢é€£
        "è¨ˆç®—æ¸ˆã¿æŒ‡æ¨™": list(range(17, 25)),  # ratio, scoreé–¢é€£
    }

    for cat_name, indices in categories.items():
        if max(indices) < len(weights):
            cat_weights = weights[indices]
            print(f"\nğŸ“Š {cat_name}:")
            print(f"  - å¹³å‡é‡ã¿: {cat_weights.mean():.4f}")
            print(f"  - é‡è¦åº¦ä¸Šä½:")
            sorted_indices = np.argsort(np.abs(cat_weights))[::-1]
            for i, idx in enumerate(sorted_indices[:3]):
                global_idx = indices[idx]
                feature_name, description = feature_info[global_idx]
                print(f"    {i+1}. {weights[global_idx]:6.4f} | {feature_name}")


def create_detailed_visualization(weights, feature_info):
    """è©³ç´°ãªå¯è¦–åŒ–"""
    print(f"\nğŸ“Š å¯è¦–åŒ–ã‚°ãƒ©ãƒ•ç”Ÿæˆä¸­...")

    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))

    # 1. é‡ã¿å€¤ã®æ£’ã‚°ãƒ©ãƒ•ï¼ˆä¸Šä½20ï¼‰
    top_20_indices = np.argsort(np.abs(weights))[-20:]
    top_20_weights = weights[top_20_indices]
    top_20_names = [feature_info[i][0] for i in top_20_indices]

    colors = ["red" if w < 0 else "blue" for w in top_20_weights]
    bars = ax1.barh(range(len(top_20_weights)), top_20_weights, color=colors, alpha=0.7)
    ax1.set_yticks(range(len(top_20_weights)))
    ax1.set_yticklabels(
        [name[:15] + "..." if len(name) > 15 else name for name in top_20_names],
        fontsize=8,
    )
    ax1.set_xlabel("Weight Value")
    ax1.set_title("Top 20 Features by Absolute Weight")
    ax1.grid(True, alpha=0.3)

    # 2. åŸºæœ¬ç‰¹å¾´é‡ vs GATç‰¹å¾´é‡ã®æ¯”è¼ƒ
    base_weights = weights[:25]
    gat_weights = weights[25:] if len(weights) > 25 else np.array([])

    categories = ["Base Features"]
    means = [base_weights.mean()]
    stds = [base_weights.std()]

    if len(gat_weights) > 0:
        categories.append("GAT Features")
        means.append(gat_weights.mean())
        stds.append(gat_weights.std())

    x_pos = np.arange(len(categories))
    ax2.bar(
        x_pos,
        means,
        yerr=stds,
        capsize=5,
        alpha=0.7,
        color=["skyblue", "lightcoral"][: len(categories)],
    )
    ax2.set_xticks(x_pos)
    ax2.set_xticklabels(categories)
    ax2.set_ylabel("Mean Weight")
    ax2.set_title("Feature Category Comparison")
    ax2.grid(True, alpha=0.3)

    # 3. é‡ã¿ã®åˆ†å¸ƒãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
    ax3.hist(weights, bins=30, alpha=0.7, edgecolor="black")
    ax3.axvline(
        weights.mean(), color="red", linestyle="--", label=f"Mean: {weights.mean():.3f}"
    )
    ax3.axvline(0, color="black", linestyle="-", alpha=0.5, label="Zero")
    ax3.set_xlabel("Weight Value")
    ax3.set_ylabel("Frequency")
    ax3.set_title("Weight Distribution")
    ax3.legend()
    ax3.grid(True, alpha=0.3)

    # 4. é‡ã¿ã®ç´¯ç©åˆ†å¸ƒ
    sorted_abs_weights = np.sort(np.abs(weights))[::-1]
    cumsum_weights = np.cumsum(sorted_abs_weights)
    cumsum_normalized = cumsum_weights / cumsum_weights[-1] * 100

    ax4.plot(range(1, len(weights) + 1), cumsum_normalized, "b-", linewidth=2)
    ax4.axhline(80, color="red", linestyle="--", alpha=0.7, label="80% threshold")
    ax4.axhline(95, color="orange", linestyle="--", alpha=0.7, label="95% threshold")
    ax4.set_xlabel("Number of Features")
    ax4.set_ylabel("Cumulative Importance (%)")
    ax4.set_title("Cumulative Feature Importance")
    ax4.legend()
    ax4.grid(True, alpha=0.3)

    # é‡è¦åº¦80%ã‚’å ã‚ã‚‹ç‰¹å¾´é‡æ•°ã‚’è¨ˆç®—
    threshold_80_idx = np.where(cumsum_normalized >= 80)[0][0] + 1
    threshold_95_idx = np.where(cumsum_normalized >= 95)[0][0] + 1
    ax4.axvline(threshold_80_idx, color="red", linestyle=":", alpha=0.7)
    ax4.axvline(threshold_95_idx, color="orange", linestyle=":", alpha=0.7)

    plt.tight_layout()

    # ä¿å­˜
    output_path = (
        Path("outputs")
        / f"irl_detailed_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
    )
    output_path.parent.mkdir(exist_ok=True)
    plt.savefig(output_path, dpi=300, bbox_inches="tight")
    print(f"âœ… è©³ç´°åˆ†æã‚°ãƒ©ãƒ•ä¿å­˜: {output_path}")
    plt.close()

    print(f"\nğŸ’¡ é‡è¦åº¦åˆ†æçµæœ:")
    print(f"  - é‡è¦åº¦80%ã‚’å ã‚ã‚‹ç‰¹å¾´é‡æ•°: {threshold_80_idx}/{len(weights)}")
    print(f"  - é‡è¦åº¦95%ã‚’å ã‚ã‚‹ç‰¹å¾´é‡æ•°: {threshold_95_idx}/{len(weights)}")


def interpret_results(weights, feature_info):
    """çµæœã®è§£é‡ˆ"""
    print(f"\nğŸ§  IRLé‡ã¿çµæœã®è§£é‡ˆ:")
    print("=" * 60)

    # æœ€ã‚‚å½±éŸ¿åŠ›ã®å¤§ãã„ç‰¹å¾´é‡
    top_positive_idx = np.argmax(weights)
    top_negative_idx = np.argmin(weights)

    print(f"ğŸ” æœ€ã‚‚æ­£ã®å½±éŸ¿ãŒå¤§ãã„ç‰¹å¾´é‡:")
    feature_name, description = feature_info[top_positive_idx]
    print(f"   {feature_name} ({weights[top_positive_idx]:.4f})")
    print(f"   â†’ {description}")
    print(f"   â†’ é–‹ç™ºè€…é¸æŠã«ãŠã„ã¦å¼·ãå„ªå…ˆã•ã‚Œã‚‹è¦ç´ ")

    print(f"\nğŸ”» æœ€ã‚‚è² ã®å½±éŸ¿ãŒå¤§ãã„ç‰¹å¾´é‡:")
    feature_name, description = feature_info[top_negative_idx]
    print(f"   {feature_name} ({weights[top_negative_idx]:.4f})")
    print(f"   â†’ {description}")
    print(f"   â†’ é–‹ç™ºè€…é¸æŠã«ãŠã„ã¦é¿ã‘ã‚‰ã‚Œã‚‹è¦ç´ ")

    # GATç‰¹å¾´é‡ã®å½±éŸ¿
    if len(weights) > 25:
        gat_weights = weights[25:]
        gat_importance = np.mean(np.abs(gat_weights))
        base_importance = np.mean(np.abs(weights[:25]))

        print(f"\nğŸ¤ å”åŠ›é–¢ä¿‚ï¼ˆGATï¼‰ã®å½±éŸ¿åº¦:")
        print(f"   åŸºæœ¬ç‰¹å¾´é‡ã®å¹³å‡é‡è¦åº¦: {base_importance:.4f}")
        print(f"   GATç‰¹å¾´é‡ã®å¹³å‡é‡è¦åº¦: {gat_importance:.4f}")

        if gat_importance > base_importance:
            print(f"   â†’ å”åŠ›é–¢ä¿‚æƒ…å ±ãŒé–‹ç™ºè€…é¸æŠã«ã‚ˆã‚Šå¼·ãå½±éŸ¿ã—ã¦ã„ã‚‹")
        else:
            print(f"   â†’ åŸºæœ¬çš„ãªé–‹ç™ºè€…å±æ€§ãŒã‚ˆã‚Šé‡è¦")

    # å®Ÿç”¨çš„ãªç¤ºå”†
    print(f"\nğŸ’¼ å®Ÿç”¨çš„ãªç¤ºå”†:")

    # æ­£ã®é‡ã¿ãŒå¤§ãã„ç‰¹å¾´é‡ã‹ã‚‰ç¤ºå”†ã‚’å°å‡º
    positive_indices = np.where(weights > 0)[0]
    top_positive = positive_indices[np.argsort(weights[positive_indices])[-5:]]

    print(f"   å„ªå…ˆã•ã‚Œã‚‹é–‹ç™ºè€…ç‰¹æ€§:")
    for idx in reversed(top_positive):
        feature_name, description = feature_info[idx]
        print(f"   âœ… {description} (é‡ã¿: {weights[idx]:.3f})")

    # è² ã®é‡ã¿ãŒå¤§ãã„ç‰¹å¾´é‡ã‹ã‚‰ç¤ºå”†ã‚’å°å‡º
    negative_indices = np.where(weights < 0)[0]
    if len(negative_indices) > 0:
        top_negative = negative_indices[np.argsort(weights[negative_indices])[:5]]

        print(f"\n   é¿ã‘ã‚‰ã‚Œã‚‹å‚¾å‘ãŒã‚ã‚‹ç‰¹æ€§:")
        for idx in top_negative:
            feature_name, description = feature_info[idx]
            print(f"   âŒ {description} (é‡ã¿: {weights[idx]:.3f})")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸ” IRLé‡ã¿è©³ç´°åˆ†æ")
    print(f"ğŸ“… å®Ÿè¡Œæ—¥æ™‚: {datetime.now()}")
    print("=" * 60)

    try:
        weights, feature_info = analyze_irl_weights_detailed()
        interpret_results(weights, feature_info)

        print(f"\nğŸ‰ åˆ†æå®Œäº†!")
        print(f"ğŸ“Š åˆ†æçµæœ:")
        print(f"   - ç·ç‰¹å¾´é‡æ•°: {len(weights)}")
        print(f"   - æœ‰æ„ãªé‡ã¿æ•°: {np.sum(np.abs(weights) > 0.01)}")
        print(f"   - æ­£ã®é‡ã¿æ•°: {np.sum(weights > 0)}")
        print(f"   - è² ã®é‡ã¿æ•°: {np.sum(weights < 0)}")

    except Exception as e:
        print(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
