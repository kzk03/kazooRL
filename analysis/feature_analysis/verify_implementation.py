#!/usr/bin/env python3
"""
ç‰¹å¾´é‡åˆ†æåŸºç›¤ã®å®Ÿè£…ç¢ºèª
======================

å®Ÿè£…ã—ãŸã‚¯ãƒ©ã‚¹ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã‹ã‚’ç¢ºèªã—ã¾ã™ã€‚
"""

import sys
from pathlib import Path

import numpy as np

# ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿½åŠ 
sys.path.append(str(Path(__file__).parent))


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸš€ ç‰¹å¾´é‡åˆ†æåŸºç›¤å®Ÿè£…ç¢ºèªé–‹å§‹")
    print("=" * 60)

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    n_samples, n_features = 100, 10
    feature_data = np.random.randn(n_samples, n_features)
    feature_names = [
        (
            f"task_feature_{i}"
            if i < 3
            else f"dev_feature_{i}" if i < 6 else f"match_feature_{i}"
        )
        for i in range(n_features)
    ]
    weights = np.random.randn(n_features) * 0.5

    print(f"âœ… ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {feature_data.shape}")

    # é‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    weights_path = "test_weights.npy"
    np.save(weights_path, weights)

    try:
        # 1. FeatureImportanceAnalyzer ã®ãƒ†ã‚¹ãƒˆ
        print("\nğŸ“Š FeatureImportanceAnalyzer ãƒ†ã‚¹ãƒˆ")
        print("-" * 40)

        from feature_importance_analyzer import FeatureImportanceAnalyzer

        importance_analyzer = FeatureImportanceAnalyzer(weights_path, feature_names)
        print("âœ… åˆæœŸåŒ–æˆåŠŸ")

        importance_results = importance_analyzer.analyze_importance()
        print(f"âœ… é‡è¦åº¦åˆ†æå®Œäº†")
        print(
            f"   - é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°: {len(importance_results['importance_ranking'])}é …ç›®"
        )
        print(
            f"   - ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ: {len(importance_results['category_importance'])}ã‚«ãƒ†ã‚´ãƒª"
        )

        # TOP3ã‚’è¡¨ç¤º
        print("   é‡è¦åº¦TOP3:")
        for i, (name, weight, importance) in enumerate(
            importance_results["importance_ranking"][:3], 1
        ):
            print(
                f"     {i}. {name:20s} | é‡ã¿:{weight:6.3f} | é‡è¦åº¦:{importance:6.3f}"
            )

        # 2. FeatureCorrelationAnalyzer ã®ãƒ†ã‚¹ãƒˆ
        print("\nğŸ”— FeatureCorrelationAnalyzer ãƒ†ã‚¹ãƒˆ")
        print("-" * 40)

        from feature_correlation_analyzer import FeatureCorrelationAnalyzer

        correlation_analyzer = FeatureCorrelationAnalyzer(feature_data, feature_names)
        print("âœ… åˆæœŸåŒ–æˆåŠŸ")

        correlation_results = correlation_analyzer.analyze_correlations(
            correlation_threshold=0.3
        )
        print(f"âœ… ç›¸é–¢åˆ†æå®Œäº†")
        print(f"   - ç›¸é–¢è¡Œåˆ—: {correlation_results['correlation_matrix'].shape}")
        print(
            f"   - é«˜ç›¸é–¢ãƒšã‚¢: {len(correlation_results['high_correlation_pairs'])}ãƒšã‚¢"
        )
        print(
            f"   - å†—é•·ç‰¹å¾´é‡å€™è£œ: {len(correlation_results['redundant_features'])}å€‹"
        )

        # 3. FeatureDistributionAnalyzer ã®ãƒ†ã‚¹ãƒˆ
        print("\nğŸ“ˆ FeatureDistributionAnalyzer ãƒ†ã‚¹ãƒˆ")
        print("-" * 40)

        from feature_distribution_analyzer import FeatureDistributionAnalyzer

        distribution_analyzer = FeatureDistributionAnalyzer(feature_data, feature_names)
        print("âœ… åˆæœŸåŒ–æˆåŠŸ")

        distribution_results = distribution_analyzer.analyze_distributions()
        print(f"âœ… åˆ†å¸ƒåˆ†æå®Œäº†")
        print(f"   - åˆ†å¸ƒçµ±è¨ˆ: {len(distribution_results['distribution_stats'])}ç‰¹å¾´é‡")
        print(f"   - æ­£è¦æ€§æ¤œå®š: {len(distribution_results['normality_tests'])}ç‰¹å¾´é‡")
        print(
            f"   - å¤–ã‚Œå€¤æ¤œå‡º: {len(distribution_results['outlier_detection'])}ç‰¹å¾´é‡"
        )

        # ã‚¹ã‚±ãƒ¼ãƒ«ä¸å‡è¡¡æƒ…å ±
        scale_info = distribution_results["scale_imbalance"]
        print(f"   - æ¨™æº–åå·®æ¯”ï¼ˆæœ€å¤§/æœ€å°ï¼‰: {scale_info['std_ratio_max_min']:.2f}")

        print("\nğŸ‰ å…¨ã¦ã®å®Ÿè£…ç¢ºèªå®Œäº†ï¼")
        print("=" * 60)
        print("âœ… FeatureImportanceAnalyzer: å‹•ä½œç¢ºèªæ¸ˆã¿")
        print("âœ… FeatureCorrelationAnalyzer: å‹•ä½œç¢ºèªæ¸ˆã¿")
        print("âœ… FeatureDistributionAnalyzer: å‹•ä½œç¢ºèªæ¸ˆã¿")
        print("\nğŸ“ è¦ä»¶1.1, 1.2, 1.3ã®å®Ÿè£…ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

        return True

    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback

        traceback.print_exc()
        return False

    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        Path(weights_path).unlink(missing_ok=True)


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
