#!/usr/bin/env python3
"""
GATåŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®è§£é‡ˆå¯èƒ½æ€§åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import sys
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import torch
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "..", "src"))

from kazoo.features.gnn_feature_extractor import GNNFeatureExtractor


def load_gat_embeddings():
    """GATåŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    try:
        # è¨­å®šã‚’ç°¡æ˜“çš„ã«ä½œæˆ
        class SimpleConfig:
            def __init__(self):
                self.irl = SimpleConfig()
                self.irl.use_gat = True
                self.irl.gat_graph_path = "data/graph.pt"
                self.irl.gat_model_path = "data/gat_model_unified.pt"

        cfg = SimpleConfig()

        # GATç‰¹å¾´é‡æŠ½å‡ºå™¨ã‚’åˆæœŸåŒ–
        extractor = GNNFeatureExtractor(cfg)

        if not extractor.model or not extractor.embeddings:
            print("âŒ GATç‰¹å¾´é‡æŠ½å‡ºå™¨ã®åˆæœŸåŒ–ã«å¤±æ•—")
            return None, None, None

        dev_embeddings = extractor.embeddings["dev"].detach().cpu().numpy()
        task_embeddings = extractor.embeddings["task"].detach().cpu().numpy()

        return dev_embeddings, task_embeddings, extractor

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return None, None, None


def analyze_embedding_dimensions(embeddings, name="GATåŸ‹ã‚è¾¼ã¿"):
    """åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒåˆ†æ"""
    print(f"\n=== {name}ã®æ¬¡å…ƒåˆ†æ ===")

    # åŸºæœ¬çµ±è¨ˆ
    print(f"å½¢çŠ¶: {embeddings.shape}")
    print(f"å¹³å‡å€¤: {np.mean(embeddings, axis=0)[:5]}... (æœ€åˆã®5æ¬¡å…ƒ)")
    print(f"æ¨™æº–åå·®: {np.std(embeddings, axis=0)[:5]}... (æœ€åˆã®5æ¬¡å…ƒ)")
    print(f"æœ€å°å€¤: {np.min(embeddings)}")
    print(f"æœ€å¤§å€¤: {np.max(embeddings)}")

    # æ¬¡å…ƒé–“ã®ç›¸é–¢åˆ†æ
    corr_matrix = np.corrcoef(embeddings.T)
    high_corr_pairs = []

    for i in range(corr_matrix.shape[0]):
        for j in range(i + 1, corr_matrix.shape[1]):
            if abs(corr_matrix[i, j]) > 0.7:  # é«˜ã„ç›¸é–¢
                high_corr_pairs.append((i, j, corr_matrix[i, j]))

    print(f"é«˜ç›¸é–¢ãƒšã‚¢æ•° (|r| > 0.7): {len(high_corr_pairs)}")
    if high_corr_pairs:
        print("é«˜ç›¸é–¢ãƒšã‚¢ï¼ˆä¸Šä½5å€‹ï¼‰:")
        for i, j, corr in sorted(
            high_corr_pairs, key=lambda x: abs(x[2]), reverse=True
        )[:5]:
            print(f"  æ¬¡å…ƒ{i} - æ¬¡å…ƒ{j}: r={corr:.3f}")


def visualize_embeddings_2d(dev_embeddings, task_embeddings, output_dir="outputs"):
    """åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®2æ¬¡å…ƒå¯è¦–åŒ–"""
    print("\n=== 2æ¬¡å…ƒå¯è¦–åŒ–ã®ç”Ÿæˆ ===")

    os.makedirs(output_dir, exist_ok=True)

    # PCA
    print("PCAå®Ÿè¡Œä¸­...")
    pca = PCA(n_components=2)
    all_embeddings = np.vstack([dev_embeddings, task_embeddings])
    pca_result = pca.fit_transform(all_embeddings)

    dev_pca = pca_result[: len(dev_embeddings)]
    task_pca = pca_result[len(dev_embeddings) :]

    plt.figure(figsize=(12, 5))

    # PCAãƒ—ãƒ­ãƒƒãƒˆ
    plt.subplot(1, 2, 1)
    plt.scatter(dev_pca[:, 0], dev_pca[:, 1], alpha=0.6, label="é–‹ç™ºè€…", s=20)
    plt.scatter(task_pca[:, 0], task_pca[:, 1], alpha=0.6, label="ã‚¿ã‚¹ã‚¯", s=20)
    plt.xlabel(f"PC1 (åˆ†æ•£æ¯”: {pca.explained_variance_ratio_[0]:.2f})")
    plt.ylabel(f"PC2 (åˆ†æ•£æ¯”: {pca.explained_variance_ratio_[1]:.2f})")
    plt.title("GATåŸ‹ã‚è¾¼ã¿ - PCA")
    plt.legend()
    plt.grid(True, alpha=0.3)

    # t-SNEï¼ˆã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’åˆ¶é™ï¼‰
    print("t-SNEå®Ÿè¡Œä¸­...")
    sample_size = min(500, len(all_embeddings))  # è¨ˆç®—æ™‚é–“ã‚’çŸ­ç¸®
    sample_indices = np.random.choice(len(all_embeddings), sample_size, replace=False)
    sample_embeddings = all_embeddings[sample_indices]

    tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, sample_size // 4))
    tsne_result = tsne.fit_transform(sample_embeddings)

    dev_indices = sample_indices[sample_indices < len(dev_embeddings)]
    task_indices = sample_indices[sample_indices >= len(dev_embeddings)] - len(
        dev_embeddings
    )

    plt.subplot(1, 2, 2)
    if len(dev_indices) > 0:
        dev_tsne_indices = np.where(sample_indices < len(dev_embeddings))[0]
        plt.scatter(
            tsne_result[dev_tsne_indices, 0],
            tsne_result[dev_tsne_indices, 1],
            alpha=0.6,
            label="é–‹ç™ºè€…",
            s=20,
        )

    if len(task_indices) > 0:
        task_tsne_indices = np.where(sample_indices >= len(dev_embeddings))[0]
        plt.scatter(
            tsne_result[task_tsne_indices, 0],
            tsne_result[task_tsne_indices, 1],
            alpha=0.6,
            label="ã‚¿ã‚¹ã‚¯",
            s=20,
        )

    plt.xlabel("t-SNE 1")
    plt.ylabel("t-SNE 2")
    plt.title("GATåŸ‹ã‚è¾¼ã¿ - t-SNE")
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(f"{output_dir}/gat_embeddings_2d.png", dpi=300, bbox_inches="tight")
    plt.close()

    print(f"âœ… 2æ¬¡å…ƒå¯è¦–åŒ–ã‚’ä¿å­˜: {output_dir}/gat_embeddings_2d.png")

    return pca


def analyze_dimension_importance(pca, embeddings, top_n=10):
    """PCAæˆåˆ†ã«ã‚ˆã‚‹æ¬¡å…ƒé‡è¦åº¦åˆ†æ"""
    print(f"\n=== æ¬¡å…ƒé‡è¦åº¦åˆ†æï¼ˆä¸Šä½{top_n}æ¬¡å…ƒï¼‰ ===")

    # ç¬¬1ä¸»æˆåˆ†ã¸ã®è²¢çŒ®åº¦
    pc1_importance = np.abs(pca.components_[0])
    top_dims_pc1 = np.argsort(pc1_importance)[-top_n:][::-1]

    print("ç¬¬1ä¸»æˆåˆ†ã¸ã®è²¢çŒ®åº¦ãŒé«˜ã„æ¬¡å…ƒ:")
    for i, dim in enumerate(top_dims_pc1):
        print(f"  {i+1}. gat_dev_emb_{dim}: {pc1_importance[dim]:.3f}")

    # ç¬¬2ä¸»æˆåˆ†ã¸ã®è²¢çŒ®åº¦
    pc2_importance = np.abs(pca.components_[1])
    top_dims_pc2 = np.argsort(pc2_importance)[-top_n:][::-1]

    print("\nç¬¬2ä¸»æˆåˆ†ã¸ã®è²¢çŒ®åº¦ãŒé«˜ã„æ¬¡å…ƒ:")
    for i, dim in enumerate(top_dims_pc2):
        print(f"  {i+1}. gat_dev_emb_{dim}: {pc2_importance[dim]:.3f}")


def create_interpretability_report(dev_embeddings, task_embeddings):
    """è§£é‡ˆå¯èƒ½æ€§ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
    print("\n=== è§£é‡ˆå¯èƒ½æ€§ãƒ¬ãƒãƒ¼ãƒˆ ===")

    # çµ±è¨ˆçš„è¦ç´„
    print("ğŸ“Š çµ±è¨ˆçš„è¦ç´„:")
    print(
        f"  - é–‹ç™ºè€…åŸ‹ã‚è¾¼ã¿: {dev_embeddings.shape[0]}å€‹ Ã— {dev_embeddings.shape[1]}æ¬¡å…ƒ"
    )
    print(
        f"  - ã‚¿ã‚¹ã‚¯åŸ‹ã‚è¾¼ã¿: {task_embeddings.shape[0]}å€‹ Ã— {task_embeddings.shape[1]}æ¬¡å…ƒ"
    )

    # åˆ†æ•£ã®èª¬æ˜
    total_var_dev = np.var(dev_embeddings, axis=0).sum()
    print(f"  - é–‹ç™ºè€…åŸ‹ã‚è¾¼ã¿ã®ç·åˆ†æ•£: {total_var_dev:.2f}")

    # æ¬¡å…ƒã®æ´»ç”¨åº¦
    zero_dims_dev = np.sum(np.std(dev_embeddings, axis=0) < 0.01)
    print(f"  - ã»ã¼ä½¿ã‚ã‚Œã¦ã„ãªã„æ¬¡å…ƒ: {zero_dims_dev}/32")

    # è§£é‡ˆã®é›£ã—ã•
    print("\nğŸ¤” è§£é‡ˆå¯èƒ½æ€§:")
    print("  - å„æ¬¡å…ƒã®ç›´æ¥çš„ãªæ„å‘³: âŒ ä¸æ˜ï¼ˆãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ï¼‰")
    print("  - çµ±è¨ˆçš„ç‰¹å¾´é‡: âœ… ç†è§£å¯èƒ½")
    print("  - 2æ¬¡å…ƒå¯è¦–åŒ–: âœ… å…¨ä½“çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã¯è¦³å¯Ÿå¯èƒ½")
    print("  - ä¸»æˆåˆ†åˆ†æ: âœ… é‡è¦ãªæ¬¡å…ƒã®ç‰¹å®šã¯å¯èƒ½")

    print("\nğŸ’¡ æ¨å¥¨äº‹é …:")
    print("  1. ç›´æ¥çš„ãªè§£é‡ˆã§ã¯ãªãã€çµ±è¨ˆçš„ç‰¹å¾´é‡ã‚’æ´»ç”¨")
    print("  2. ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ç™ºè¦‹")
    print("  3. é¡ä¼¼åº¦è¨ˆç®—ã«ã‚ˆã‚‹ç›¸å¯¾çš„ãªæ¯”è¼ƒ")
    print("  4. ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç ”ç©¶ã«ã‚ˆã‚‹é‡è¦åº¦åˆ†æ")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ” GATåŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®è§£é‡ˆå¯èƒ½æ€§åˆ†æ")

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    dev_embeddings, task_embeddings, extractor = load_gat_embeddings()

    if dev_embeddings is None:
        print("âŒ ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return

    # æ¬¡å…ƒåˆ†æ
    analyze_embedding_dimensions(dev_embeddings, "é–‹ç™ºè€…åŸ‹ã‚è¾¼ã¿")
    analyze_embedding_dimensions(task_embeddings, "ã‚¿ã‚¹ã‚¯åŸ‹ã‚è¾¼ã¿")

    # 2æ¬¡å…ƒå¯è¦–åŒ–
    pca = visualize_embeddings_2d(dev_embeddings, task_embeddings)

    # é‡è¦åº¦åˆ†æ
    analyze_dimension_importance(pca, dev_embeddings)

    # è§£é‡ˆå¯èƒ½æ€§ãƒ¬ãƒãƒ¼ãƒˆ
    create_interpretability_report(dev_embeddings, task_embeddings)

    print("\nâœ… åˆ†æå®Œäº†ï¼")


if __name__ == "__main__":
    main()
