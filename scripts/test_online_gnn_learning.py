#!/usr/bin/env python3

"""
ã‚ªãƒ³ãƒ©ã‚¤ãƒ³GNNå­¦ç¿’ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å¼·åŒ–å­¦ç¿’ã®ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«GNNãŒæ›´æ–°ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
"""

import sys
from pathlib import Path

# Add project root to Python path
project_root = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(project_root / "src"))

import json

import hydra
import numpy as np
import yaml
from omegaconf import DictConfig

from kazoo.envs.oss_simple import OSSSimpleEnv
from kazoo.features.feature_extractor import FeatureExtractor


def test_online_gnn_learning():
    """ã‚ªãƒ³ãƒ©ã‚¤ãƒ³GNNå­¦ç¿’ã‚’ãƒ†ã‚¹ãƒˆ"""
    
    print("ğŸ§ª ã‚ªãƒ³ãƒ©ã‚¤ãƒ³GNNå­¦ç¿’ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)
    
    # è¨­å®šã‚’èª­ã¿è¾¼ã¿
    with hydra.initialize(config_path="../configs", version_base=None):
        cfg = hydra.compose(config_name="base")
    
    # ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã‚’æœ‰åŠ¹åŒ–
    cfg.irl.online_gnn_learning = True
    cfg.irl.gnn_update_frequency = 10  # ãƒ†ã‚¹ãƒˆç”¨ã«é »ç¹ã«æ›´æ–°
    
    print(f"ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’è¨­å®š:")
    print(f"  æœ‰åŠ¹: {cfg.irl.online_gnn_learning}")
    print(f"  æ›´æ–°é »åº¦: {cfg.irl.gnn_update_frequency}ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨")
    print(f"  å­¦ç¿’ç‡: {cfg.irl.gnn_learning_rate}")
    print(f"  ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º: {cfg.irl.gnn_buffer_size}")
    print()
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    with open(cfg.env.backlog_path, 'r') as f:
        backlog = json.load(f)
    
    with open(cfg.env.dev_profiles_path, 'r') as f:
        dev_profiles = yaml.safe_load(f)
    
    # äººé–“ã®é–‹ç™ºè€…ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
    human_devs = {name: profile for name, profile in dev_profiles.items() 
                  if 'bot' not in name.lower()}
    
    print(f"ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ:")
    print(f"  ã‚¿ã‚¹ã‚¯æ•°: {len(backlog)}")
    print(f"  äººé–“é–‹ç™ºè€…æ•°: {len(human_devs)}")
    print()
    
    # ç’°å¢ƒã¨ç‰¹å¾´é‡æŠ½å‡ºå™¨ã‚’åˆæœŸåŒ–
    print("ç’°å¢ƒã‚’åˆæœŸåŒ–ä¸­...")
    env = OSSSimpleEnv(cfg, backlog[:100], human_devs)  # ãƒ†ã‚¹ãƒˆç”¨ã«100ã‚¿ã‚¹ã‚¯ã«åˆ¶é™
    feature_extractor = FeatureExtractor(cfg)
    
    if not feature_extractor.gnn_extractor:
        print("âŒ GNNç‰¹å¾´é‡æŠ½å‡ºå™¨ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        return
    
    if not feature_extractor.gnn_extractor.online_learning:
        print("âŒ ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ãŒæœ‰åŠ¹ã«ãªã£ã¦ã„ã¾ã›ã‚“") 
        return
    
    print("âœ… ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’å¯¾å¿œGNNåˆæœŸåŒ–å®Œäº†")
    print()
    
    # åˆæœŸçµ±è¨ˆã‚’è¨˜éŒ²
    print("ğŸ“Š åˆæœŸçµ±è¨ˆ:")
    feature_extractor.gnn_extractor.print_statistics()
    
    # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
    print("\nğŸ® ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹...")
    
    obs, info = env.reset()
    developer_names = list(human_devs.keys())
    
    for step in range(100):  # 100ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ
        # ãƒ©ãƒ³ãƒ€ãƒ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        actions = {}
        for agent_id in env.agent_ids:
            if env.backlog:  # ãƒãƒƒã‚¯ãƒ­ã‚°ã«ã‚¿ã‚¹ã‚¯ãŒã‚ã‚Œã°
                action = np.random.randint(0, min(len(env.backlog), 5))  # ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
            else:
                action = len(env.initial_backlog)  # NO_OP
            actions[agent_id] = action
        
        # ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ
        obs, rewards, terminated, truncated, info = env.step(actions)
        
        # å ±é…¬ãŒã‚ã£ãŸå ´åˆã®çµ±è¨ˆ
        total_reward = sum(rewards.values())
        if total_reward != 0:
            print(f"  Step {step}: Total reward = {total_reward:.3f}")
        
        # 10ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«çµ±è¨ˆè¡¨ç¤º
        if (step + 1) % 20 == 0:
            print(f"\n--- Step {step + 1} çµ±è¨ˆ ---")
            feature_extractor.gnn_extractor.print_statistics()
        
        # çµ‚äº†æ¡ä»¶
        if all(terminated.values()) or all(truncated.values()):
            print(f"ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº† (Step {step})")
            break
    
    # æœ€çµ‚çµ±è¨ˆ
    print("\nğŸ“ˆ æœ€çµ‚çµ±è¨ˆ:")
    feature_extractor.gnn_extractor.print_statistics()
    
    # æ›´æ–°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
    if feature_extractor.gnn_extractor.stats["updates"] > 0:
        print("\nğŸ’¾ æ›´æ–°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ä¸­...")
        feature_extractor.gnn_extractor.save_updated_model()
        print("âœ… ä¿å­˜å®Œäº†")
    else:
        print("\nâš ï¸ GNNã®æ›´æ–°ãŒç™ºç”Ÿã—ã¾ã›ã‚“ã§ã—ãŸ")
    
    # æ–°ã—ã„é–‹ç™ºè€…/ã‚¿ã‚¹ã‚¯ã®è¿½åŠ ãƒ†ã‚¹ãƒˆ
    print("\nğŸ†• æ–°ã—ã„ãƒãƒ¼ãƒ‰è¿½åŠ ãƒ†ã‚¹ãƒˆ...")
    
    new_developers = {
        "test_new_dev": {
            "skills": ["python", "testing"],
            "touched_files": ["test.py"],
            "label_affinity": {"bug": 0.8, "enhancement": 0.5}
        }
    }
    
    new_tasks = {
        "test_task_12345": {
            "title": "Test task for online learning",
            "body": "This is a test task with ```code blocks```",
            "labels": ["bug", "test"]
        }
    }
    
    feature_extractor.gnn_extractor.add_new_nodes(new_developers, new_tasks)
    
    print("\nğŸ¯ çµè«–:")
    if feature_extractor.gnn_extractor.stats["updates"] > 0:
        print("âœ… ã‚ªãƒ³ãƒ©ã‚¤ãƒ³GNNå­¦ç¿’ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
        print(f"âœ… {feature_extractor.gnn_extractor.stats['updates']}å›ã®GNNæ›´æ–°ãŒå®Ÿè¡Œã•ã‚Œã¾ã—ãŸ")
        print("âœ… å¼·åŒ–å­¦ç¿’ã®ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«GNNãŒæ”¹å–„ã•ã‚Œã¦ã„ã¾ã™")
    else:
        print("âš ï¸ GNNæ›´æ–°ãŒç™ºç”Ÿã—ã¾ã›ã‚“ã§ã—ãŸ - ã‚ˆã‚Šå¤šãã®ã‚¹ãƒ†ãƒƒãƒ—ã¾ãŸã¯å ±é…¬ãŒå¿…è¦ã§ã™")
    
    print("ğŸš€ ã‚·ã‚¹ãƒ†ãƒ ã¯ç¶™ç¶šçš„ã«å­¦ç¿’ãƒ»æ”¹å–„ã™ã‚‹æº–å‚™ãŒã§ãã¦ã„ã¾ã™ï¼")


def test_manual_gnn_update():
    """æ‰‹å‹•ã§GNNæ›´æ–°ã‚’ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 50)
    print("ğŸ”§ æ‰‹å‹•GNNæ›´æ–°ãƒ†ã‚¹ãƒˆ")
    
    # è¨­å®šã‚’èª­ã¿è¾¼ã¿
    with hydra.initialize(config_path="../configs", version_base=None):
        cfg = hydra.compose(config_name="base")
    
    cfg.irl.online_gnn_learning = True
    
    feature_extractor = FeatureExtractor(cfg)
    gnn = feature_extractor.gnn_extractor
    
    if not gnn:
        print("âŒ GNNç‰¹å¾´é‡æŠ½å‡ºå™¨ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        return
    
    print("âœ… GNNåˆæœŸåŒ–å®Œäº†")
    
    # æ‰‹å‹•ã§ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
    print("ğŸ“ æ‰‹å‹•ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³è¨˜éŒ²...")
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®ã‚¿ã‚¹ã‚¯ã¨é–‹ç™ºè€…
    class TestTask:
        def __init__(self, task_id):
            self.id = task_id
    
    test_interactions = [
        (TestTask("pr_347626001"), {"name": "ndeloof"}, 1.5),
        (TestTask("pr_347626001"), {"name": "chris-crone"}, -0.5),
        (TestTask("pr_345198021"), {"name": "ndeloof"}, 2.0),
        (TestTask("issue_12345"), {"name": "missing_dev"}, 0.8),
    ]
    
    for task, developer, reward in test_interactions:
        gnn.record_interaction(task, developer, reward, "COMPLETE" if reward > 0 else "SKIP")
        print(f"  è¨˜éŒ²: {developer['name']} + {task.id} = {reward}")
    
    # å¼·åˆ¶çš„ã«æ›´æ–°
    print("\nğŸ”„ å¼·åˆ¶GNNæ›´æ–°...")
    gnn._update_gnn_online()
    
    print("\nğŸ“Š æ›´æ–°å¾Œçµ±è¨ˆ:")
    gnn.print_statistics()


if __name__ == "__main__":
    test_online_gnn_learning()
    test_manual_gnn_update()
