#!/usr/bin/env python3
"""
æ™‚ç³»åˆ—GNNå¯¾å¿œã®å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ
1. IRL (é€†å¼·åŒ–å­¦ç¿’) ã§å ±é…¬é–¢æ•°ã‚’å­¦ç¿’
2. RL (å¼·åŒ–å­¦ç¿’) ã§GNNã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã‚’ä½¿ç”¨ã—ã¦æ”¿ç­–ã‚’å­¦ç¿’
"""
import json
import sys
from datetime import datetime
from pathlib import Path

# Add project root to Python path
project_root = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(project_root / "src"))

import numpy as np
from omegaconf import OmegaConf


def run_complete_pipeline():
    """æ™‚ç³»åˆ—GNNå¯¾å¿œã®å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œ"""
    print("ğŸš€ æ™‚ç³»åˆ—GNNå¯¾å¿œ å®Œå…¨å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³")
    print("=" * 60)

    # è¨­å®šèª­ã¿è¾¼ã¿
    cfg = OmegaConf.load(project_root / "configs" / "base_training.yaml")

    print("ğŸ“‹ å®Ÿè¡Œè¨­å®š:")
    print(f"  ğŸ¯ IRLè¨­å®š:")
    print(f"    - ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆè»Œè·¡: {cfg.irl.expert_path}")
    print(f"    - å­¦ç¿’ç‡: {cfg.irl.learning_rate}")
    print(f"    - ã‚¨ãƒãƒƒã‚¯æ•°: {cfg.irl.epochs}")
    print(f"    - GNNä½¿ç”¨: {cfg.irl.use_gnn}")
    print(f"    - GNNã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’: {cfg.irl.online_gnn_learning}")

    print(f"  ğŸ¯ RLè¨­å®š:")
    print(f"    - ç·ã‚¹ãƒ†ãƒƒãƒ—æ•°: {cfg.rl.total_timesteps}")
    print(f"    - å­¦ç¿’ç‡: {cfg.rl.learning_rate}")
    print(f"    - GNNæ›´æ–°é »åº¦: {cfg.irl.gnn_update_frequency}")
    print(f"    - GNNæ™‚é–“çª“: {cfg.irl.gnn_time_window_hours}æ™‚é–“")

    # Step 1: IRL (é€†å¼·åŒ–å­¦ç¿’) å®Ÿè¡Œ
    print(f"\nğŸ”¥ Step 1: IRL (é€†å¼·åŒ–å­¦ç¿’) å®Ÿè¡Œ")
    print(f"=" * 40)

    start_time = datetime.now()

    try:
        # IRLã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
        import subprocess

        import yaml

        print("ğŸ“š ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆè»Œè·¡ã‹ã‚‰å ±é…¬é–¢æ•°ã‚’å­¦ç¿’ä¸­...")

        # IRLå­¦ç¿’å®Ÿè¡Œï¼ˆã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œï¼‰
        result = subprocess.run(
            [sys.executable, str(project_root / "scripts" / "train_irl.py")],
            capture_output=True,
            text=True,
            cwd=str(project_root),
        )

        if result.returncode == 0:
            print("âœ… IRLå­¦ç¿’æˆåŠŸ")
            print(result.stdout[-500:])  # æœ€å¾Œã®500æ–‡å­—ã‚’è¡¨ç¤º

            # å­¦ç¿’çµæœç¢ºèª
            weights_path = project_root / cfg.irl.output_weights_path
            if weights_path.exists():
                import numpy as np

                reward_weights = np.load(weights_path)
                print(f"ğŸ“Š å­¦ç¿’ã•ã‚ŒãŸå ±é…¬é‡ã¿å½¢çŠ¶: {reward_weights.shape}")
                print(f"ğŸ’¾ ä¿å­˜å…ˆ: {cfg.irl.output_weights_path}")
            else:
                print("âš ï¸  å ±é…¬é‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                reward_weights = None
        else:
            print(f"âŒ IRLå­¦ç¿’å¤±æ•—: {result.stderr}")
            reward_weights = None

        irl_duration = datetime.now() - start_time
        print(f"â±ï¸  IRLå®Ÿè¡Œæ™‚é–“: {irl_duration.total_seconds():.1f}ç§’")

    except Exception as e:
        print(f"âŒ IRLå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        print("âš ï¸  IRLã‚¹ã‚­ãƒƒãƒ—ã—ã¦å¼·åŒ–å­¦ç¿’ã®ã¿å®Ÿè¡Œã—ã¾ã™")
        reward_weights = None

    # Step 2: RL (å¼·åŒ–å­¦ç¿’) å®Ÿè¡Œ
    print(f"\nğŸ¤– Step 2: RL (å¼·åŒ–å­¦ç¿’) å®Ÿè¡Œ")
    print(f"=" * 40)

    rl_start_time = datetime.now()

    try:
        import yaml

        from kazoo.envs.oss_simple import OSSSimpleEnv
        from kazoo.learners.independent_ppo_controller import IndependentPPOController

        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        with open(project_root / cfg.env.backlog_path, "r") as f:
            backlog = json.load(f)

        with open(project_root / cfg.env.dev_profiles_path, "r") as f:
            dev_profiles = yaml.safe_load(f)

        # ç’°å¢ƒåˆæœŸåŒ–
        print("ğŸŒ å¼·åŒ–å­¦ç¿’ç’°å¢ƒã‚’åˆæœŸåŒ–ä¸­...")
        env = OSSSimpleEnv(cfg, backlog, dev_profiles)

        # GNNçŠ¶æ…‹ç¢ºèª
        if hasattr(env, "feature_extractor") and hasattr(
            env.feature_extractor, "gnn_extractor"
        ):
            gnn_extractor = env.feature_extractor.gnn_extractor
            if gnn_extractor and gnn_extractor.online_learning:
                print("âœ… GNNã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ãŒæœ‰åŠ¹ã§ã™")
                print(f"  ğŸ“Š é–‹ç™ºè€…ãƒãƒ¼ãƒ‰æ•°: {len(gnn_extractor.dev_id_to_idx)}")
                print(f"  ğŸ“Š ã‚¿ã‚¹ã‚¯ãƒãƒ¼ãƒ‰æ•°: {len(gnn_extractor.task_id_to_idx)}")
                print(f"  âš™ï¸ æ›´æ–°é »åº¦: {gnn_extractor.update_frequency}å›ã”ã¨")
                print(f"  â° æ™‚é–“çª“: {gnn_extractor.time_window_hours}æ™‚é–“")
            else:
                print("âš ï¸  GNNã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ãŒç„¡åŠ¹ã§ã™")
        else:
            print("âš ï¸  GNNç‰¹å¾´é‡æŠ½å‡ºå™¨ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        # PPOå­¦ç¿’å®Ÿè¡Œ
        print(f"ğŸš€ PPOå­¦ç¿’é–‹å§‹ ({cfg.rl.total_timesteps}ã‚¹ãƒ†ãƒƒãƒ—)...")
        controller = IndependentPPOController(env=env, config=cfg)

        # GNNçµ±è¨ˆï¼ˆå­¦ç¿’å‰ï¼‰
        if hasattr(env, "feature_extractor") and hasattr(
            env.feature_extractor, "gnn_extractor"
        ):
            gnn_extractor = env.feature_extractor.gnn_extractor
            if gnn_extractor:
                updates_before = gnn_extractor.stats.get("updates", 0)
                buffer_before = len(gnn_extractor.interaction_buffer)
                print(
                    f"  ğŸ“Š å­¦ç¿’å‰GNNçŠ¶æ…‹: æ›´æ–°{updates_before}å›, ãƒãƒƒãƒ•ã‚¡{buffer_before}ä»¶"
                )

        # å­¦ç¿’å®Ÿè¡Œ
        controller.learn(total_timesteps=cfg.rl.total_timesteps)

        rl_duration = datetime.now() - rl_start_time
        print(f"âœ… RLå®Œäº† (å®Ÿè¡Œæ™‚é–“: {rl_duration.total_seconds():.1f}ç§’)")

        # GNNçµ±è¨ˆï¼ˆå­¦ç¿’å¾Œï¼‰
        if hasattr(env, "feature_extractor") and hasattr(
            env.feature_extractor, "gnn_extractor"
        ):
            gnn_extractor = env.feature_extractor.gnn_extractor
            if gnn_extractor:
                updates_after = gnn_extractor.stats.get("updates", 0)
                buffer_after = len(gnn_extractor.interaction_buffer)
                print(
                    f"  ğŸ“Š å­¦ç¿’å¾ŒGNNçŠ¶æ…‹: æ›´æ–°{updates_after}å›, ãƒãƒƒãƒ•ã‚¡{buffer_after}ä»¶"
                )
                print(f"  ğŸ”„ GNNæ›´æ–°å›æ•°: +{updates_after - updates_before}")
                print(f"  ğŸ’¾ ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³è“„ç©: +{buffer_after - buffer_before}")

                # è©³ç´°çµ±è¨ˆ
                print(f"\nğŸ“ˆ GNNå­¦ç¿’çµ±è¨ˆ:")
                gnn_extractor.print_statistics()

                # æ™‚ç³»åˆ—æƒ…å ±ã®åˆ†æ
                if gnn_extractor.interaction_buffer:
                    times = [
                        interaction["simulation_time"]
                        for interaction in gnn_extractor.interaction_buffer
                    ]
                    if times:
                        min_time = min(times)
                        max_time = max(times)
                        print(f"  â° ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³æ™‚é–“ç¯„å›²:")
                        print(f"    é–‹å§‹: {min_time}")
                        print(f"    çµ‚äº†: {max_time}")
                        print(f"    æœŸé–“: {max_time - min_time}")

    except Exception as e:
        print(f"âŒ RLå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback

        traceback.print_exc()

    # ç·åˆçµæœ
    total_duration = datetime.now() - start_time
    print(f"\nğŸ‰ å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œå®Œäº†")
    print(f"=" * 60)
    print(f"  ğŸ“Š ç·å®Ÿè¡Œæ™‚é–“: {total_duration.total_seconds():.1f}ç§’")
    print(f"  âœ… IRL: {'æˆåŠŸ' if reward_weights is not None else 'ã‚¹ã‚­ãƒƒãƒ—'}")
    print(f"  âœ… RL: å®Ÿè¡Œå®Œäº†")
    print(f"  ğŸ§  GNNã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’: æ™‚ç³»åˆ—å¯¾å¿œ")

    # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®ææ¡ˆ
    print(f"\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ææ¡ˆ:")
    print(f"  1. å­¦ç¿’çµæœã®è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ")
    print(f"  2. GNNæ›´æ–°åŠ¹æœã®åˆ†æ")
    print(f"  3. æ™‚ç³»åˆ—å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–")
    print(f"  4. ã‚ˆã‚Šé•·æœŸé–“ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ")


if __name__ == "__main__":
    run_complete_pipeline()
