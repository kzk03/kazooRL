#!/usr/bin/env python3
"""
GNNã®æ™‚ç³»åˆ—å­¦ç¿’ã«ãŠã‘ã‚‹æƒ…å ±ä¿æŒ/æ¶ˆå¤±ã®ãƒ†ã‚¹ãƒˆ
- å…ƒã®ã‚°ãƒ©ãƒ•æ§‹é€ ãŒä¿æŒã•ã‚Œã‚‹ã‹ãƒ†ã‚¹ãƒˆ
- éå»ã®å­¦ç¿’çµæœãŒç´¯ç©ã•ã‚Œã‚‹ã‹ãƒ†ã‚¹ãƒˆ
- æ™‚é–“çª“ã«ã‚ˆã‚‹å½±éŸ¿ã‚’ãƒ†ã‚¹ãƒˆ
"""
import json
import sys
from datetime import datetime, timedelta
from pathlib import Path

import numpy as np
import torch
import yaml

# Add project root to Python path
project_root = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(project_root / "src"))

from omegaconf import OmegaConf

from kazoo.envs.oss_simple import OSSSimpleEnv


def test_gnn_information_preservation():
    """GNNã®æƒ…å ±ä¿æŒ/æ¶ˆå¤±ã‚’è©³ç´°ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ” GNNæ™‚ç³»åˆ—å­¦ç¿’ã§ã®æƒ…å ±ä¿æŒ/æ¶ˆå¤±ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    # è¨­å®šã¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    cfg = OmegaConf.load(project_root / "configs" / "base.yaml")
    
    with open(project_root / cfg.env.backlog_path, 'r') as f:
        backlog = json.load(f)
    
    with open(project_root / cfg.env.dev_profiles_path, 'r') as f:
        dev_profiles = yaml.safe_load(f)
    
    # ç’°å¢ƒåˆæœŸåŒ–
    env = OSSSimpleEnv(cfg, backlog, dev_profiles)
    gnn_extractor = env.feature_extractor.gnn_extractor
    
    if not gnn_extractor or not gnn_extractor.online_learning:
        print("âŒ GNNã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        return
    
    print("âœ… ãƒ†ã‚¹ãƒˆæº–å‚™å®Œäº†")
    
    # ãƒ†ã‚¹ãƒˆç”¨ãƒãƒ¼ãƒ‰
    test_devs = list(gnn_extractor.dev_id_to_idx.keys())[:3]
    test_tasks = list(gnn_extractor.task_id_to_idx.keys())[:5]
    
    print(f"ğŸ“Š ãƒ†ã‚¹ãƒˆå¯¾è±¡: é–‹ç™ºè€…{len(test_devs)}å, ã‚¿ã‚¹ã‚¯{len(test_tasks)}å€‹")
    
    # Step 1: åˆæœŸçŠ¶æ…‹ã®åŸ‹ã‚è¾¼ã¿ã‚’è¨˜éŒ²
    print("\nğŸ”¸ Step 1: åˆæœŸçŠ¶æ…‹ã®åŸ‹ã‚è¾¼ã¿ã‚’è¨˜éŒ²")
    
    def get_embeddings_snapshot():
        """ç¾åœ¨ã®åŸ‹ã‚è¾¼ã¿ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—"""
        with torch.no_grad():
            embeddings = gnn_extractor.model(
                gnn_extractor.graph_data.x_dict, 
                gnn_extractor.graph_data.edge_index_dict
            )
        return {
            'dev': embeddings['dev'].clone(),
            'task': embeddings['task'].clone()
        }
    
    def get_similarity_matrix(dev_list, task_list, embeddings):
        """é–‹ç™ºè€…-ã‚¿ã‚¹ã‚¯é–“ã®é¡ä¼¼åº¦è¡Œåˆ—ã‚’è¨ˆç®—"""
        similarities = {}
        for dev_name in dev_list:
            dev_idx = gnn_extractor.dev_id_to_idx.get(dev_name)
            if dev_idx is not None:
                similarities[dev_name] = {}
                for task_id in task_list:
                    task_idx = gnn_extractor.task_id_to_idx.get(task_id)
                    if task_idx is not None:
                        dev_emb = embeddings['dev'][dev_idx]
                        task_emb = embeddings['task'][task_idx]
                        sim = torch.cosine_similarity(dev_emb.unsqueeze(0), task_emb.unsqueeze(0)).item()
                        similarities[dev_name][task_id] = sim
        return similarities
    
    # åˆæœŸåŸ‹ã‚è¾¼ã¿ã¨é¡ä¼¼åº¦ã‚’è¨˜éŒ²
    initial_embeddings = get_embeddings_snapshot()
    initial_similarities = get_similarity_matrix(test_devs, test_tasks, initial_embeddings)
    
    print("  ğŸ“Š åˆæœŸé¡ä¼¼åº¦è¡Œåˆ—:")
    for dev_name in test_devs:
        print(f"    {dev_name}:")
        for task_id in test_tasks[:3]:  # æœ€åˆã®3ã¤ã®ã‚¿ã‚¹ã‚¯ã®ã¿è¡¨ç¤º
            sim = initial_similarities[dev_name][task_id]
            print(f"      vs {task_id[:15]}... = {sim:.4f}")
    
    # Step 2: ç¬¬1æœŸé–“ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæ™‚é–“: T0ï¼‰
    print("\nğŸ”¸ Step 2: ç¬¬1æœŸé–“ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆT0ï¼‰")
    
    class TestTask:
        def __init__(self, task_id):
            self.id = task_id
    
    class TestDev:
        def __init__(self, dev_name):
            self.name = dev_name
        def get(self, key, default=None):
            return self.name if key == "name" else default
    
    base_time = env.current_time
    
    # ç¬¬1æœŸé–“: ç‰¹å®šã®ãƒšã‚¢ã‚’å¼·åŒ–
    period1_interactions = [
        (test_devs[0], test_tasks[0], base_time, 1.5, "strong_positive"),
        (test_devs[0], test_tasks[1], base_time + timedelta(hours=1), 1.2, "positive"),
        (test_devs[1], test_tasks[2], base_time + timedelta(hours=2), 1.0, "positive"),
        (test_devs[2], test_tasks[0], base_time + timedelta(hours=3), -0.8, "negative"),
        (test_devs[1], test_tasks[3], base_time + timedelta(hours=4), 1.1, "positive"),
    ]
    
    print(f"  ğŸ“ ç¬¬1æœŸé–“: {len(period1_interactions)} ä»¶ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³")
    for dev_name, task_id, sim_time, reward, action in period1_interactions:
        developer = TestDev(dev_name)
        task = TestTask(task_id)
        gnn_extractor.record_interaction(task, developer, reward, action, simulation_time=sim_time)
        print(f"    {sim_time.strftime('%H:%M')} - {dev_name} + {task_id[:15]}... = {reward}")
    
    # ç¬¬1æœŸé–“å¾Œã®çŠ¶æ…‹ã‚’è¨˜éŒ²
    period1_embeddings = get_embeddings_snapshot()
    period1_similarities = get_similarity_matrix(test_devs, test_tasks, period1_embeddings)
    
    print("  ğŸ“Š ç¬¬1æœŸé–“å¾Œã®é¡ä¼¼åº¦å¤‰åŒ–:")
    for dev_name in test_devs:
        for task_id in test_tasks[:3]:
            initial_sim = initial_similarities[dev_name][task_id]
            period1_sim = period1_similarities[dev_name][task_id]
            change = period1_sim - initial_sim
            print(f"    {dev_name} vs {task_id[:15]}...: {initial_sim:.4f} â†’ {period1_sim:.4f} (Î”{change:+.4f})")
    
    # Step 3: æ™‚é–“ã‚’å¤§å¹…ã«é€²ã‚ã¦ç¬¬2æœŸé–“ï¼ˆæ™‚é–“çª“å¤–ï¼‰
    print("\nğŸ”¸ Step 3: ç¬¬2æœŸé–“ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆT0 + 30æ™‚é–“, æ™‚é–“çª“å¤–ï¼‰")
    
    period2_start = base_time + timedelta(hours=30)  # æ™‚é–“çª“ï¼ˆ24æ™‚é–“ï¼‰ã‚’è¶…ãˆã‚‹
    
    # ç¬¬2æœŸé–“: ç•°ãªã‚‹ãƒšã‚¢ã‚’å¼·åŒ–ï¼ˆç¬¬1æœŸé–“ã¨ã¯é€†ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
    period2_interactions = [
        (test_devs[2], test_tasks[0], period2_start, 1.8, "very_positive"),  # ç¬¬1æœŸé–“ã§ã¯negative
        (test_devs[1], test_tasks[1], period2_start + timedelta(hours=1), 1.5, "strong_positive"),
        (test_devs[0], test_tasks[3], period2_start + timedelta(hours=2), 1.3, "positive"),
        (test_devs[0], test_tasks[0], period2_start + timedelta(hours=3), -0.9, "negative"),  # ç¬¬1æœŸé–“ã§ã¯positive
        (test_devs[2], test_tasks[4], period2_start + timedelta(hours=4), 1.0, "positive"),
    ]
    
    print(f"  ğŸ“ ç¬¬2æœŸé–“: {len(period2_interactions)} ä»¶ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³")
    for dev_name, task_id, sim_time, reward, action in period2_interactions:
        developer = TestDev(dev_name)
        task = TestTask(task_id)
        gnn_extractor.record_interaction(task, developer, reward, action, simulation_time=sim_time)
        print(f"    {sim_time.strftime('%H:%M')} - {dev_name} + {task_id[:15]}... = {reward}")
    
    # ç¬¬2æœŸé–“å¾Œã®çŠ¶æ…‹ã‚’è¨˜éŒ²
    period2_embeddings = get_embeddings_snapshot()
    period2_similarities = get_similarity_matrix(test_devs, test_tasks, period2_embeddings)
    
    print("  ğŸ“Š ç¬¬2æœŸé–“å¾Œã®é¡ä¼¼åº¦å¤‰åŒ–:")
    for dev_name in test_devs:
        for task_id in test_tasks[:3]:
            period1_sim = period1_similarities[dev_name][task_id]
            period2_sim = period2_similarities[dev_name][task_id]
            change = period2_sim - period1_sim
            print(f"    {dev_name} vs {task_id[:15]}...: {period1_sim:.4f} â†’ {period2_sim:.4f} (Î”{change:+.4f})")
    
    # Step 4: æ™‚é–“çª“ã®å½±éŸ¿ã‚’åˆ†æ
    print("\nğŸ”¸ Step 4: æ™‚é–“çª“ã®å½±éŸ¿åˆ†æ")
    
    # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒãƒƒãƒ•ã‚¡ã®åˆ†æ
    all_interactions = gnn_extractor.interaction_buffer
    latest_time = max(interaction['simulation_time'] for interaction in all_interactions)
    cutoff_time = latest_time - timedelta(hours=gnn_extractor.time_window_hours)
    
    period1_count = sum(1 for interaction in all_interactions 
                       if interaction['simulation_time'] < cutoff_time)
    period2_count = sum(1 for interaction in all_interactions 
                       if interaction['simulation_time'] >= cutoff_time)
    
    print(f"  â° æœ€æ–°æ™‚åˆ»: {latest_time.strftime('%m/%d %H:%M')}")
    print(f"  â° ã‚«ãƒƒãƒˆã‚ªãƒ•æ™‚åˆ»: {cutoff_time.strftime('%m/%d %H:%M')}")
    print(f"  ğŸ“Š ç¬¬1æœŸé–“ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæ™‚é–“çª“å¤–ï¼‰: {period1_count} ä»¶")
    print(f"  ğŸ“Š ç¬¬2æœŸé–“ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæ™‚é–“çª“å†…ï¼‰: {period2_count} ä»¶")
    
    # Step 5: å…ƒã®ã‚°ãƒ©ãƒ•æ§‹é€ ã¨ã®æ¯”è¼ƒ
    print("\nğŸ”¸ Step 5: å…ƒã®ã‚°ãƒ©ãƒ•æ§‹é€ ã¨ã®æ¯”è¼ƒ")
    
    # å…ƒã®ã‚°ãƒ©ãƒ•ã®ã‚¨ãƒƒã‚¸æƒ…å ±ã‚’ç¢ºèª
    original_edges = gnn_extractor.graph_data[('dev', 'writes', 'task')].edge_index
    print(f"  ğŸ“Š å…ƒã®ã‚°ãƒ©ãƒ•ã‚¨ãƒƒã‚¸æ•°: {original_edges.shape[1]}")
    
    # å­¦ç¿’ã§å½±éŸ¿ã‚’å—ã‘ãŸãƒšã‚¢ã¨å…ƒã®ã‚¨ãƒƒã‚¸ã®é–¢ä¿‚ã‚’ç¢ºèª
    print("  ğŸ” å­¦ç¿’ãƒšã‚¢ã¨å…ƒã®ã‚¨ãƒƒã‚¸ã®é–¢ä¿‚:")
    for dev_name, task_id, _, reward, _ in period1_interactions + period2_interactions:
        dev_idx = gnn_extractor.dev_id_to_idx.get(dev_name)
        task_idx = gnn_extractor.task_id_to_idx.get(task_id)
        
        if dev_idx is not None and task_idx is not None:
            # å…ƒã®ã‚°ãƒ©ãƒ•ã«ã‚¨ãƒƒã‚¸ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            has_original_edge = False
            for i in range(original_edges.shape[1]):
                if original_edges[0, i].item() == dev_idx and original_edges[1, i].item() == task_idx:
                    has_original_edge = True
                    break
            
            edge_status = "å…ƒã‚¨ãƒƒã‚¸ã‚ã‚Š" if has_original_edge else "å…ƒã‚¨ãƒƒã‚¸ãªã—"
            print(f"    {dev_name} â†’ {task_id[:15]}... (å ±é…¬:{reward:+.1f}): {edge_status}")
    
    # Step 6: ç·åˆåˆ†æ
    print("\nğŸ”¸ Step 6: ç·åˆåˆ†æçµæœ")
    
    # é¡ä¼¼åº¦ã®å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ
    total_changes = {}
    for dev_name in test_devs:
        for task_id in test_tasks:
            initial_sim = initial_similarities[dev_name][task_id]
            final_sim = period2_similarities[dev_name][task_id]
            total_change = final_sim - initial_sim
            total_changes[f"{dev_name}-{task_id}"] = total_change
    
    # æœ€ã‚‚å¤‰åŒ–ã—ãŸãƒšã‚¢ã‚’ç‰¹å®š
    most_positive_change = max(total_changes.items(), key=lambda x: x[1])
    most_negative_change = min(total_changes.items(), key=lambda x: x[1])
    
    print(f"  ğŸ“ˆ æœ€å¤§ã®æ­£ã®å¤‰åŒ–: {most_positive_change[0]} (Î”{most_positive_change[1]:+.4f})")
    print(f"  ğŸ“‰ æœ€å¤§ã®è² ã®å¤‰åŒ–: {most_negative_change[0]} (Î”{most_negative_change[1]:+.4f})")
    
    # çµ±è¨ˆæƒ…å ±
    updates_count = gnn_extractor.stats.get("updates", 0)
    buffer_size = len(gnn_extractor.interaction_buffer)
    
    print(f"\nğŸ“Š å­¦ç¿’çµ±è¨ˆ:")
    print(f"  ğŸ”„ GNNæ›´æ–°å›æ•°: {updates_count}")
    print(f"  ğŸ’¾ ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º: {buffer_size}")
    print(f"  â° æ™‚é–“çª“: {gnn_extractor.time_window_hours} æ™‚é–“")
    
    # çµè«–
    print(f"\nğŸ¯ çµè«–:")
    print(f"  1. **ã‚°ãƒ©ãƒ•æ§‹é€ **: å…ƒã®ãƒãƒ¼ãƒ‰ãƒ»ã‚¨ãƒƒã‚¸æ§‹é€ ã¯ä¿æŒã•ã‚Œã‚‹")
    print(f"  2. **å­¦ç¿’ã®ç´¯ç©**: ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ç¶™ç¶šçš„ã«æ›´æ–°ã•ã‚Œã‚‹")
    print(f"  3. **æ™‚é–“çª“ã®å½±éŸ¿**: å­¦ç¿’ã«ã¯ç›´è¿‘{gnn_extractor.time_window_hours}æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨")
    print(f"  4. **æƒ…å ±ã®ä¿æŒ**: éå»ã®å­¦ç¿’çµæœã¯ãƒ¢ãƒ‡ãƒ«é‡ã¿ã«è“„ç©ã•ã‚Œã‚‹")
    print(f"  5. **æ™‚é–“çª“å¤–ãƒ‡ãƒ¼ã‚¿**: ç›´æ¥çš„ãªå­¦ç¿’ã«ã¯ä½¿ã‚ã‚Œãªã„ãŒã€éå»ã®é‡ã¿ã¯ä¿æŒ")

if __name__ == "__main__":
    test_gnn_information_preservation()
