#!/usr/bin/env python3
"""
GNNå­¦ç¿’åŠ¹æœã®è©³ç´°åˆ†æ
ãªãœé¡ä¼¼åº¦ãŒå¤‰åŒ–ã—ãªã„ã®ã‹ã‚’èª¿æŸ»
"""
import json
import sys
from datetime import datetime, timedelta
from pathlib import Path

import torch
import torch.nn.functional as F
import yaml

# Add project root to Python path
project_root = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(project_root / "src"))

from omegaconf import OmegaConf

from kazoo.envs.oss_simple import OSSSimpleEnv


def analyze_gnn_learning_effectiveness():
    """GNNå­¦ç¿’åŠ¹æœã®è©³ç´°åˆ†æ"""
    print("ğŸ”¬ GNNå­¦ç¿’åŠ¹æœã®è©³ç´°åˆ†æ")
    print("=" * 50)

    # ç’°å¢ƒåˆæœŸåŒ–
    cfg = OmegaConf.load(project_root / "configs" / "base.yaml")

    with open(project_root / cfg.env.backlog_path, "r") as f:
        backlog = json.load(f)

    with open(project_root / cfg.env.dev_profiles_path, "r") as f:
        dev_profiles = yaml.safe_load(f)

    env = OSSSimpleEnv(cfg, backlog, dev_profiles)
    gnn_extractor = env.feature_extractor.gnn_extractor

    print("âœ… åˆ†ææº–å‚™å®Œäº†")

    # ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åˆæœŸçŠ¶æ…‹ã‚’ä¿å­˜
    initial_params = {}
    for name, param in gnn_extractor.model.named_parameters():
        initial_params[name] = param.clone().detach()

    print(
        f"ğŸ“Š ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in gnn_extractor.model.parameters())}"
    )

    # å­¦ç¿’ç‡ã‚’ç¢ºèª
    print(f"ğŸ“Š å­¦ç¿’ç‡: {gnn_extractor.learning_rate}")
    print(f"ğŸ“Š æ›´æ–°é »åº¦: {gnn_extractor.update_frequency}")

    # ãƒ†ã‚¹ãƒˆç”¨ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³
    class TestTask:
        def __init__(self, task_id):
            self.id = task_id

    class TestDev:
        def __init__(self, dev_name):
            self.name = dev_name

        def get(self, key, default=None):
            return self.name if key == "name" else default

    test_devs = list(gnn_extractor.dev_id_to_idx.keys())[:2]
    test_tasks = list(gnn_extractor.task_id_to_idx.keys())[:2]

    print(f"ğŸ¯ ãƒ†ã‚¹ãƒˆå¯¾è±¡: {test_devs[0]} & {test_tasks[0]}")

    # åˆæœŸåŸ‹ã‚è¾¼ã¿ã‚’è¨˜éŒ²
    def get_specific_embeddings():
        with torch.no_grad():
            embeddings = gnn_extractor.model(
                gnn_extractor.graph_data.x_dict,
                gnn_extractor.graph_data.edge_index_dict,
            )

        dev_idx = gnn_extractor.dev_id_to_idx[test_devs[0]]
        task_idx = gnn_extractor.task_id_to_idx[test_tasks[0]]

        return {
            "dev_emb": embeddings["dev"][dev_idx].clone(),
            "task_emb": embeddings["task"][task_idx].clone(),
            "similarity": F.cosine_similarity(
                embeddings["dev"][dev_idx].unsqueeze(0),
                embeddings["task"][task_idx].unsqueeze(0),
            ).item(),
        }

    initial_state = get_specific_embeddings()
    print(f"ğŸ“Š åˆæœŸé¡ä¼¼åº¦: {initial_state['similarity']:.6f}")
    print(
        f"ğŸ“Š åˆæœŸé–‹ç™ºè€…åŸ‹ã‚è¾¼ã¿ãƒãƒ«ãƒ : {torch.norm(initial_state['dev_emb']).item():.6f}"
    )
    print(
        f"ğŸ“Š åˆæœŸã‚¿ã‚¹ã‚¯åŸ‹ã‚è¾¼ã¿ãƒãƒ«ãƒ : {torch.norm(initial_state['task_emb']).item():.6f}"
    )

    # å¼·ã„ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¤‡æ•°å›å®Ÿè¡Œ
    base_time = env.current_time

    print(f"\nğŸ”¥ å¼·ã„ãƒã‚¸ãƒ†ã‚£ãƒ–ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ:")
    for i in range(20):  # 20å›ã®å¼·ã„ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³
        developer = TestDev(test_devs[0])
        task = TestTask(test_tasks[0])
        reward = 5.0  # éå¸¸ã«å¼·ã„ãƒã‚¸ãƒ†ã‚£ãƒ–å ±é…¬
        sim_time = base_time + timedelta(hours=i)

        gnn_extractor.record_interaction(
            task, developer, reward, "strong_positive", simulation_time=sim_time
        )

        # 5å›ã”ã¨ã«çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯
        if (i + 1) % 5 == 0:
            current_state = get_specific_embeddings()
            similarity_change = (
                current_state["similarity"] - initial_state["similarity"]
            )
            print(
                f"  ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ {i+1}: é¡ä¼¼åº¦ = {current_state['similarity']:.6f} (Î”{similarity_change:+.6f})"
            )

    # æœ€çµ‚çŠ¶æ…‹
    final_state = get_specific_embeddings()
    final_similarity_change = final_state["similarity"] - initial_state["similarity"]

    print(f"\nğŸ“Š æœ€çµ‚çµæœ:")
    print(f"  åˆæœŸé¡ä¼¼åº¦: {initial_state['similarity']:.6f}")
    print(f"  æœ€çµ‚é¡ä¼¼åº¦: {final_state['similarity']:.6f}")
    print(f"  å¤‰åŒ–é‡: {final_similarity_change:+.6f}")

    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¤‰åŒ–ã‚’ç¢ºèª
    param_changes = []
    for name, initial_param in initial_params.items():
        current_param = dict(gnn_extractor.model.named_parameters())[name]
        change = torch.norm(current_param - initial_param).item()
        param_changes.append((name, change))

    # æœ€ã‚‚å¤‰åŒ–ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
    param_changes.sort(key=lambda x: x[1], reverse=True)
    print(f"\nğŸ“Š ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¤‰åŒ–ï¼ˆä¸Šä½5å±¤ï¼‰:")
    for name, change in param_changes[:5]:
        print(f"  {name}: {change:.8f}")

    # æå¤±å€¤ã®è©³ç´°åˆ†æ
    print(f"\nğŸ” æå¤±è¨ˆç®—ã®è©³ç´°:")

    # æ‰‹å‹•ã§æå¤±ã‚’è¨ˆç®—
    current_embeddings = gnn_extractor.model(
        gnn_extractor.graph_data.x_dict, gnn_extractor.graph_data.edge_index_dict
    )

    dev_idx = gnn_extractor.dev_id_to_idx[test_devs[0]]
    task_idx = gnn_extractor.task_id_to_idx[test_tasks[0]]

    dev_emb = current_embeddings["dev"][dev_idx]
    task_emb = current_embeddings["task"][task_idx]

    similarity = F.cosine_similarity(dev_emb.unsqueeze(0), task_emb.unsqueeze(0))
    sigmoid_sim = torch.sigmoid(similarity)

    print(f"  ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦: {similarity.item():.6f}")
    print(f"  ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰å¾Œ: {sigmoid_sim.item():.6f}")
    print(f"  ãƒ­ã‚°å€¤: {torch.log(sigmoid_sim + 1e-8).item():.6f}")

    # å­¦ç¿’è¨­å®šã®ç¢ºèª
    print(f"\nâš™ï¸ å­¦ç¿’è¨­å®š:")
    print(f"  æ›´æ–°å›æ•°: {gnn_extractor.stats.get('updates', 0)}")
    print(f"  å­¦ç¿’ç‡: {gnn_extractor.learning_rate}")
    print(f"  ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼: {type(gnn_extractor.optimizer).__name__}")

    # åŸ‹ã‚è¾¼ã¿åˆ†å¸ƒã®åˆ†æ
    dev_embeddings = current_embeddings["dev"]
    task_embeddings = current_embeddings["task"]

    print(f"\nğŸ“Š åŸ‹ã‚è¾¼ã¿çµ±è¨ˆ:")
    print(
        f"  é–‹ç™ºè€…åŸ‹ã‚è¾¼ã¿ - å¹³å‡: {dev_embeddings.mean().item():.6f}, æ¨™æº–åå·®: {dev_embeddings.std().item():.6f}"
    )
    print(
        f"  ã‚¿ã‚¹ã‚¯åŸ‹ã‚è¾¼ã¿ - å¹³å‡: {task_embeddings.mean().item():.6f}, æ¨™æº–åå·®: {task_embeddings.std().item():.6f}"
    )

    # é¡ä¼¼åº¦åˆ†å¸ƒ
    all_similarities = []
    for i in range(min(10, dev_embeddings.shape[0])):
        for j in range(min(10, task_embeddings.shape[0])):
            sim = F.cosine_similarity(
                dev_embeddings[i].unsqueeze(0), task_embeddings[j].unsqueeze(0)
            ).item()
            all_similarities.append(sim)

    import numpy as np

    all_similarities = np.array(all_similarities)
    print(
        f"  é¡ä¼¼åº¦åˆ†å¸ƒ - å¹³å‡: {all_similarities.mean():.6f}, æ¨™æº–åå·®: {all_similarities.std():.6f}"
    )
    print(f"  é¡ä¼¼åº¦ç¯„å›²: [{all_similarities.min():.6f}, {all_similarities.max():.6f}]")

    # å‹¾é…ã®ç¢ºèª
    print(f"\nğŸ” å‹¾é…ç¢ºèª:")
    gnn_extractor.model.train()
    gnn_extractor.optimizer.zero_grad()

    # æå¤±ã‚’æ‰‹å‹•è¨ˆç®—
    weight = 5.0
    pos_loss = -weight * torch.log(torch.sigmoid(similarity) + 1e-8)
    print(f"  è¨ˆç®—ã•ã‚ŒãŸæå¤±: {pos_loss.item():.6f}")

    pos_loss.backward()

    # å‹¾é…ã®ãƒãƒ«ãƒ ã‚’ç¢ºèª
    total_grad_norm = 0
    for name, param in gnn_extractor.model.named_parameters():
        if param.grad is not None:
            grad_norm = torch.norm(param.grad).item()
            total_grad_norm += grad_norm**2
            if grad_norm > 1e-6:
                print(f"  {name}: å‹¾é…ãƒãƒ«ãƒ  = {grad_norm:.8f}")

    total_grad_norm = total_grad_norm**0.5
    print(f"  ç·å‹¾é…ãƒãƒ«ãƒ : {total_grad_norm:.8f}")


if __name__ == "__main__":
    analyze_gnn_learning_effectiveness()
