#!/usr/bin/env python3
"""
å®Ÿéš›ã®æ‹…å½“è€…ã‚’å«ã‚€é©åˆ‡ãªå€™è£œç¾¤ã§ã®æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ è©•ä¾¡
"""

import argparse
import json
import os
import sys
from collections import defaultdict
from pathlib import Path

import numpy as np
import torch
import yaml
from stable_baselines3 import PPO
from tqdm import tqdm

# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent / "src"))

from kazoo.envs.oss_simple import OSSSimpleEnv
from kazoo.features.feature_extractor import FeatureExtractor


class SimpleConfig:
    """è¾æ›¸ã‚’ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã‚ˆã†ã«æ‰±ã†ãŸã‚ã®ã‚¯ãƒ©ã‚¹"""

    def __init__(self, config_dict):
        self._dict = config_dict
        for key, value in config_dict.items():
            if isinstance(value, dict):
                setattr(self, key, SimpleConfig(value))
            else:
                setattr(self, key, value)

    def get(self, key, default=None):
        """è¾æ›¸ã®getãƒ¡ã‚½ãƒƒãƒ‰ã¨åŒæ§˜ã®å‹•ä½œ"""
        return self._dict.get(key, default)


def load_config(config_path):
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    with open(config_path, "r", encoding="utf-8") as f:
        config_dict = yaml.safe_load(f)
    return SimpleConfig(config_dict)


def get_smart_candidate_developers(backlog_data, dev_profiles_data, num_candidates=200):
    """
    å®Ÿéš›ã®æ‹…å½“è€…ã‚’å«ã‚€è³¢ã„å€™è£œé–‹ç™ºè€…ãƒªã‚¹ãƒˆã‚’ä½œæˆ
    """
    # å®Ÿéš›ã®æ‹…å½“è€…ã‚’æŠ½å‡º
    actual_assignees = set()
    for task in backlog_data:
        if task.get("assignees"):
            for assignee in task["assignees"]:
                if assignee.get("login") and assignee["login"] in dev_profiles_data:
                    actual_assignees.add(assignee["login"])

    print(f"ğŸ¯ å®Ÿéš›ã®æ‹…å½“è€…æ•°: {len(actual_assignees)}")
    print(f"ğŸ“‹ å®Ÿéš›ã®æ‹…å½“è€…: {sorted(actual_assignees)}")

    # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä¸Šä½é–‹ç™ºè€…
    all_developers = list(dev_profiles_data.keys())
    top_developers = all_developers[: num_candidates - len(actual_assignees)]

    # å®Ÿéš›ã®æ‹…å½“è€… + ä¸Šä½é–‹ç™ºè€…ã®çµ„ã¿åˆã‚ã›
    candidate_developers = list(actual_assignees) + [
        dev for dev in top_developers if dev not in actual_assignees
    ]

    print(f"ğŸ‘¥ å€™è£œé–‹ç™ºè€…æ•°: {len(candidate_developers)}")
    print(f"   - å®Ÿéš›ã®æ‹…å½“è€…: {len(actual_assignees)}")
    print(f"   - ä¸Šä½é–‹ç™ºè€…: {len(candidate_developers) - len(actual_assignees)}")

    return candidate_developers, actual_assignees


class ImprovedRecommendationSystem:
    """æ”¹è‰¯ã•ã‚ŒãŸæ¨è–¦ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, irl_weights, ppo_model, env, feature_extractor):
        self.irl_weights = irl_weights
        self.ppo_model = ppo_model
        self.env = env
        self.feature_extractor = feature_extractor
        self.dev_profiles = env.dev_profiles

    def get_task_developer_features(self, task, developer_name):
        """ã‚¿ã‚¹ã‚¯ã¨é–‹ç™ºè€…ã®ãƒšã‚¢ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡º"""
        try:
            dev_profile = self.dev_profiles[developer_name]
            developer = {"name": developer_name, "profile": dev_profile}
            features = self.feature_extractor.get_features(task, developer, self.env)
            return features
        except Exception as e:
            return None

    def calculate_hybrid_score(self, features, weights=(0.6, 0.3, 0.1)):
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        irl_weight, ppo_weight, gat_weight = weights

        try:
            # IRL ã‚¹ã‚³ã‚¢
            irl_score = np.dot(features, self.irl_weights)

            # PPO ã‚¹ã‚³ã‚¢
            obs = features.reshape(1, -1)
            with torch.no_grad():
                if hasattr(self.ppo_model.policy, "predict_values"):
                    obs_tensor = torch.FloatTensor(obs)
                    value = self.ppo_model.policy.predict_values(obs_tensor)
                    ppo_score = float(value.item())
                else:
                    ppo_score = 0.5

            # GAT ã‚¹ã‚³ã‚¢
            gat_features = features[25:62] if len(features) > 61 else features[25:]
            gat_score = np.mean(np.abs(gat_features)) if len(gat_features) > 0 else 0.0

            # ç·åˆã‚¹ã‚³ã‚¢
            total_score = (
                irl_weight * irl_score + ppo_weight * ppo_score + gat_weight * gat_score
            )

            return float(total_score), {
                "irl_score": float(irl_score),
                "ppo_score": float(ppo_score),
                "gat_score": float(gat_score),
            }

        except Exception as e:
            return 0.0, {"irl_score": 0.0, "ppo_score": 0.0, "gat_score": 0.0}

    def recommend_developers(self, task, candidate_developers, num_recommendations=5):
        """é–‹ç™ºè€…ã‚’æ¨è–¦"""
        developer_scores = []

        for dev_name in candidate_developers:
            features = self.get_task_developer_features(task, dev_name)
            if features is None:
                continue

            total_score, score_details = self.calculate_hybrid_score(features)
            developer_scores.append((dev_name, total_score, score_details))

        # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰
        developer_scores.sort(key=lambda x: x[1], reverse=True)
        return developer_scores[:num_recommendations]


def create_mock_task(task_data):
    """ã‚¿ã‚¹ã‚¯ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¢ãƒƒã‚¯ã‚¿ã‚¹ã‚¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ"""

    class MockTask:
        def __init__(self, task_data):
            self.id = task_data.get("id")
            self.title = task_data.get("title", "")
            self.body = task_data.get("body", "")

            # ãƒ©ãƒ™ãƒ«ã®å½¢å¼ã‚’çµ±ä¸€çš„ã«å‡¦ç†
            labels_data = task_data.get("labels", [])
            if labels_data and isinstance(labels_data[0], dict):
                self.labels = [label.get("name") for label in labels_data]
            else:
                self.labels = labels_data if isinstance(labels_data, list) else []

            self.comments = task_data.get("comments", 0)
            self.updated_at = task_data.get("updated_at", "2023-01-01T00:00:00Z")
            self.user = task_data.get("user", task_data.get("author", {}))
            self.assignees = task_data.get("assignees", [])

            # æ—¥ä»˜æ–‡å­—åˆ—ã‚’datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
            from datetime import datetime

            if isinstance(self.updated_at, str):
                try:
                    if self.updated_at.endswith("Z"):
                        self.updated_at = self.updated_at[:-1] + "+00:00"
                    self.updated_at = datetime.fromisoformat(self.updated_at)
                except:
                    self.updated_at = datetime(2023, 1, 1)

    return MockTask(task_data)


def evaluate_improved_recommendations(
    backlog_data,
    dev_profiles_data,
    irl_weights,
    ppo_model,
    env,
    feature_extractor,
    num_recommendations=5,
):
    """æ”¹è‰¯ã•ã‚ŒãŸæ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã‚’è©•ä¾¡"""

    # è³¢ã„å€™è£œé–‹ç™ºè€…ãƒªã‚¹ãƒˆã‚’ä½œæˆ
    candidate_developers, actual_assignees = get_smart_candidate_developers(
        backlog_data, dev_profiles_data, num_candidates=200
    )

    # æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
    recommender = ImprovedRecommendationSystem(
        irl_weights, ppo_model, env, feature_extractor
    )

    results = {
        "total_tasks": 0,
        "tasks_with_assignees": 0,
        "correct_recommendations": 0,
        "top_k_hits": defaultdict(int),
        "recommendation_details": [],
        "candidate_info": {
            "total_candidates": len(candidate_developers),
            "actual_assignees_in_candidates": len(actual_assignees),
            "actual_assignees": list(actual_assignees),
        },
    }

    print(f"ğŸ¤– æ”¹è‰¯æ¨è–¦è©•ä¾¡é–‹å§‹: {len(backlog_data)} ã‚¿ã‚¹ã‚¯ã§è©•ä¾¡")

    # æ‹…å½“è€…æƒ…å ±ãŒã‚ã‚‹ã‚¿ã‚¹ã‚¯ã®ã¿ã‚’æŠ½å‡º
    tasks_with_assignees = []
    for task in backlog_data:
        if task.get("assignees") and len(task["assignees"]) > 0:
            assignees = [a.get("login") for a in task["assignees"] if a.get("login")]
            if any(assignee in dev_profiles_data for assignee in assignees):
                tasks_with_assignees.append(task)

    print(f"ğŸ“Š æ‹…å½“è€…æƒ…å ±ãŒã‚ã‚‹ã‚¿ã‚¹ã‚¯: {len(tasks_with_assignees)}/{len(backlog_data)}")

    eval_tasks = tasks_with_assignees
    print(f"ğŸ¯ æ”¹è‰¯æ¨è–¦è©•ä¾¡: {len(eval_tasks)} ã‚¿ã‚¹ã‚¯ã§è©•ä¾¡å®Ÿè¡Œ")

    # è©•ä¾¡ã‚¿ã‚¹ã‚¯ã®é€²æ—ãƒãƒ¼
    task_progress = tqdm(
        enumerate(eval_tasks),
        total=len(eval_tasks),
        desc="ğŸš€ æ”¹è‰¯æ¨è–¦è©•ä¾¡",
        unit="task",
        colour="green",
        leave=True,
    )

    for task_idx, task in task_progress:
        # ã‚¿ã‚¹ã‚¯ã®å®Ÿéš›ã®æ‹…å½“è€…ã‚’å–å¾—ï¼ˆGround Truthï¼‰
        actual_assignees_task = [
            assignee.get("login")
            for assignee in task["assignees"]
            if assignee.get("login")
        ]

        if not actual_assignees_task:
            task_progress.set_postfix({"Status": "æ‹…å½“è€…ãªã— (ã‚¹ã‚­ãƒƒãƒ—)"})
            continue

        try:
            # ãƒ¢ãƒƒã‚¯ã‚¿ã‚¹ã‚¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
            mock_task = create_mock_task(task)

            # æ¨è–¦ã‚’å®Ÿè¡Œ
            recommendations_with_scores = recommender.recommend_developers(
                mock_task, candidate_developers, num_recommendations
            )

            if not recommendations_with_scores:
                task_progress.set_postfix({"Status": "æ¨è–¦å¤±æ•—"})
                continue

            # æ¨è–¦ãƒªã‚¹ãƒˆã‚’ä½œæˆ
            recommendations = [
                dev_name for dev_name, score, details in recommendations_with_scores
            ]

            # æ­£è§£ç‡ã‚’è¨ˆç®—
            correct_in_top_k = []
            for k in [1, 3, 5]:
                top_k_recs = recommendations[:k]
                hit = any(assignee in top_k_recs for assignee in actual_assignees_task)
                if hit:
                    results["top_k_hits"][f"top_{k}"] += 1
                correct_in_top_k.append(hit)

            # è©³ç´°çµæœã‚’è¨˜éŒ²
            results["recommendation_details"].append(
                {
                    "task_id": task.get("id"),
                    "task_title": task.get("title", "Unknown")[:50],
                    "actual_assignees": actual_assignees_task,
                    "recommendations": recommendations,
                    "recommendation_scores": [
                        (dev, float(score))
                        for dev, score, details in recommendations_with_scores
                    ],
                    "correct_in_top_1": correct_in_top_k[0],
                    "correct_in_top_3": correct_in_top_k[1],
                    "correct_in_top_5": correct_in_top_k[2],
                }
            )

            results["total_tasks"] += 1
            results["tasks_with_assignees"] += 1

            # é€²æ—ãƒãƒ¼ã®æƒ…å ±æ›´æ–°
            if results["total_tasks"] > 0:
                top1_acc = results["top_k_hits"]["top_1"] / results["total_tasks"]
                top3_acc = results["top_k_hits"]["top_3"] / results["total_tasks"]
                task_progress.set_postfix(
                    {
                        "Top-1": f"{top1_acc:.3f}",
                        "Top-3": f"{top3_acc:.3f}",
                        "å®Œäº†": f"{results['total_tasks']}/{len(eval_tasks)}",
                    }
                )

        except Exception as e:
            print(f"âš ï¸ ã‚¿ã‚¹ã‚¯ {task_idx} ã§ã‚¨ãƒ©ãƒ¼: {e}")
            task_progress.set_postfix({"Status": f"ã‚¨ãƒ©ãƒ¼: {str(e)[:20]}"})
            continue

    return results


def main():
    parser = argparse.ArgumentParser(
        description="å®Ÿéš›ã®æ‹…å½“è€…ã‚’å«ã‚€é©åˆ‡ãªå€™è£œç¾¤ã§ã®æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ è©•ä¾¡"
    )
    parser.add_argument("--config", required=True, help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    parser.add_argument(
        "--irl-weights", required=True, help="å­¦ç¿’æ¸ˆã¿IRLé‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹"
    )
    parser.add_argument(
        "--ppo-model", required=True, help="å­¦ç¿’æ¸ˆã¿PPOãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹"
    )
    parser.add_argument(
        "--output",
        default="improved_recommendation_results_2023.json",
        help="çµæœå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«",
    )

    args = parser.parse_args()

    print("ğŸš€ æ”¹è‰¯æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ è©•ä¾¡é–‹å§‹")
    print(f"ğŸ“ è¨­å®š: {args.config}")
    print(f"ğŸ“Š IRLé‡ã¿: {args.irl_weights}")
    print(f"ğŸ¤– PPOãƒ¢ãƒ‡ãƒ«: {args.ppo_model}")

    # è¨­å®šèª­ã¿è¾¼ã¿
    config = load_config(args.config)

    # IRLé‡ã¿èª­ã¿è¾¼ã¿
    irl_weights = np.load(args.irl_weights)
    print(f"ğŸ“Š IRLé‡ã¿å½¢çŠ¶: {irl_weights.shape}")

    # PPOãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    print("ğŸ¤– PPOãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
    try:
        ppo_model = PPO.load(args.ppo_model)
        print(f"âœ… PPOãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
    except Exception as e:
        print(f"âŒ PPOãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        return

    # ãƒãƒƒã‚¯ãƒ­ã‚°ã¨ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("ğŸ“š ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    with open(config.env.backlog_path, "r", encoding="utf-8") as f:
        backlog_data = json.load(f)
    with open(config.env.dev_profiles_path, "r", encoding="utf-8") as f:
        dev_profiles_data = yaml.safe_load(f)

    # ç’°å¢ƒåˆæœŸåŒ–
    print("ğŸŒ ç’°å¢ƒåˆæœŸåŒ–ä¸­...")
    env = OSSSimpleEnv(config, backlog_data, dev_profiles_data)

    print(
        f"ğŸ“Š ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(backlog_data)} ã‚¿ã‚¹ã‚¯, {len(dev_profiles_data)} é–‹ç™ºè€…"
    )

    # æ”¹è‰¯æ¨è–¦è©•ä¾¡å®Ÿè¡Œ
    print("ğŸš€ æ”¹è‰¯æ¨è–¦è©•ä¾¡å®Ÿè¡Œä¸­...")
    results = evaluate_improved_recommendations(
        backlog_data,
        dev_profiles_data,
        irl_weights,
        ppo_model,
        env,
        env.feature_extractor,
    )

    # çµæœè¨ˆç®—
    total_tasks = results["total_tasks"]
    if total_tasks > 0:
        accuracy_top_1 = results["top_k_hits"]["top_1"] / total_tasks
        accuracy_top_3 = results["top_k_hits"]["top_3"] / total_tasks
        accuracy_top_5 = results["top_k_hits"]["top_5"] / total_tasks

        print("\n" + "=" * 70)
        print("ğŸš€ æ”¹è‰¯æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ è©•ä¾¡çµæœ")
        print("=" * 70)
        print(f"è©•ä¾¡ã‚¿ã‚¹ã‚¯æ•°: {total_tasks}")
        print(f"å€™è£œé–‹ç™ºè€…æ•°: {results['candidate_info']['total_candidates']}")
        print(
            f"å®Ÿéš›ã®æ‹…å½“è€…ãŒå€™è£œã«å«ã¾ã‚Œã‚‹æ•°: {results['candidate_info']['actual_assignees_in_candidates']}"
        )
        print(f"")
        print(
            f"Top-1 Accuracy: {accuracy_top_1:.3f} ({results['top_k_hits']['top_1']}/{total_tasks})"
        )
        print(
            f"Top-3 Accuracy: {accuracy_top_3:.3f} ({results['top_k_hits']['top_3']}/{total_tasks})"
        )
        print(
            f"Top-5 Accuracy: {accuracy_top_5:.3f} ({results['top_k_hits']['top_5']}/{total_tasks})"
        )
        print("=" * 70)

        # çµæœã‚’ã¾ã¨ã‚
        final_results = {
            "evaluation_config": args.config,
            "irl_weights_path": args.irl_weights,
            "ppo_model_path": args.ppo_model,
            "total_tasks_evaluated": total_tasks,
            "tasks_with_assignees": results["tasks_with_assignees"],
            "candidate_info": results["candidate_info"],
            "results": {
                "top_1_accuracy": float(accuracy_top_1),
                "top_3_accuracy": float(accuracy_top_3),
                "top_5_accuracy": float(accuracy_top_5),
            },
            "method": "Improved_Hybrid_Recommendation_With_Actual_Candidates",
        }

        # çµæœä¿å­˜
        output_path = Path(args.output)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(final_results, f, indent=2, ensure_ascii=False)

        print(f"ğŸ’¾ è©³ç´°çµæœã‚’ä¿å­˜: {output_path}")

        # ã‚µãƒ³ãƒ—ãƒ«çµæœè¡¨ç¤º
        print("\nğŸ“‹ ã‚µãƒ³ãƒ—ãƒ«æ”¹è‰¯æ¨è–¦çµæœ:")
        for i, detail in enumerate(results["recommendation_details"][:5]):
            print(f"\nã‚¿ã‚¹ã‚¯ {i+1}: {detail['task_title']}")
            print(f"  å®Ÿéš›ã®æ‹…å½“è€…: {detail['actual_assignees']}")
            print(f"  æ”¹è‰¯æ¨è–¦Top-5: {detail['recommendations']}")
            print(f"  Top-1æ­£è§£: {'âœ…' if detail['correct_in_top_1'] else 'âŒ'}")
            print(f"  Top-3æ­£è§£: {'âœ…' if detail['correct_in_top_3'] else 'âŒ'}")

    else:
        print("âš ï¸ è©•ä¾¡ã§ãã‚‹ã‚¿ã‚¹ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


if __name__ == "__main__":
    main()
