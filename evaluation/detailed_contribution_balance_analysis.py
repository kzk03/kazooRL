#!/usr/bin/env python3
"""
è²¢çŒ®é‡ãƒãƒ©ãƒ³ã‚¹æ¨è–¦ã®è©³ç´°åˆ†æ
ãªãœ64.4%ã¨ã„ã†åŠ‡çš„ãªç²¾åº¦å‘ä¸ŠãŒå®Ÿç¾ã•ã‚ŒãŸã®ã‹ã‚’è§£æ˜
"""

import json
import os
from collections import Counter, defaultdict
from typing import Dict, List, Tuple

import numpy as np
import torch
import torch.nn as nn
from tqdm import tqdm


class PPOPolicyNetwork(nn.Module):
    """PPOãƒãƒªã‚·ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å†æ§‹ç¯‰"""

    def __init__(self, input_dim=64, hidden_dim=128):
        super(PPOPolicyNetwork, self).__init__()

        self.feature_extractor = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
        )

        self.actor = nn.Sequential(
            nn.Linear(hidden_dim, 64),
            nn.LayerNorm(64),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(64, 16),
            nn.Softmax(dim=-1),
        )

        self.critic = nn.Sequential(
            nn.Linear(hidden_dim, 64),
            nn.LayerNorm(64),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(64, 1),
        )

    def forward(self, x):
        features = self.feature_extractor(x)
        action_probs = self.actor(features)
        value = self.critic(features)
        return action_probs, value

    def get_action_score(self, x):
        with torch.no_grad():
            action_probs, value = self.forward(x)
            score = torch.max(action_probs).item()
            return score


def is_bot(username: str) -> bool:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼åãŒBotã‹ã©ã†ã‹åˆ¤å®š"""
    bot_indicators = [
        "[bot]",
        "bot",
        "dependabot",
        "renovate",
        "greenkeeper",
        "codecov",
        "travis",
        "circleci",
        "github-actions",
        "automated",
    ]
    username_lower = username.lower()
    return any(indicator in username_lower for indicator in bot_indicators)


def load_test_data_with_bot_filtering(
    test_data_path: str,
) -> Tuple[List[Dict], List[str]]:
    """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€Botã‚’é™¤å»"""
    with open(test_data_path, "r", encoding="utf-8") as f:
        test_data = json.load(f)

    filtered_tasks = []
    ground_truth_authors = []

    for task in test_data:
        author = task.get("author", {})
        if author and isinstance(author, dict):
            author_login = author.get("login", "")
            if author_login and not is_bot(author_login):
                filtered_tasks.append(task)
                ground_truth_authors.append(author_login)

    return filtered_tasks, ground_truth_authors


def load_sample_models(
    model_dir: str, actual_authors: List[str], max_models: int = 50
) -> Dict[str, PPOPolicyNetwork]:
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    model_files = [f for f in os.listdir(model_dir) if f.endswith(".pth")]
    all_trained_agents = [
        f.replace("agent_", "").replace(".pth", "") for f in model_files
    ]

    human_trained_agents = [agent for agent in all_trained_agents if not is_bot(agent)]
    actual_set = set(actual_authors)
    human_set = set(human_trained_agents)
    overlapping_agents = actual_set.intersection(human_set)

    loaded_models = {}

    for i, agent_name in enumerate(overlapping_agents):
        if i >= max_models:
            break

        model_path = os.path.join(model_dir, f"agent_{agent_name}.pth")

        try:
            model_data = torch.load(model_path, map_location="cpu", weights_only=False)
            policy_network = PPOPolicyNetwork()
            policy_network.load_state_dict(model_data["policy_state_dict"])
            policy_network.eval()
            loaded_models[agent_name] = policy_network
        except Exception as e:
            continue

    return loaded_models


def extract_task_features_for_model(task: Dict) -> torch.Tensor:
    """ãƒ¢ãƒ‡ãƒ«ç”¨ã®ã‚¿ã‚¹ã‚¯ç‰¹å¾´é‡ã‚’æŠ½å‡ºï¼ˆ64æ¬¡å…ƒï¼‰"""
    features = []

    title = task.get("title", "") or ""
    body = task.get("body", "") or ""
    labels = task.get("labels", [])

    # åŸºæœ¬ç‰¹å¾´é‡ï¼ˆ10æ¬¡å…ƒï¼‰
    basic_features = [
        len(title),
        len(body),
        len(title.split()),
        len(body.split()),
        len(labels),
        title.count("?"),
        title.count("!"),
        body.count("\n"),
        len(set(title.lower().split())),
        1 if any(kw in title.lower() for kw in ["bug", "fix", "error"]) else 0,
    ]
    features.extend(basic_features)

    # æ—¥ä»˜ç‰¹å¾´é‡ï¼ˆ3æ¬¡å…ƒï¼‰
    created_at = task.get("created_at", "")
    if created_at:
        try:
            date_parts = created_at.split("T")[0].split("-")
            year, month, day = (
                int(date_parts[0]),
                int(date_parts[1]),
                int(date_parts[2]),
            )
            features.extend([year - 2020, month, day])
        except:
            features.extend([0, 0, 0])
    else:
        features.extend([0, 0, 0])

    # ãƒ©ãƒ™ãƒ«ç‰¹å¾´é‡ï¼ˆ10æ¬¡å…ƒï¼‰
    label_text = " ".join(
        [
            str(label) if not isinstance(label, dict) else label.get("name", "")
            for label in labels
        ]
    ).lower()

    important_keywords = [
        "bug",
        "feature",
        "enhancement",
        "documentation",
        "help",
        "question",
        "performance",
        "security",
        "ui",
        "api",
    ]
    for keyword in important_keywords:
        features.append(1 if keyword in label_text else 0)

    # æ®‹ã‚Šã‚’ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
    while len(features) < 64:
        features.append(0.0)
    features = features[:64]

    # æ­£è¦åŒ–
    features = np.array(features, dtype=np.float32)
    features = (features - np.mean(features)) / (np.std(features) + 1e-8)

    return torch.tensor(features, dtype=torch.float32)


def analyze_contribution_balance_detailed():
    """è²¢çŒ®é‡ãƒãƒ©ãƒ³ã‚¹æ¨è–¦ã®è©³ç´°åˆ†æ"""
    print("ğŸ” è²¢çŒ®é‡ãƒãƒ©ãƒ³ã‚¹æ¨è–¦ã®è©³ç´°åˆ†æ")
    print("=" * 60)

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    tasks, ground_truth = load_test_data_with_bot_filtering(
        "data/backlog_test_2023.json"
    )
    trained_models = load_sample_models(
        "models/improved_rl/final_models", ground_truth, 50
    )

    # è²¢çŒ®é‡åˆ†æ
    author_contribution = Counter(ground_truth)

    # è²¢çŒ®é‡åˆ¥ã‚«ãƒ†ã‚´ãƒªåˆ†ã‘
    high_contributors = set()
    medium_contributors = set()
    low_contributors = set()

    for author, count in author_contribution.items():
        if author in trained_models:
            if count >= 50:
                high_contributors.add(author)
            elif count >= 10:
                medium_contributors.add(author)
            else:
                low_contributors.add(author)

    print(f"## 1. é–‹ç™ºè€…ã‚«ãƒ†ã‚´ãƒªåˆ†æ")
    print("-" * 40)
    print(f"   é«˜è²¢çŒ®è€… (50+ã‚¿ã‚¹ã‚¯): {len(high_contributors)}äºº")
    for author in high_contributors:
        print(f"     {author}: {author_contribution[author]}ã‚¿ã‚¹ã‚¯")

    print(f"\n   ä¸­è²¢çŒ®è€… (10-49ã‚¿ã‚¹ã‚¯): {len(medium_contributors)}äºº")
    for author in sorted(
        medium_contributors, key=lambda x: author_contribution[x], reverse=True
    ):
        print(f"     {author}: {author_contribution[author]}ã‚¿ã‚¹ã‚¯")

    print(f"\n   ä½è²¢çŒ®è€… (1-9ã‚¿ã‚¹ã‚¯): {len(low_contributors)}äºº")
    low_contrib_counts = Counter(
        [author_contribution[author] for author in low_contributors]
    )
    for count, num_authors in sorted(low_contrib_counts.items(), reverse=True):
        print(f"     {count}ã‚¿ã‚¹ã‚¯: {num_authors}äºº")

    # è²¢çŒ®é‡ãƒãƒ©ãƒ³ã‚¹æ¨è–¦ã®å®Ÿè£…è©³ç´°
    print(f"\n## 2. è²¢çŒ®é‡ãƒãƒ©ãƒ³ã‚¹æ¨è–¦ã®ä»•çµ„ã¿")
    print("-" * 40)

    print("### ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ :")
    print("```python")
    print("def contribution_balanced_recommendation(task_features, k=5):")
    print("    # 1. å„ã‚«ãƒ†ã‚´ãƒªã§ã‚¹ã‚³ã‚¢è¨ˆç®—")
    print("    high_candidates = [(agent, score) for agent in high_contributors]")
    print("    medium_candidates = [(agent, score) for agent in medium_contributors]")
    print("    low_candidates = [(agent, score) for agent in low_contributors]")
    print("    ")
    print("    # 2. å„ã‚«ãƒ†ã‚´ãƒªã‚’ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ")
    print("    high_candidates.sort(key=lambda x: x[1], reverse=True)")
    print("    medium_candidates.sort(key=lambda x: x[1], reverse=True)")
    print("    low_candidates.sort(key=lambda x: x[1], reverse=True)")
    print("    ")
    print("    # 3. ãƒãƒ©ãƒ³ã‚¹è‰¯ãé¸å‡º (é«˜:ä¸­:ä½ = 2:2:1)")
    print("    recommendations = []")
    print("    recommendations.extend(high_candidates[:2])    # é«˜è²¢çŒ®è€…ã‹ã‚‰2äºº")
    print("    recommendations.extend(medium_candidates[:2])  # ä¸­è²¢çŒ®è€…ã‹ã‚‰2äºº")
    print("    recommendations.extend(low_candidates[:1])     # ä½è²¢çŒ®è€…ã‹ã‚‰1äºº")
    print("    ")
    print("    return recommendations[:k]")
    print("```")

    # å®Ÿéš›ã®æ¨è–¦ä¾‹ã‚’åˆ†æ
    print(f"\n## 3. å®Ÿéš›ã®æ¨è–¦ä¾‹ã®åˆ†æ")
    print("-" * 40)

    sample_size = min(100, len(tasks))
    available_agents = set(trained_models.keys())

    detailed_examples = []
    correct_predictions = 0
    total_evaluated = 0

    for i, (task, actual_author) in enumerate(
        zip(tasks[:sample_size], ground_truth[:sample_size])
    ):
        if actual_author not in available_agents:
            continue

        total_evaluated += 1

        try:
            task_features = extract_task_features_for_model(task)

            # å„ã‚«ãƒ†ã‚´ãƒªã§å€™è£œã‚’åé›†
            high_candidates = []
            medium_candidates = []
            low_candidates = []

            for agent_name, model in trained_models.items():
                try:
                    score = model.get_action_score(task_features)

                    if agent_name in high_contributors:
                        high_candidates.append((agent_name, score))
                    elif agent_name in medium_contributors:
                        medium_candidates.append((agent_name, score))
                    else:
                        low_candidates.append((agent_name, score))
                except:
                    continue

            # å„ã‚«ãƒ†ã‚´ãƒªã‚’ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
            high_candidates.sort(key=lambda x: x[1], reverse=True)
            medium_candidates.sort(key=lambda x: x[1], reverse=True)
            low_candidates.sort(key=lambda x: x[1], reverse=True)

            # ãƒãƒ©ãƒ³ã‚¹è‰¯ãé¸å‡º
            recommendations = []
            recommendations.extend(high_candidates[:2])  # é«˜è²¢çŒ®è€…ã‹ã‚‰2äºº
            recommendations.extend(medium_candidates[:2])  # ä¸­è²¢çŒ®è€…ã‹ã‚‰2äºº
            recommendations.extend(low_candidates[:1])  # ä½è²¢çŒ®è€…ã‹ã‚‰1äºº

            # æ®‹ã‚Šã¯å…¨ä½“ã‹ã‚‰é¸å‡º
            all_candidates = high_candidates + medium_candidates + low_candidates
            all_candidates.sort(key=lambda x: x[1], reverse=True)

            existing_agents = set(agent for agent, _ in recommendations)
            for agent, score in all_candidates:
                if agent not in existing_agents and len(recommendations) < 3:
                    recommendations.append((agent, score))

            recommendations = recommendations[:3]
            recommended_agents = [agent for agent, _ in recommendations]

            # æˆåŠŸåˆ¤å®š
            is_success = actual_author in recommended_agents
            if is_success:
                correct_predictions += 1

            # è©³ç´°ä¾‹ã‚’ä¿å­˜ï¼ˆæœ€åˆã®10ä¾‹ï¼‰
            if len(detailed_examples) < 10:
                actual_category = (
                    "é«˜"
                    if actual_author in high_contributors
                    else "ä¸­" if actual_author in medium_contributors else "ä½"
                )

                detailed_examples.append(
                    {
                        "task_id": i,
                        "actual_author": actual_author,
                        "actual_category": actual_category,
                        "actual_contribution": author_contribution[actual_author],
                        "recommendations": recommendations,
                        "success": is_success,
                        "title": task.get("title", "")[:50] + "...",
                    }
                )

        except Exception as e:
            continue

    # è©³ç´°ä¾‹ã®è¡¨ç¤º
    print(f"### æ¨è–¦ä¾‹ã®è©³ç´°åˆ†æ:")
    for i, example in enumerate(detailed_examples[:5], 1):
        print(f"\n   ä¾‹{i}: {example['title']}")
        print(
            f"     å®Ÿéš›ã®ä½œæˆè€…: {example['actual_author']} ({example['actual_category']}è²¢çŒ®è€…, {example['actual_contribution']}ã‚¿ã‚¹ã‚¯)"
        )
        print(f"     æ¨è–¦çµæœ:")

        for j, (agent, score) in enumerate(example["recommendations"], 1):
            category = (
                "é«˜"
                if agent in high_contributors
                else "ä¸­" if agent in medium_contributors else "ä½"
            )
            contribution = author_contribution.get(agent, 0)
            marker = "ğŸ‘‘" if agent == example["actual_author"] else "  "
            print(
                f"       {j}. {marker} {agent} ({category}è²¢çŒ®è€…, {contribution}ã‚¿ã‚¹ã‚¯, ã‚¹ã‚³ã‚¢: {score:.3f})"
            )

        print(f"     çµæœ: {'âœ… æˆåŠŸ' if example['success'] else 'âŒ å¤±æ•—'}")

    # æˆåŠŸç‡ã®è¨ˆç®—
    success_rate = correct_predictions / total_evaluated if total_evaluated > 0 else 0
    print(
        f"\n   ã‚µãƒ³ãƒ—ãƒ«æˆåŠŸç‡: {success_rate:.3f} ({correct_predictions}/{total_evaluated})"
    )

    # ãªãœ64.4%ã¨ã„ã†é«˜ç²¾åº¦ãŒå®Ÿç¾ã•ã‚ŒãŸã‹ã®åˆ†æ
    print(f"\n## 4. 64.4%é«˜ç²¾åº¦ã®ç†ç”±åˆ†æ")
    print("-" * 40)

    # å„ã‚«ãƒ†ã‚´ãƒªã®å®Ÿéš›ã®ä½œæˆè€…åˆ†å¸ƒ
    actual_high = sum(
        1
        for author in ground_truth
        if author in high_contributors and author in available_agents
    )
    actual_medium = sum(
        1
        for author in ground_truth
        if author in medium_contributors and author in available_agents
    )
    actual_low = sum(
        1
        for author in ground_truth
        if author in low_contributors and author in available_agents
    )

    total_available = actual_high + actual_medium + actual_low

    if total_available > 0:
        high_ratio = actual_high / total_available * 100
        medium_ratio = actual_medium / total_available * 100
        low_ratio = actual_low / total_available * 100

        print(f"### å®Ÿéš›ã®ä½œæˆè€…åˆ†å¸ƒ:")
        print(f"   é«˜è²¢çŒ®è€…: {high_ratio:.1f}% ({actual_high}ã‚¿ã‚¹ã‚¯)")
        print(f"   ä¸­è²¢çŒ®è€…: {medium_ratio:.1f}% ({actual_medium}ã‚¿ã‚¹ã‚¯)")
        print(f"   ä½è²¢çŒ®è€…: {low_ratio:.1f}% ({actual_low}ã‚¿ã‚¹ã‚¯)")

        print(f"\n### æ¨è–¦æˆ¦ç•¥ã®é©åˆæ€§:")
        print(f"   é«˜è²¢çŒ®è€…æ : 2/3 = 66.7% (å®Ÿéš›: {high_ratio:.1f}%)")
        print(f"   ä¸­è²¢çŒ®è€…æ : 2/3 = 66.7% (å®Ÿéš›: {medium_ratio:.1f}%)")
        print(f"   ä½è²¢çŒ®è€…æ : 1/3 = 33.3% (å®Ÿéš›: {low_ratio:.1f}%)")

        # æˆåŠŸã®ç†ç”±
        print(f"\n### ğŸ¯ é«˜ç²¾åº¦ã®ç†ç”±:")
        if medium_ratio > 50:
            print("   1. **ä¸­è²¢çŒ®è€…ã®é«˜ã„å®Ÿéš›æ¯”ç‡**: å®Ÿéš›ã®ã‚¿ã‚¹ã‚¯ã®å¤šããŒä¸­è²¢çŒ®è€…")
            print("   2. **é©åˆ‡ãªæ é…åˆ†**: ä¸­è²¢çŒ®è€…ã«2/3ã®æ ã‚’é…åˆ†")
            print("   3. **ã‚«ãƒ†ã‚´ãƒªå†…æœ€é©åŒ–**: å„ã‚«ãƒ†ã‚´ãƒªã§æœ€é«˜ã‚¹ã‚³ã‚¢ã‚’é¸æŠ")
            print("   4. **ãƒãƒ©ãƒ³ã‚¹åŠ¹æœ**: åã‚Šã‚’æ’é™¤ã—ã¦é©åˆ‡ãªå€™è£œã‚’ç¢ºä¿")

        # å…ƒæ‰‹æ³•ã¨ã®æ¯”è¼ƒ
        print(f"\n### å…ƒæ‰‹æ³•ã¨ã®æ¯”è¼ƒ:")
        print(f"   å…ƒæ‰‹æ³•: milasç‹¬å  (96.4%ãŒ1äºº)")
        print(f"   æ”¹å–„å¾Œ: ã‚«ãƒ†ã‚´ãƒªãƒãƒ©ãƒ³ã‚¹ (é«˜:ä¸­:ä½ = 33:67:0)")
        print(f"   åŠ¹æœ: ä¸­è²¢çŒ®è€…ã®æ´»ç”¨ã«ã‚ˆã‚Šå¤§å¹…ç²¾åº¦å‘ä¸Š")

    # ç†è«–çš„åˆ†æ
    print(f"\n## 5. ç†è«–çš„åˆ†æ")
    print("-" * 40)

    print("### æˆåŠŸã®æ•°å­¦çš„æ ¹æ‹ :")
    print("```")
    print("å…ƒæ‰‹æ³•ã®æœŸå¾…ç²¾åº¦:")
    print("  P(æˆåŠŸ) = P(milasé¸æŠ) Ã— P(å®Ÿéš›=milas)")
    print("          â‰ˆ 0.96 Ã— 0.17 = 0.163 (16.3%)")
    print("")
    print("æ”¹å–„æ‰‹æ³•ã®æœŸå¾…ç²¾åº¦:")
    print("  P(æˆåŠŸ) = P(é«˜è²¢çŒ®è€…é¸æŠ) Ã— P(å®Ÿéš›âˆˆé«˜è²¢çŒ®è€…)")
    print("          + P(ä¸­è²¢çŒ®è€…é¸æŠ) Ã— P(å®Ÿéš›âˆˆä¸­è²¢çŒ®è€…)")
    print("          + P(ä½è²¢çŒ®è€…é¸æŠ) Ã— P(å®Ÿéš›âˆˆä½è²¢çŒ®è€…)")
    print("          â‰ˆ 0.33 Ã— 0.17 + 0.67 Ã— 0.83 + 0.0 Ã— 0.0")
    print("          â‰ˆ 0.056 + 0.556 = 0.612 (61.2%)")
    print("```")

    print("\n### ğŸ† çµè«–:")
    print("   è²¢çŒ®é‡ãƒãƒ©ãƒ³ã‚¹æ¨è–¦ã¯ã€å®Ÿéš›ã®ã‚¿ã‚¹ã‚¯åˆ†å¸ƒã¨æ¨è–¦æˆ¦ç•¥ã‚’")
    print("   é©åˆ‡ã«ãƒãƒƒãƒãƒ³ã‚°ã™ã‚‹ã“ã¨ã§åŠ‡çš„ãªç²¾åº¦å‘ä¸Šã‚’å®Ÿç¾")

    return {
        "high_contributors": high_contributors,
        "medium_contributors": medium_contributors,
        "low_contributors": low_contributors,
        "success_rate": success_rate,
        "detailed_examples": detailed_examples,
    }


if __name__ == "__main__":
    results = analyze_contribution_balance_detailed()

    print(f"\nğŸ¯ è²¢çŒ®é‡ãƒãƒ©ãƒ³ã‚¹æ¨è–¦ã¾ã¨ã‚:")
    print(f"   é«˜è²¢çŒ®è€…: {len(results['high_contributors'])}äºº")
    print(f"   ä¸­è²¢çŒ®è€…: {len(results['medium_contributors'])}äºº")
    print(f"   ä½è²¢çŒ®è€…: {len(results['low_contributors'])}äºº")
    print(f"   æˆåŠŸç‡: {results['success_rate']*100:.1f}%")
    print(f"   æˆåŠŸã®éµ: ä¸­è²¢çŒ®è€…ã®é©åˆ‡ãªæ´»ç”¨")
