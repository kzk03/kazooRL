#!/usr/bin/env python3
"""
å­¦ç¿’æ¸ˆã¿RLãƒ¢ãƒ‡ãƒ«ï¼ˆPPOï¼‰ã‚’ä½¿ã£ã¦2023å¹´ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import argparse
import json
import os
import sys
from collections import defaultdict
from pathlib import Path

import numpy as np
import torch
import yaml
from stable_baselines3 import PPO
from tqdm import tqdm

# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent / "src"))

from kazoo.envs.oss_simple import OSSSimpleEnv
from kazoo.features.feature_extractor import FeatureExtractor


class SimpleConfig:
    """è¾æ›¸ã‚’ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã‚ˆã†ã«æ‰±ã†ãŸã‚ã®ã‚¯ãƒ©ã‚¹"""

    def __init__(self, config_dict):
        self._dict = config_dict
        for key, value in config_dict.items():
            if isinstance(value, dict):
                setattr(self, key, SimpleConfig(value))
            else:
                setattr(self, key, value)

    def get(self, key, default=None):
        """è¾æ›¸ã®getãƒ¡ã‚½ãƒƒãƒ‰ã¨åŒæ§˜ã®å‹•ä½œ"""
        return self._dict.get(key, default)


def load_config(config_path):
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    with open(config_path, "r", encoding="utf-8") as f:
        config_dict = yaml.safe_load(f)
    return SimpleConfig(config_dict)


def evaluate_rl_recommendations(
    backlog_data,
    dev_profiles_data,
    rl_model,
    env,
    num_recommendations=5,
):
    """
    å­¦ç¿’æ¸ˆã¿RLãƒ¢ãƒ‡ãƒ«ï¼ˆPPOï¼‰ã‚’ä½¿ã£ã¦æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã‚’è©•ä¾¡ã™ã‚‹

    Args:
        backlog_data: ãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯ãƒ‡ãƒ¼ã‚¿
        dev_profiles_data: é–‹ç™ºè€…ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿
        rl_model: å­¦ç¿’æ¸ˆã¿PPOãƒ¢ãƒ‡ãƒ«
        env: ç’°å¢ƒã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        num_recommendations: æ¨è–¦ã™ã‚‹é–‹ç™ºè€…æ•°

    Returns:
        dict: è©•ä¾¡çµæœï¼ˆaccuracy, precision, recall, etc.ï¼‰
    """

    results = {
        "total_tasks": 0,
        "tasks_with_assignees": 0,
        "correct_recommendations": 0,
        "top_k_hits": defaultdict(int),
        "recommendation_details": [],
    }

    print(f"ğŸ” RLè©•ä¾¡é–‹å§‹: {len(backlog_data)} ã‚¿ã‚¹ã‚¯ã§è©•ä¾¡")

    # æ‹…å½“è€…æƒ…å ±ãŒã‚ã‚‹ã‚¿ã‚¹ã‚¯ã®ã¿ã‚’æŠ½å‡º
    tasks_with_assignees = []
    for task in backlog_data:
        if task.get("assignees") and len(task["assignees"]) > 0:
            # æ‹…å½“è€…ãŒdev_profiles_dataã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            assignees = [a.get("login") for a in task["assignees"] if a.get("login")]
            if any(assignee in dev_profiles_data for assignee in assignees):
                tasks_with_assignees.append(task)

    print(f"ğŸ“Š æ‹…å½“è€…æƒ…å ±ãŒã‚ã‚‹ã‚¿ã‚¹ã‚¯: {len(tasks_with_assignees)}/{len(backlog_data)}")

    eval_tasks = tasks_with_assignees
    print(f"ğŸ¯ RLè©•ä¾¡: {len(eval_tasks)} ã‚¿ã‚¹ã‚¯ã§è©•ä¾¡å®Ÿè¡Œ")

    # è©•ä¾¡ã‚¿ã‚¹ã‚¯ã®é€²æ—ãƒãƒ¼
    task_progress = tqdm(
        enumerate(eval_tasks),
        total=len(eval_tasks),
        desc="ğŸ¤– RLæ¨è–¦è©•ä¾¡",
        unit="task",
        colour="green",
        leave=True,
    )

    for task_idx, task in task_progress:
        # ã‚¿ã‚¹ã‚¯ã®å®Ÿéš›ã®æ‹…å½“è€…ã‚’å–å¾—ï¼ˆGround Truthï¼‰
        actual_assignees = [
            assignee.get("login")
            for assignee in task["assignees"]
            if assignee.get("login")
        ]

        if not actual_assignees:
            task_progress.set_postfix({"Status": "æ‹…å½“è€…ãªã— (ã‚¹ã‚­ãƒƒãƒ—)"})
            continue

        try:
            # ç’°å¢ƒã«ã‚¿ã‚¹ã‚¯ã‚’è¨­å®š
            env.reset()

            # ã‚¿ã‚¹ã‚¯ã‚’ç’°å¢ƒã«è¿½åŠ ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
            task_obj = type(
                "Task",
                (),
                {
                    "id": task.get("id"),
                    "title": task.get("title", ""),
                    "body": task.get("body", ""),
                    "labels": (
                        task.get("labels", [])
                        if isinstance(task.get("labels", []), list)
                        else []
                    ),
                    "updated_at": task.get("updated_at", "2023-01-01T00:00:00Z"),
                    "user": task.get("user", task.get("author", {})),
                    "assignees": task.get("assignees", []),
                },
            )()

            # åˆ©ç”¨å¯èƒ½ãªé–‹ç™ºè€…ãƒªã‚¹ãƒˆã‚’å–å¾—
            available_developers = list(dev_profiles_data.keys())[
                :200
            ]  # ä¸Šä½200äººã§è©•ä¾¡

            # å„é–‹ç™ºè€…ã«å¯¾ã—ã¦RLãƒ¢ãƒ‡ãƒ«ã§è¡Œå‹•ç¢ºç‡ã‚’è¨ˆç®—
            developer_scores = []

            for dev_name in available_developers:
                try:
                    # é–‹ç™ºè€…ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
                    dev_profile = dev_profiles_data[dev_name]
                    developer = {"name": dev_name, "profile": dev_profile}

                    # ç‰¹å¾´é‡ã‚’æŠ½å‡ºï¼ˆçŠ¶æ…‹ã¨ã—ã¦ä½¿ç”¨ï¼‰
                    features = env.feature_extractor.get_features(
                        task_obj, developer, env
                    )

                    # RLãƒ¢ãƒ‡ãƒ«ã§è¡Œå‹•ç¢ºç‡ã‚’äºˆæ¸¬
                    obs = features.reshape(1, -1)  # ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ 
                    action_probs = rl_model.predict(obs, deterministic=True)

                    # è¡Œå‹•ç¢ºç‡ã‚’ã‚¹ã‚³ã‚¢ã¨ã—ã¦ä½¿ç”¨
                    if isinstance(action_probs, tuple):
                        score = float(action_probs[0][0])  # æœ€åˆã®è¡Œå‹•ã®ç¢ºç‡
                    else:
                        score = float(action_probs[0])

                    developer_scores.append((dev_name, score))

                except Exception as e:
                    # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    continue

            if not developer_scores:
                task_progress.set_postfix({"Status": "ã‚¹ã‚³ã‚¢è¨ˆç®—å¤±æ•—"})
                continue

            # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰
            developer_scores.sort(key=lambda x: x[1], reverse=True)

            # ä¸Šä½Näººã®æ¨è–¦ãƒªã‚¹ãƒˆã‚’ä½œæˆ
            recommendations = [
                dev_name for dev_name, score in developer_scores[:num_recommendations]
            ]

            # æ­£è§£ç‡ã‚’è¨ˆç®—
            correct_in_top_k = []
            for k in [1, 3, 5]:
                top_k_recs = recommendations[:k]
                hit = any(assignee in top_k_recs for assignee in actual_assignees)
                if hit:
                    results["top_k_hits"][f"top_{k}"] += 1
                correct_in_top_k.append(hit)

            # è©³ç´°çµæœã‚’è¨˜éŒ²
            results["recommendation_details"].append(
                {
                    "task_id": task.get("id"),
                    "task_title": task.get("title", "Unknown")[:50],
                    "actual_assignees": actual_assignees,
                    "recommendations": recommendations,
                    "top_scores": [
                        (dev, float(score)) for dev, score in developer_scores[:5]
                    ],
                    "correct_in_top_1": correct_in_top_k[0],
                    "correct_in_top_3": correct_in_top_k[1],
                    "correct_in_top_5": correct_in_top_k[2],
                }
            )

            results["total_tasks"] += 1
            results["tasks_with_assignees"] += 1

            # é€²æ—ãƒãƒ¼ã®æƒ…å ±æ›´æ–°
            if results["total_tasks"] > 0:
                top1_acc = results["top_k_hits"]["top_1"] / results["total_tasks"]
                top3_acc = results["top_k_hits"]["top_3"] / results["total_tasks"]
                task_progress.set_postfix(
                    {
                        "Top-1": f"{top1_acc:.3f}",
                        "Top-3": f"{top3_acc:.3f}",
                        "å®Œäº†": f"{results['total_tasks']}/{len(eval_tasks)}",
                    }
                )

        except Exception as e:
            print(f"âš ï¸ ã‚¿ã‚¹ã‚¯ {task_idx} ã§ã‚¨ãƒ©ãƒ¼: {e}")
            continue

    return results


def main():
    parser = argparse.ArgumentParser(
        description="å­¦ç¿’æ¸ˆã¿RLãƒ¢ãƒ‡ãƒ«ï¼ˆPPOï¼‰ã‚’2023å¹´ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡"
    )
    parser.add_argument("--config", required=True, help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    parser.add_argument(
        "--rl-model", required=True, help="å­¦ç¿’æ¸ˆã¿RLãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹"
    )
    parser.add_argument(
        "--output", default="rl_evaluation_results_2023.json", help="çµæœå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«"
    )

    args = parser.parse_args()

    print("ğŸš€ 2023å¹´ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®RLè©•ä¾¡é–‹å§‹")
    print(f"ğŸ“ è¨­å®š: {args.config}")
    print(f"ğŸ¤– å­¦ç¿’æ¸ˆã¿RLãƒ¢ãƒ‡ãƒ«: {args.rl_model}")

    # è¨­å®šèª­ã¿è¾¼ã¿
    config = load_config(args.config)

    # å­¦ç¿’æ¸ˆã¿RLãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    print("ğŸ¤– RLãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
    try:
        rl_model = PPO.load(args.rl_model)
        print(f"âœ… RLãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
    except Exception as e:
        print(f"âŒ RLãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        return

    # ãƒãƒƒã‚¯ãƒ­ã‚°ã¨ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("ğŸ“š ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    with open(config.env.backlog_path, "r", encoding="utf-8") as f:
        backlog_data = json.load(f)
    with open(config.env.dev_profiles_path, "r", encoding="utf-8") as f:
        dev_profiles_data = yaml.safe_load(f)

    # ç’°å¢ƒåˆæœŸåŒ–
    print("ğŸŒ ç’°å¢ƒåˆæœŸåŒ–ä¸­...")
    env = OSSSimpleEnv(config, backlog_data, dev_profiles_data)

    print(
        f"ğŸ“Š ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(backlog_data)} ã‚¿ã‚¹ã‚¯, {len(dev_profiles_data)} é–‹ç™ºè€…"
    )

    # RLè©•ä¾¡å®Ÿè¡Œ
    print("ğŸ¤– RLæ¨è–¦è©•ä¾¡å®Ÿè¡Œä¸­...")
    results = evaluate_rl_recommendations(
        backlog_data, dev_profiles_data, rl_model, env
    )

    # çµæœè¨ˆç®—
    total_tasks = results["total_tasks"]
    if total_tasks > 0:
        accuracy_top_1 = results["top_k_hits"]["top_1"] / total_tasks
        accuracy_top_3 = results["top_k_hits"]["top_3"] / total_tasks
        accuracy_top_5 = results["top_k_hits"]["top_5"] / total_tasks

        print("\n" + "=" * 60)
        print("ğŸ¤– RLè©•ä¾¡çµæœ")
        print("=" * 60)
        print(f"è©•ä¾¡ã‚¿ã‚¹ã‚¯æ•°: {total_tasks}")
        print(
            f"Top-1 Accuracy: {accuracy_top_1:.3f} ({results['top_k_hits']['top_1']}/{total_tasks})"
        )
        print(
            f"Top-3 Accuracy: {accuracy_top_3:.3f} ({results['top_k_hits']['top_3']}/{total_tasks})"
        )
        print(
            f"Top-5 Accuracy: {accuracy_top_5:.3f} ({results['top_k_hits']['top_5']}/{total_tasks})"
        )
        print("=" * 60)

        # çµæœã‚’ã¾ã¨ã‚
        final_results = {
            "evaluation_config": args.config,
            "rl_model_path": args.rl_model,
            "total_tasks_evaluated": total_tasks,
            "tasks_with_assignees": results["tasks_with_assignees"],
            "top_1_accuracy": float(accuracy_top_1),
            "top_3_accuracy": float(accuracy_top_3),
            "top_5_accuracy": float(accuracy_top_5),
            "detailed_results": results["recommendation_details"],
        }

        # çµæœä¿å­˜
        output_path = Path(args.output)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(final_results, f, indent=2, ensure_ascii=False)

        print(f"ğŸ’¾ è©³ç´°çµæœã‚’ä¿å­˜: {output_path}")

        # ã‚µãƒ³ãƒ—ãƒ«çµæœè¡¨ç¤º
        print("\nğŸ“‹ ã‚µãƒ³ãƒ—ãƒ«RLæ¨è–¦çµæœ:")
        for i, detail in enumerate(results["recommendation_details"][:3]):
            print(f"\nã‚¿ã‚¹ã‚¯ {i+1}: {detail['task_title']}")
            print(f"  å®Ÿéš›ã®æ‹…å½“è€…: {detail['actual_assignees']}")
            print(f"  RLæ¨è–¦Top-5: {detail['recommendations']}")
            print(f"  Top-1æ­£è§£: {'âœ…' if detail['correct_in_top_1'] else 'âŒ'}")
            print(f"  Top-3æ­£è§£: {'âœ…' if detail['correct_in_top_3'] else 'âŒ'}")

    else:
        print("âš ï¸ è©•ä¾¡ã§ãã‚‹ã‚¿ã‚¹ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


if __name__ == "__main__":
    main()
