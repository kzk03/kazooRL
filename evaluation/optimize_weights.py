#!/usr/bin/env python3
"""
ãƒ¡ã‚¿ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é‡ã¿æœ€é©åŒ–å®Ÿé¨“
"""

import itertools

from advanced_ensemble_system import AdvancedEnsembleSystem
from tqdm import tqdm


def optimize_meta_weights():
    """ãƒ¡ã‚¿ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®é‡ã¿æœ€é©åŒ–"""
    print("ğŸ”§ ãƒ¡ã‚¿ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é‡ã¿æœ€é©åŒ–å®Ÿé¨“")
    print("=" * 50)
    
    system = AdvancedEnsembleSystem(
        model_dir="models/improved_rl/final_models",
        test_data_path="data/backlog_test_2023.json",
    )
    
    # é‡ã¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç”Ÿæˆ
    weight_patterns = {
        "current_best": [0.35, 0.25, 0.25, 0.15],  # ç¾åœ¨ã®ä¸€èˆ¬ãƒ‘ã‚¿ãƒ¼ãƒ³
        "bug_optimized": [0.15, 0.45, 0.25, 0.15],  # ãƒã‚°ä¿®æ­£æœ€é©åŒ–
        "feature_optimized": [0.25, 0.15, 0.45, 0.15],  # æ©Ÿèƒ½é–‹ç™ºæœ€é©åŒ–
        "doc_optimized": [0.15, 0.15, 0.55, 0.15],  # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæœ€é©åŒ–
        "experience_heavy": [0.10, 0.60, 0.20, 0.10],  # çµŒé¨“è¶…é‡è¦–
        "similarity_heavy": [0.20, 0.15, 0.50, 0.15],  # é¡ä¼¼åº¦è¶…é‡è¦–
        "balanced_new": [0.25, 0.30, 0.30, 0.15],  # æ–°ãƒãƒ©ãƒ³ã‚¹
    }
    
    # è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™
    available_agents = set(system.models.keys())
    eval_tasks = []
    eval_ground_truth = []
    
    for task, author in zip(system.tasks[:300], system.ground_truth[:300]):
        if author in available_agents and len(eval_tasks) < 100:
            eval_tasks.append(task)
            eval_ground_truth.append(author)
    
    results = {}
    
    for pattern_name, base_weights in weight_patterns.items():
        print(f"\nğŸ” {pattern_name}ãƒ‘ã‚¿ãƒ¼ãƒ³è©•ä¾¡ä¸­...")
        
        correct_count = 0
        
        for task, actual_author in tqdm(zip(eval_tasks, eval_ground_truth), 
                                      desc=f"{pattern_name}", 
                                      total=len(eval_tasks)):
            try:
                # ã‚«ã‚¹ã‚¿ãƒ é‡ã¿ã§ãƒ¡ã‚¿ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å®Ÿè¡Œ
                task_features = system._extract_task_features(task)
                
                # å„æ‰‹æ³•ã®ã‚¹ã‚³ã‚¢å–å¾—
                methods_results = {}
                
                # åŸºæœ¬ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
                basic_scores = {}
                for agent_name, model in system.models.items():
                    try:
                        ppo_score = model.get_action_score(task_features)
                        contribution = system.author_contributions.get(agent_name, 0)
                        contribution_score = min(contribution / 100.0, 1.0)
                        similarity_score = system._calculate_task_similarity(task, agent_name)
                        basic_score = (0.4 * ppo_score + 0.4 * contribution_score + 0.2 * similarity_score)
                        basic_scores[agent_name] = basic_score
                    except:
                        basic_scores[agent_name] = 0.0
                
                methods_results["basic"] = basic_scores
                
                # ä»–ã®æ‰‹æ³•ã®ã‚¹ã‚³ã‚¢
                contribution_scores = {agent: min(system.author_contributions.get(agent, 0) / 200.0, 1.0) 
                                     for agent in system.models.keys()}
                similarity_scores = {agent: system._calculate_task_similarity(task, agent) 
                                   for agent in system.models.keys()}
                temporal_scores = {agent: system._calculate_temporal_match(task, agent) 
                                 for agent in system.models.keys()}
                
                methods_results["contribution"] = contribution_scores
                methods_results["similarity"] = similarity_scores  
                methods_results["temporal"] = temporal_scores
                
                # ã‚«ã‚¹ã‚¿ãƒ é‡ã¿ã§çµ±åˆ
                final_scores = {}
                for agent_name in system.models.keys():
                    basic_score = methods_results["basic"].get(agent_name, 0.0)
                    contrib_score = methods_results["contribution"].get(agent_name, 0.0)
                    sim_score = methods_results["similarity"].get(agent_name, 0.0)
                    temp_score = methods_results["temporal"].get(agent_name, 0.0)
                    
                    # ã‚«ã‚¹ã‚¿ãƒ é‡ã¿ã‚’é©ç”¨
                    meta_score = (
                        base_weights[0] * basic_score +
                        base_weights[1] * contrib_score +
                        base_weights[2] * sim_score +
                        base_weights[3] * temp_score
                    )
                    
                    # ãƒ–ãƒ¼ã‚¹ãƒˆé©ç”¨
                    contribution = system.author_contributions.get(agent_name, 0)
                    if contribution >= 200:
                        meta_score *= 1.2
                    elif contribution >= 100:
                        meta_score *= 1.15
                    elif contribution >= 50:
                        meta_score *= 1.1
                    
                    final_scores[agent_name] = min(meta_score, 1.0)
                
                # Top-1äºˆæ¸¬
                top_agent = max(final_scores.items(), key=lambda x: x[1])[0]
                if top_agent == actual_author:
                    correct_count += 1
                    
            except Exception as e:
                continue
        
        accuracy = correct_count / len(eval_tasks)
        results[pattern_name] = {
            "accuracy": accuracy,
            "weights": base_weights,
            "correct_count": correct_count,
            "total_count": len(eval_tasks)
        }
        
        print(f"   ç²¾åº¦: {accuracy*100:.1f}% ({correct_count}/{len(eval_tasks)})")
    
    # çµæœè¡¨ç¤º
    print(f"\n## ğŸ† é‡ã¿æœ€é©åŒ–çµæœ")
    print("=" * 60)
    
    sorted_results = sorted(results.items(), key=lambda x: x[1]["accuracy"], reverse=True)
    
    print("| é †ä½ | ãƒ‘ã‚¿ãƒ¼ãƒ³å | ç²¾åº¦ | åŸºæœ¬ | è²¢çŒ® | é¡ä¼¼ | æ™‚é–“ |")
    print("|------|------------|------|------|------|------|------|")
    
    for i, (pattern_name, result) in enumerate(sorted_results):
        accuracy = result["accuracy"]
        weights = result["weights"]
        print(f"| {i+1} | {pattern_name} | {accuracy*100:.1f}% | {weights[0]:.2f} | {weights[1]:.2f} | {weights[2]:.2f} | {weights[3]:.2f} |")
    
    # æœ€é©é‡ã¿ã®ææ¡ˆ
    best_pattern, best_result = sorted_results[0]
    print(f"\nğŸ¯ æœ€é©é‡ã¿ãƒ‘ã‚¿ãƒ¼ãƒ³: {best_pattern}")
    print(f"   ç²¾åº¦: {best_result['accuracy']*100:.1f}%")
    print(f"   æ¨å¥¨é‡ã¿: {best_result['weights']}")


if __name__ == "__main__":
    optimize_meta_weights()