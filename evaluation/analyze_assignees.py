#!/usr/bin/env python3
"""
å®Ÿéš›ã®æ‹…å½“è€…ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ
"""

import json
import sys
from collections import Counter
from pathlib import Path


def analyze_assignees(test_data_path: str):
    """æ‹…å½“è€…ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ"""
    print(f"ğŸ“Š æ‹…å½“è€…ãƒ‡ãƒ¼ã‚¿åˆ†æ: {test_data_path}")
    
    with open(test_data_path, "r", encoding="utf-8") as f:
        test_data = json.load(f)
    
    all_assignees = []
    tasks_with_assignees = 0
    
    print("\nğŸ” æ‹…å½“è€…æƒ…å ±ã®è©³ç´°åˆ†æ:")
    
    for i, task in enumerate(test_data[:10]):  # æœ€åˆã®10å€‹ã‚’è©³ç´°è¡¨ç¤º
        assignees = task.get("assignees", [])
        print(f"\nã‚¿ã‚¹ã‚¯ {i+1}:")
        print(f"  ID: {task.get('id')}")
        print(f"  Title: {task.get('title', '')[:50]}...")
        print(f"  Assignees: {assignees}")
        
        if assignees:
            tasks_with_assignees += 1
            for assignee in assignees:
                if isinstance(assignee, dict):
                    login = assignee.get("login", "unknown")
                    all_assignees.append(login)
                    print(f"    - {login}")
                else:
                    all_assignees.append(str(assignee))
                    print(f"    - {assignee}")
    
    # å…¨ä½“çµ±è¨ˆ
    total_with_assignees = sum(1 for task in test_data if task.get("assignees"))
    assignee_counter = Counter(all_assignees)
    
    print(f"\nğŸ“ˆ å…¨ä½“çµ±è¨ˆ:")
    print(f"  ç·ã‚¿ã‚¹ã‚¯æ•°: {len(test_data):,}")
    print(f"  æ‹…å½“è€…ã‚ã‚Šã‚¿ã‚¹ã‚¯æ•°: {total_with_assignees:,}")
    print(f"  æ‹…å½“è€…ã‚ã‚Šç‡: {total_with_assignees/len(test_data)*100:.1f}%")
    print(f"  ãƒ¦ãƒ‹ãƒ¼ã‚¯æ‹…å½“è€…æ•°: {len(assignee_counter)}")
    
    print(f"\nğŸ‘¥ ä¸Šä½æ‹…å½“è€…:")
    for assignee, count in assignee_counter.most_common(10):
        print(f"  {assignee}: {count}ã‚¿ã‚¹ã‚¯")
    
    # è¨“ç·´ã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåã¨ã®æ¯”è¼ƒ
    import os
    model_dir = "models/improved_rl/final_models"
    if os.path.exists(model_dir):
        model_files = [f for f in os.listdir(model_dir) if f.endswith('.pth')]
        trained_agents = [f.replace('agent_', '').replace('.pth', '') for f in model_files[:10]]
        
        print(f"\nğŸ¤– è¨“ç·´ã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä¾‹:")
        for agent in trained_agents:
            print(f"  {agent}")
        
        # ä¸€è‡´ã™ã‚‹åå‰ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        actual_assignees = set(all_assignees)
        trained_set = set(trained_agents)
        matches = actual_assignees.intersection(trained_set)
        
        print(f"\nğŸ¯ åå‰ã®ä¸€è‡´:")
        print(f"  ä¸€è‡´ã™ã‚‹åå‰æ•°: {len(matches)}")
        if matches:
            print(f"  ä¸€è‡´ã™ã‚‹åå‰: {list(matches)}")
        else:
            print("  ä¸€è‡´ã™ã‚‹åå‰ãªã— - ä»£æ›¿è©•ä¾¡æ–¹æ³•ãŒå¿…è¦")

if __name__ == "__main__":
    analyze_assignees("data/backlog_test_2023.json")