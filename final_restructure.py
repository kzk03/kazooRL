#!/usr/bin/env python3
"""
Kazooãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã®æœ€çµ‚ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å…¨ã¦ã®åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’çµ±åˆã—ã€é‡è¤‡ã‚’æ’é™¤ã™ã‚‹
"""

import os
import shutil
from pathlib import Path


def main():
    print("=== Kazoo ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæœ€çµ‚ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°é–‹å§‹ ===\n")
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    root_dir = Path("/Users/kazuki-h/rl/kazoo")
    
    # ç§»å‹•ã™ã¹ããƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    file_moves = {
        # åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’analysis/reportsã«çµ±åˆ
        "analyze_collaboration.py": "analysis/reports/collaboration_analysis.py",
        "analyze_gat_features.py": "analysis/reports/gat_analysis.py",  # æ—¢å­˜ã®åŒåãƒ•ã‚¡ã‚¤ãƒ«ã¨çµ±åˆ
        "analyze_irl_collaboration.py": "analysis/reports/irl_collaboration_analysis.py",
        "analyze_irl_completion.py": "analysis/reports/irl_completion_analysis.py", 
        "analyze_irl_feature_weights.py": "analysis/reports/irl_weights_analysis.py",
        "analyze_training_results.py": "analysis/reports/training_analysis.py",  # æ—¢å­˜ã®åŒåãƒ•ã‚¡ã‚¤ãƒ«ã¨çµ±åˆ
        "simple_irl_analysis.py": "analysis/reports/simple_irl_analysis.py",
        "generate_summary_report.py": "analysis/reports/summary_report.py",  # æ—¢å­˜ã®åŒåãƒ•ã‚¡ã‚¤ãƒ«ã¨çµ±åˆ
        
        # è©•ä¾¡ãƒ»ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
        "test_feature_dimensions.py": "evaluation/test_feature_dimensions.py",
        
        # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
        "run_full_training_from_scratch.py": "pipelines/full_training_pipeline.py",
        
        # utilsãƒ•ã‚©ãƒ«ãƒ€ã«ç§»å‹•ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
        "project_restructure_plan.py": "utils/project_restructure_plan.py",
        "execute_restructure.py": "utils/execute_restructure.py",
    }
    
    # toolsãƒ•ã‚©ãƒ«ãƒ€ã®å†…å®¹ã‚’ãƒ¡ã‚¤ãƒ³ãƒ•ã‚©ãƒ«ãƒ€ã«çµ±åˆ
    tools_moves = {
        "tools/analysis/analyze_weights.py": "analysis/reports/weights_analysis.py",
        "tools/analysis/create_expert_trajectories.py": "data_processing/create_expert_trajectories.py", 
        "tools/analysis/create_expert_trajectories_bot_excluded.py": "data_processing/create_expert_trajectories_bot_excluded.py",
        "tools/data_processing/get_github_data.py": "data_processing/extract_github_data.py",  # æ—¢å­˜ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨çµ±åˆ
        "tools/data_processing/generate_backlog.py": "data_processing/generate_backlog.py",  # æ—¢å­˜ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨çµ±åˆ
        "tools/data_processing/generate_profiles.py": "data_processing/generate_profiles.py",  # æ—¢å­˜ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨çµ±åˆ
        "tools/data_processing/generate_labels.py": "data_processing/generate_labels.py",  # æ—¢å­˜ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨çµ±åˆ
        "tools/data_processing/generate_graph.py": "data_processing/generate_graph.py",  # æ—¢å­˜ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨çµ±åˆ
        "tools/data_processing/build_developer_network.py": "data_processing/build_network.py",  # æ—¢å­˜ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨çµ±åˆ
    }
    
    # scriptsãƒ•ã‚©ãƒ«ãƒ€ã®æ•´ç†
    scripts_moves = {
        "scripts/train_collaborative_gat.py": "training/gat/train_collaborative_gat.py",
        "scripts/plot_gnn_graph.py": "analysis/visualization/plot_gnn_graph.py",
        "scripts/run_complete_pipeline.py": "pipelines/complete_pipeline.py",
        "scripts/retrain_gnn_with_recent_data.py": "training/gat/retrain_gnn_with_recent_data.py",
        "scripts/train_irl.py": "training/irl/train_irl.py",  # æ—¢å­˜ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨çµ±åˆ
        "scripts/full_training_pipeline.py": "pipelines/full_training_pipeline.py",  # ä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨çµ±åˆ
        "scripts/train_gnn.py": "training/gat/train_gnn.py",
        "scripts/train_oss.py": "training/rl/train_oss.py",
        "scripts/evaluate_2022_test.py": "evaluation/evaluate_2022_test.py",
    }
    
    # å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    directories_to_create = [
        "analysis/visualization",
        "utils",
        "training/gat",
        "training/irl", 
        "training/rl",
        "evaluation",
        "pipelines"
    ]
    
    for dir_path in directories_to_create:
        full_path = root_dir / dir_path
        full_path.mkdir(parents=True, exist_ok=True)
        # __init__.pyãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        init_file = full_path / "__init__.py"
        if not init_file.exists():
            init_file.write_text("")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»å‹•
    all_moves = {**file_moves, **tools_moves, **scripts_moves}
    
    for src, dst in all_moves.items():
        src_path = root_dir / src
        dst_path = root_dir / dst
        
        if src_path.exists():
            print(f"ç§»å‹•: {src} -> {dst}")
            if dst_path.exists():
                print(f"  è­¦å‘Š: æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ« {dst} ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã—ã¾ã™")
                backup_path = dst_path.with_suffix(dst_path.suffix + ".backup")
                shutil.move(str(dst_path), str(backup_path))
            
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
            dst_path.parent.mkdir(parents=True, exist_ok=True)
            shutil.move(str(src_path), str(dst_path))
        else:
            print(f"ã‚¹ã‚­ãƒƒãƒ—: {src} (ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“)")
    
    print("\n=== utilsãƒ•ã‚©ãƒ«ãƒ€ã®å†…å®¹ã‚’ä½œæˆ ===")
    
    # utilsã«project_setup.pyã‚’ä½œæˆ
    project_setup_content = '''#!/usr/bin/env python3
"""
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåˆæœŸåŒ–
"""

import os
from pathlib import Path

def setup_project_directories():
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
    dirs = [
        "data",
        "logs", 
        "models",
        "outputs",
        "results",
        "configs"
    ]
    
    for dir_name in dirs:
        Path(dir_name).mkdir(exist_ok=True)
        print(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {dir_name}")

def verify_dependencies():
    """ä¾å­˜é–¢ä¿‚ã®ç¢ºèª"""
    try:
        import torch
        import numpy as np
        import yaml
        import json
        print("âœ“ å¿…è¦ãªä¾å­˜é–¢ä¿‚ãŒå…¨ã¦åˆ©ç”¨å¯èƒ½ã§ã™")
        return True
    except ImportError as e:
        print(f"âœ— ä¾å­˜é–¢ä¿‚ã‚¨ãƒ©ãƒ¼: {e}")
        return False

if __name__ == "__main__":
    setup_project_directories()
    verify_dependencies()
'''
    
    utils_setup_file = root_dir / "utils" / "project_setup.py"
    utils_setup_file.write_text(project_setup_content)
    
    # utilsã«config_manager.pyã‚’ä½œæˆ
    config_manager_content = '''#!/usr/bin/env python3
"""
è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ç®¡ç†
"""

import yaml
from pathlib import Path

class ConfigManager:
    def __init__(self, config_dir="configs"):
        self.config_dir = Path(config_dir)
    
    def load_config(self, config_name):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        config_path = self.config_dir / f"{config_name}.yaml"
        if config_path.exists():
            with open(config_path, 'r') as f:
                return yaml.safe_load(f)
        else:
            raise FileNotFoundError(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}")
    
    def save_config(self, config_name, config_data):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜"""
        config_path = self.config_dir / f"{config_name}.yaml"
        self.config_dir.mkdir(exist_ok=True)
        with open(config_path, 'w') as f:
            yaml.dump(config_data, f, default_flow_style=False)
'''
    
    config_manager_file = root_dir / "utils" / "config_manager.py"
    config_manager_file.write_text(config_manager_content)
    
    print("\n=== visualizationç”¨ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆ ===")
    
    # analysis/visualization/plot_results.pyã‚’ä½œæˆ
    plot_results_content = '''#!/usr/bin/env python3
"""
çµæœã®å¯è¦–åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path

def plot_training_metrics(log_file):
    """ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ãƒ—ãƒ­ãƒƒãƒˆ"""
    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
    pass

def plot_irl_weights(weights_file):
    """IRLé‡ã¿ã®å¯è¦–åŒ–"""
    if Path(weights_file).exists():
        weights = np.load(weights_file)
        plt.figure(figsize=(10, 6))
        plt.bar(range(len(weights)), weights)
        plt.title("IRL Feature Weights")
        plt.xlabel("Feature Index")
        plt.ylabel("Weight")
        plt.show()

def plot_gat_features(features_file):
    """GATç‰¹å¾´é‡ã®å¯è¦–åŒ–"""
    # ç‰¹å¾´é‡ã®å¯è¦–åŒ–ãƒ­ã‚¸ãƒƒã‚¯
    pass

if __name__ == "__main__":
    print("å¯è¦–åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒå®Ÿè¡Œã•ã‚Œã¾ã—ãŸ")
'''
    
    plot_results_file = root_dir / "analysis" / "visualization" / "plot_results.py"
    plot_results_file.write_text(plot_results_content)
    
    print("\n=== å¤ã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å‰Šé™¤ç¢ºèª ===")
    
    # ç©ºã«ãªã£ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤
    old_dirs = ["tools", "scripts"]
    for old_dir in old_dirs:
        old_path = root_dir / old_dir
        if old_path.exists():
            try:
                # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒç©ºã‹ãƒã‚§ãƒƒã‚¯
                if not any(old_path.iterdir()):
                    old_path.rmdir()
                    print(f"ç©ºã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤: {old_dir}")
                else:
                    print(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«æ®‹ã‚Šãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã™: {old_dir}")
                    for item in old_path.iterdir():
                        print(f"  - {item.name}")
            except OSError:
                print(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‰Šé™¤ã«å¤±æ•—: {old_dir}")
    
    print("\n=== æ–°ã—ã„READMEã‚’ä½œæˆ ===")
    
    new_readme_content = '''# Kazoo - å¼·åŒ–å­¦ç¿’ãƒ™ãƒ¼ã‚¹ã®OSSé–‹ç™ºæ”¯æ´ã‚·ã‚¹ãƒ†ãƒ 

## ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```
kazoo/
â”œâ”€â”€ src/kazoo/           # ãƒ¡ã‚¤ãƒ³ã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰
â”œâ”€â”€ training/            # å„ç¨®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”‚   â”œâ”€â”€ gat/            # Graph Attention Networké–¢é€£
â”‚   â”œâ”€â”€ irl/            # Inverse Reinforcement Learningé–¢é€£
â”‚   â””â”€â”€ rl/             # Reinforcement Learningé–¢é€£
â”œâ”€â”€ analysis/            # åˆ†æãƒ»ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
â”‚   â”œâ”€â”€ reports/        # å„ç¨®åˆ†æãƒ¬ãƒãƒ¼ãƒˆ
â”‚   â””â”€â”€ visualization/  # å¯è¦–åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ evaluation/          # ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ãƒ»ãƒ†ã‚¹ãƒˆ
â”œâ”€â”€ data_processing/     # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
â”œâ”€â”€ pipelines/          # ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
â”œâ”€â”€ utils/              # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
â”œâ”€â”€ configs/            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ data/               # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ models/             # ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«
â””â”€â”€ outputs/            # å‡ºåŠ›çµæœ

```

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
```bash
python utils/project_setup.py
```

### 2. ãƒ‡ãƒ¼ã‚¿æº–å‚™
```bash
python data_processing/generate_graph.py
python data_processing/generate_profiles.py
python data_processing/generate_labels.py
```

### 3. å®Œå…¨ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
```bash
python pipelines/full_pipeline.py
```

### 4. å€‹åˆ¥ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°

#### GAT (Graph Attention Network)
```bash
python training/gat/train_gat.py
```

#### IRL (Inverse Reinforcement Learning)  
```bash
python training/irl/train_irl.py
```

#### RL (Reinforcement Learning)
```bash
python training/rl/train_rl.py
```

## ğŸ“Š åˆ†æãƒ»ãƒ¬ãƒãƒ¼ãƒˆ

### åŒ…æ‹¬çš„ãªåˆ†æãƒ¬ãƒãƒ¼ãƒˆ
```bash
python analysis/reports/summary_report.py
```

### å€‹åˆ¥åˆ†æ
- **IRLåˆ†æ**: `python analysis/reports/irl_analysis.py`
- **GATåˆ†æ**: `python analysis/reports/gat_analysis.py`
- **å”åŠ›é–¢ä¿‚åˆ†æ**: `python analysis/reports/collaboration_analysis.py`
- **ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµæœåˆ†æ**: `python analysis/reports/training_analysis.py`

### å¯è¦–åŒ–
```bash
python analysis/visualization/plot_results.py
```

## ğŸ§ª è©•ä¾¡ãƒ»ãƒ†ã‚¹ãƒˆ

```bash
python evaluation/evaluate_models.py
python evaluation/test_features.py
```

## ğŸ“‹ ä¸»è¦æ©Ÿèƒ½

- **GAT**: é–‹ç™ºè€…é–“ã®å”åŠ›é–¢ä¿‚ã‚’ãƒ¢ãƒ‡ãƒªãƒ³ã‚°
- **IRL**: å°‚é–€å®¶ã®è¡Œå‹•ã‹ã‚‰å ±é…¬é–¢æ•°ã‚’å­¦ç¿’
- **RL**: PPOã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã‚‹åŠ¹æœçš„ãªé–‹ç™ºè€…æ¨è–¦
- **åˆ†æ**: è©³ç´°ãªé‡ã¿åˆ†æã¨å¯è¦–åŒ–
- **è©•ä¾¡**: åŒ…æ‹¬çš„ãªãƒ¢ãƒ‡ãƒ«æ€§èƒ½è©•ä¾¡

## ğŸ”§ è¨­å®š

è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¯`configs/`ãƒ•ã‚©ãƒ«ãƒ€ã«é…ç½®ï¼š
- `base.yaml`: åŸºæœ¬è¨­å®š
- `dev_profiles.yaml`: é–‹ç™ºè€…ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«

## ğŸ“ˆ æ”¹å–„ã•ã‚ŒãŸãƒã‚¤ãƒ³ãƒˆ

1. **æ©Ÿèƒ½åˆ¥ã®æ˜ç¢ºãªåˆ†é›¢**: GATã€IRLã€RLã€åˆ†æã€ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãŒç‹¬ç«‹
2. **çµ±ä¸€ã•ã‚ŒãŸåˆ†æã‚·ã‚¹ãƒ†ãƒ **: å…¨ã¦ã®åˆ†æãŒ`analysis/`ãƒ•ã‚©ãƒ«ãƒ€ã«é›†ç´„
3. **ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**: `pipelines/`ã§å®Œå…¨è‡ªå‹•åŒ–
4. **å……å®Ÿã—ãŸè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ **: `evaluation/`ã§åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ
5. **å†åˆ©ç”¨å¯èƒ½ãªãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£**: `utils/`ã§å…±é€šæ©Ÿèƒ½

## ğŸ—ï¸ é–‹ç™ºè€…å‘ã‘

æ–°ã—ã„æ©Ÿèƒ½ã®è¿½åŠ æ™‚ã¯ã€é©åˆ‡ãªãƒ•ã‚©ãƒ«ãƒ€ã«é…ç½®ã—ã¦ãã ã•ã„ï¼š
- ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–¢é€£: `training/`
- åˆ†æé–¢é€£: `analysis/`
- è©•ä¾¡é–¢é€£: `evaluation/`
- ãƒ‡ãƒ¼ã‚¿å‡¦ç†: `data_processing/`
'''
    
    new_readme_file = root_dir / "README_FINAL.md"
    new_readme_file.write_text(new_readme_content)
    
    print("\n=== æœ€çµ‚ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å®Œäº† ===")
    print("æ–°ã—ã„æ§‹é€ :")
    print("- training/ (GAT, IRL, RL)")
    print("- analysis/ (reports, visualization)")
    print("- evaluation/ (ãƒ†ã‚¹ãƒˆãƒ»è©•ä¾¡)")
    print("- data_processing/ (ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†)")
    print("- pipelines/ (ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³)")
    print("- utils/ (ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£)")
    print("\nè©³ç´°ã¯ README_FINAL.md ã‚’å‚ç…§ã—ã¦ãã ã•ã„")

if __name__ == "__main__":
    main()
