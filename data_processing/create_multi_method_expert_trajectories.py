#!/usr/bin/env python3
"""
ãƒãƒ«ãƒãƒ¡ã‚½ãƒƒãƒ‰ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆè»Œè·¡ç”Ÿæˆ

3ã¤ã®æŠ½å‡ºæ–¹æ³•ï¼ˆassignees, creators, allï¼‰ã§ãã‚Œãã‚Œç‹¬ç«‹ã—ãŸ
ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆè»Œè·¡ã‚’ç”Ÿæˆã—ã€é€†å¼·åŒ–å­¦ç¿’ã§ä½¿ç”¨ã™ã‚‹ã€‚

ã“ã‚Œã«ã‚ˆã‚Šã€å„æŠ½å‡ºæ–¹æ³•ã«ç‰¹åŒ–ã—ãŸå ±é…¬é–¢æ•°ã‚’å­¦ç¿’ã§ãã‚‹ã€‚
"""

import argparse
import json
import os
import pickle
import sys
from collections import Counter, defaultdict
from datetime import datetime
from pathlib import Path

import numpy as np

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from evaluation.simple_similarity_recommender import SimpleSimilarityRecommender


class MultiMethodExpertTrajectoryGenerator:
    """ãƒãƒ«ãƒãƒ¡ã‚½ãƒƒãƒ‰ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆè»Œè·¡ç”Ÿæˆå™¨"""
    
    def __init__(self, config_path="configs/multi_method_training.yaml"):
        self.config_path = config_path
        
        # SimpleSimilarityRecommenderã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿å‡¦ç†
        self.recommender = SimpleSimilarityRecommender('configs/unified_rl.yaml')
        
        # æŠ½å‡ºæ–¹æ³•
        self.extraction_methods = ['assignees', 'creators', 'all']
        
        print("ğŸ¯ ãƒãƒ«ãƒãƒ¡ã‚½ãƒƒãƒ‰ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆè»Œè·¡ç”Ÿæˆå™¨åˆæœŸåŒ–å®Œäº†")
    
    def generate_all_expert_trajectories(self, data_path="data/backlog.json"):
        """å…¨ã¦ã®æŠ½å‡ºæ–¹æ³•ã§ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆè»Œè·¡ã‚’ç”Ÿæˆ"""
        print("ğŸš€ ãƒãƒ«ãƒãƒ¡ã‚½ãƒƒãƒ‰ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆè»Œè·¡ç”Ÿæˆé–‹å§‹")
        print("=" * 70)
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        training_data, test_data = self.recommender.load_data(data_path)
        
        results = {}
        
        for method in self.extraction_methods:
            print(f"\nğŸ“š {method.upper()}ãƒ¡ã‚½ãƒƒãƒ‰ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆè»Œè·¡ç”Ÿæˆ...")
            
            # å„æ–¹æ³•ã§ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆè»Œè·¡ã‚’ç”Ÿæˆ
            expert_trajectories = self.generate_expert_trajectories(
                training_data, method
            )
            
            # ä¿å­˜
            output_path = f"data/expert_trajectories_{method}.pkl"
            self.save_expert_trajectories(expert_trajectories, output_path)
            
            results[method] = {
                'trajectories': len(expert_trajectories),
                'output_path': output_path,
                'unique_developers': len(set([traj['developer'] for traj in expert_trajectories])),
                'total_actions': sum([len(traj['actions']) for traj in expert_trajectories])
            }
            
            print(f"   è»Œè·¡æ•°: {results[method]['trajectories']}")
            print(f"   é–‹ç™ºè€…æ•°: {results[method]['unique_developers']}")
            print(f"   ç·ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°: {results[method]['total_actions']}")
            print(f"   ä¿å­˜å…ˆ: {output_path}")
        
        # çµæœæ¯”è¼ƒ
        self.compare_trajectories(results)
        
        return results
    
    def generate_expert_trajectories(self, training_data, extraction_method):
        """ç‰¹å®šã®æŠ½å‡ºæ–¹æ³•ã§ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆè»Œè·¡ã‚’ç”Ÿæˆ"""
        
        # å­¦ç¿’ãƒšã‚¢ã‚’æŠ½å‡º
        training_pairs, developer_stats = self.recommender.extract_training_pairs(
            training_data, extraction_method=extraction_method
        )
        
        if not training_pairs:
            print(f"âš ï¸ {extraction_method}ã§å­¦ç¿’ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return []
        
        # é–‹ç™ºè€…åˆ¥ã«è»Œè·¡ã‚’æ§‹ç¯‰
        developer_trajectories = defaultdict(list)
        
        for pair in training_pairs:
            developer = pair['developer']
            task_data = pair['task_data']
            
            # ã‚¿ã‚¹ã‚¯ã®çŠ¶æ…‹ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½œæˆ
            state_vector = self._create_state_vector(task_data, extraction_method)
            
            # é–‹ç™ºè€…ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆã“ã®ã‚¿ã‚¹ã‚¯ã‚’é¸æŠï¼‰
            action = {
                'task_id': pair['task_id'],
                'task_data': task_data,
                'state': state_vector,
                'timestamp': task_data.get('created_at', ''),
                'extraction_source': pair.get('extraction_source', extraction_method)
            }
            
            developer_trajectories[developer].append(action)
        
        # è»Œè·¡å½¢å¼ã«å¤‰æ›
        expert_trajectories = []
        
        for developer, actions in developer_trajectories.items():
            if len(actions) >= 2:  # æœ€ä½2ã¤ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒå¿…è¦
                # æ™‚ç³»åˆ—é †ã«ã‚½ãƒ¼ãƒˆ
                actions.sort(key=lambda x: x['timestamp'])
                
                trajectory = {
                    'developer': developer,
                    'extraction_method': extraction_method,
                    'actions': actions,
                    'total_tasks': len(actions),
                    'timespan': self._calculate_timespan(actions),
                    'activity_score': len(actions) / max(1, developer_stats.get(developer, 1))
                }
                
                expert_trajectories.append(trajectory)
        
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
        expert_trajectories.sort(key=lambda x: x['activity_score'], reverse=True)
        
        return expert_trajectories
    
    def _create_state_vector(self, task_data, extraction_method):
        """ã‚¿ã‚¹ã‚¯ã®çŠ¶æ…‹ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½œæˆ"""
        
        # åŸºæœ¬ç‰¹å¾´é‡
        basic_features = self.recommender.extract_basic_features(task_data)
        
        # æ­£è¦åŒ–ã•ã‚ŒãŸç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«
        state_vector = np.array([
            min(1.0, basic_features.get('title_length', 0) / 100),
            min(1.0, basic_features.get('body_length', 0) / 1000),
            min(1.0, basic_features.get('comments_count', 0) / 20),
            basic_features.get('is_bug', 0),
            basic_features.get('is_enhancement', 0),
            basic_features.get('is_documentation', 0),
            basic_features.get('is_question', 0),
            basic_features.get('is_help_wanted', 0),
            min(1.0, basic_features.get('label_count', 0) / 10),
            basic_features.get('is_open', 0),
            # æŠ½å‡ºæ–¹æ³•åˆ¥ã®ç‰¹å¾´é‡
            self._get_extraction_method_features(extraction_method)
        ], dtype=np.float32)
        
        return state_vector
    
    def _get_extraction_method_features(self, extraction_method):
        """æŠ½å‡ºæ–¹æ³•åˆ¥ã®ç‰¹å¾´é‡"""
        if extraction_method == 'assignees':
            return 1.0  # é«˜å“è³ªãƒ»ç‹­ã„ã‚«ãƒãƒ¬ãƒƒã‚¸
        elif extraction_method == 'creators':
            return 0.5  # åºƒã„ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ»ä¸­å“è³ª
        elif extraction_method == 'all':
            return 0.8  # ãƒãƒ©ãƒ³ã‚¹å‹
        else:
            return 0.0
    
    def _calculate_timespan(self, actions):
        """ã‚¢ã‚¯ã‚·ãƒ§ãƒ³åˆ—ã®æ™‚é–“ã‚¹ãƒ‘ãƒ³ã‚’è¨ˆç®—"""
        if len(actions) < 2:
            return 0
        
        try:
            first_time = datetime.fromisoformat(actions[0]['timestamp'].replace('Z', '+00:00'))
            last_time = datetime.fromisoformat(actions[-1]['timestamp'].replace('Z', '+00:00'))
            return (last_time - first_time).days
        except:
            return 0
    
    def save_expert_trajectories(self, expert_trajectories, output_path):
        """ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆè»Œè·¡ã‚’ä¿å­˜"""
        output_path = Path(output_path)
        output_path.parent.mkdir(exist_ok=True)
        
        with open(output_path, 'wb') as f:
            pickle.dump(expert_trajectories, f)
        
        print(f"âœ… ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆè»Œè·¡ä¿å­˜: {output_path}")
    
    def compare_trajectories(self, results):
        """è»Œè·¡ã®æ¯”è¼ƒåˆ†æ"""
        print("\nğŸ“ˆ ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆè»Œè·¡æ¯”è¼ƒåˆ†æ")
        print("=" * 70)
        
        print("æ–¹æ³•         | è»Œè·¡æ•° | é–‹ç™ºè€…æ•° | ç·ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ | å¹³å‡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³/è»Œè·¡")
        print("-" * 70)
        
        for method in self.extraction_methods:
            if method in results:
                result = results[method]
                avg_actions = result['total_actions'] / max(1, result['trajectories'])
                print(f"{method:12} | {result['trajectories']:6} | {result['unique_developers']:8} | {result['total_actions']:12} | {avg_actions:15.1f}")
        
        # å“è³ªåˆ†æ
        print(f"\nğŸ” å“è³ªåˆ†æ:")
        for method in self.extraction_methods:
            if method in results:
                result = results[method]
                
                # ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æ
                coverage = result['total_actions'] / max(1, sum(r['total_actions'] for r in results.values())) * 100
                
                # å¯†åº¦åˆ†æ
                density = result['total_actions'] / max(1, result['unique_developers'])
                
                print(f"\n{method.upper()}:")
                print(f"  ã‚«ãƒãƒ¬ãƒƒã‚¸: {coverage:.1f}%")
                print(f"  é–‹ç™ºè€…ã‚ãŸã‚Šè»Œè·¡å¯†åº¦: {density:.1f}")
                
                if method == 'assignees':
                    print(f"  ç‰¹å¾´: é«˜å“è³ªãƒ»ç‹­ã„ã‚«ãƒãƒ¬ãƒƒã‚¸ï¼ˆæ­£å¼å‰²ã‚Šå½“ã¦ã®ã¿ï¼‰")
                elif method == 'creators':
                    print(f"  ç‰¹å¾´: åºƒã„ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ»ä¸­å“è³ªï¼ˆIssue/PRä½œæˆè€…ã‚‚å«ã‚€ï¼‰")
                elif method == 'all':
                    print(f"  ç‰¹å¾´: ãƒãƒ©ãƒ³ã‚¹å‹ï¼ˆassigneeså„ªå…ˆ + creatorsè£œå®Œï¼‰")
    
    def load_and_analyze_trajectories(self, method):
        """ä¿å­˜ã•ã‚ŒãŸè»Œè·¡ã‚’èª­ã¿è¾¼ã‚“ã§åˆ†æ"""
        trajectory_path = f"data/expert_trajectories_{method}.pkl"
        
        try:
            with open(trajectory_path, 'rb') as f:
                trajectories = pickle.load(f)
            
            print(f"\nğŸ“Š {method.upper()}è»Œè·¡è©³ç´°åˆ†æ:")
            print(f"   è»Œè·¡æ•°: {len(trajectories)}")
            
            # é–‹ç™ºè€…åˆ¥çµ±è¨ˆ
            dev_stats = Counter([traj['developer'] for traj in trajectories])
            print(f"   ä¸Šä½é–‹ç™ºè€…:")
            for dev, count in dev_stats.most_common(5):
                avg_tasks = np.mean([traj['total_tasks'] for traj in trajectories if traj['developer'] == dev])
                print(f"     {dev}: {count} è»Œè·¡, å¹³å‡ {avg_tasks:.1f} ã‚¿ã‚¹ã‚¯/è»Œè·¡")
            
            # ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£åˆ†æ
            activity_scores = [traj['activity_score'] for traj in trajectories]
            print(f"   ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã‚¹ã‚³ã‚¢: å¹³å‡ {np.mean(activity_scores):.3f}, æ¨™æº–åå·® {np.std(activity_scores):.3f}")
            
            # æ™‚é–“ã‚¹ãƒ‘ãƒ³åˆ†æ
            timespans = [traj['timespan'] for traj in trajectories if traj['timespan'] > 0]
            if timespans:
                print(f"   æ™‚é–“ã‚¹ãƒ‘ãƒ³: å¹³å‡ {np.mean(timespans):.1f} æ—¥, æœ€å¤§ {max(timespans)} æ—¥")
            
            return trajectories
            
        except FileNotFoundError:
            print(f"âš ï¸ è»Œè·¡ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {trajectory_path}")
            return None
        except Exception as e:
            print(f"âš ï¸ è»Œè·¡èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None


def main():
    parser = argparse.ArgumentParser(description='ãƒãƒ«ãƒãƒ¡ã‚½ãƒƒãƒ‰ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆè»Œè·¡ç”Ÿæˆ')
    parser.add_argument('--data', default='data/backlog.json',
                       help='ãƒãƒƒã‚¯ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹')
    parser.add_argument('--config', default='configs/multi_method_training.yaml',
                       help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    parser.add_argument('--analyze', action='store_true',
                       help='æ—¢å­˜è»Œè·¡ã®åˆ†æã®ã¿å®Ÿè¡Œ')
    parser.add_argument('--method', choices=['assignees', 'creators', 'all'],
                       help='ç‰¹å®šã®æ–¹æ³•ã®ã¿å‡¦ç†')
    
    args = parser.parse_args()
    
    # ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆè»Œè·¡ç”Ÿæˆå™¨
    generator = MultiMethodExpertTrajectoryGenerator(args.config)
    
    if args.analyze:
        # æ—¢å­˜è»Œè·¡ã®åˆ†æ
        if args.method:
            generator.load_and_analyze_trajectories(args.method)
        else:
            for method in ['assignees', 'creators', 'all']:
                generator.load_and_analyze_trajectories(method)
    else:
        # è»Œè·¡ç”Ÿæˆ
        if args.method:
            # ç‰¹å®šã®æ–¹æ³•ã®ã¿
            training_data, _ = generator.recommender.load_data(args.data)
            trajectories = generator.generate_expert_trajectories(training_data, args.method)
            output_path = f"data/expert_trajectories_{args.method}.pkl"
            generator.save_expert_trajectories(trajectories, output_path)
        else:
            # å…¨ã¦ã®æ–¹æ³•
            results = generator.generate_all_expert_trajectories(args.data)
    
    return 0


if __name__ == "__main__":
    exit(main())
