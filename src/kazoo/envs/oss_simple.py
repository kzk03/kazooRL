import os
from collections import defaultdict
from datetime import datetime, timedelta

import gymnasium as gym
import numpy as np
import torch
import yaml
from gymnasium import spaces

from kazoo.envs.task import Task


class OSSSimpleEnv(gym.Env):
    """
    OSSé–‹ç™ºãƒ—ãƒ­ã‚»ã‚¹ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ã€Gymnasiumäº’æ›ã®ç’°å¢ƒã€‚
    """

    def __init__(self, config, backlog, dev_profiles, reward_weights_path=None):
        super().__init__()

        self.config = config
        self.initial_backlog = backlog
        self.dev_profiles = dev_profiles

        self.num_developers = self.config.get("num_developers", len(self.dev_profiles))
        self.developers = self._create_developers()
        self.agent_ids = list(self.developers.keys())

        self.backlog = [Task.from_dict(t) for t in self.initial_backlog]

        valid_dates = [t.created_at for t in self.backlog if t.created_at is not None]
        self.start_time = min(valid_dates) if valid_dates else datetime.now()
        self.current_time = self.start_time

        ##GNNãƒ¢ãƒ‡ãƒ«ã¨ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã®import
        gnn_config = self.config.env.get("gnn", {})
        self.gnn_model = None
        if gnn_config.get("model_path") and os.path.exists(gnn_config["model_path"]):
            try:
                # GNNãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã¨èª­ã¿è¾¼ã¿
                from kazoo.GAT.GAT_model import GNNModel

                self.gnn_model = GNNModel(
                    in_channels_dict={"dev": 8, "task": 9}, out_channels=32
                )
                self.gnn_model.load_state_dict(
                    torch.load(gnn_config["model_path"], weights_only=True)
                )
                self.gnn_model.eval()
                print(
                    f"[OSSSimpleEnv] Successfully loaded GNN model from {gnn_config['model_path']}"
                )
            except Exception as e:
                print(f"[OSSSimpleEnv] Failed to load GNN model: {e}")
                self.gnn_model = None

        # PyTorch Geometricã®ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’æƒ³å®š
        self.graph_data = None
        if gnn_config.get("graph_data_path") and os.path.exists(
            gnn_config.graph_data_path
        ):
            try:
                self.graph_data = torch.load(
                    gnn_config.graph_data_path, weights_only=False
                )
                print(
                    f"[OSSSimpleEnv] Loaded graph data from {gnn_config.graph_data_path}"
                )
            except Exception as e:
                print(
                    f"Warning: Failed to load graph data from {gnn_config.graph_data_path}: {e}"
                )
                self.graph_data = None

        rl_config = self.config.get("rl", {})  # rlã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒãªã„å ´åˆã‚‚è€ƒæ…®
        self.time_step = timedelta(
            hours=self.config.env.simulation.get("time_step_hours", 8)
        )
        self.activity_window = timedelta(
            days=self.config.features.get("recent_activity_window_days", 30)
        )

        self.reset()

        # ç‰¹å¾´é‡æŠ½å‡ºå™¨ã®åˆæœŸåŒ–
        from kazoo.features.feature_extractor import FeatureExtractor

        self.feature_extractor = FeatureExtractor(self.config)

        self.action_space = spaces.Dict(
            {
                agent_id: spaces.Discrete(len(self.initial_backlog) + 1)
                for agent_id in self.agent_ids
            }
        )
        # è¦³æ¸¬ç©ºé–“ã‚’å®šç¾©ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ãªçŠ¶æ…‹ + GNNåŸ‹ã‚è¾¼ã¿ï¼‰
        simple_obs_shape = (len(self.initial_backlog) * 3,)
        gnn_pooled_dim = 64  # GNNåŸ‹ã‚è¾¼ã¿ã‚’ãƒ—ãƒ¼ãƒ«ã—ã¦å›ºå®šã‚µã‚¤ã‚ºã«

        # GNNåŸ‹ã‚è¾¼ã¿ã‚’æ˜ç¤ºçš„ã«åˆ†é›¢ã—ãŸè¦³æ¸¬ç©ºé–“
        self.observation_space = spaces.Dict(
            {
                agent_id: spaces.Dict(
                    {
                        "simple_obs": spaces.Box(
                            low=-np.inf,
                            high=np.inf,
                            shape=simple_obs_shape,
                            dtype=np.float32,
                        ),
                        "gnn_embeddings": spaces.Box(
                            low=-np.inf,
                            high=np.inf,
                            shape=(gnn_pooled_dim,),
                            dtype=np.float32,
                        ),
                    }
                )
                for agent_id in self.agent_ids
            }
        )

        self.reward_weights = None
        if reward_weights_path and os.path.exists(reward_weights_path):
            self.reward_weights = np.load(reward_weights_path)
            print(
                f"[OSSSimpleEnv] Loaded learned reward weights from {reward_weights_path}"
            )
        else:
            print("[OSSSimpleEnv] Using default hard-coded reward.")

    def _create_developers(self):
        developers = {}
        for i, (dev_id, profile) in enumerate(self.dev_profiles.items()):
            if i >= self.num_developers:
                break
            developers[dev_id] = {"name": dev_id, "profile": profile}
        return developers

    def _calculate_reward(self, agent_id, task, action_type="COMPLETE"):
        # IRLã®é‡ã¿ã‚’ä½¿ã†å ´åˆã¯ã€ã“ã“ã§ç‰¹å¾´é‡ã‚’è¨ˆç®—ã—ã¦å ±é…¬ã‚’è¿”ã™
        reward = 0.0

        if self.reward_weights is not None:
            try:
                # FeatureExtractorã‚’ä½¿ã£ã¦ç‰¹å¾´é‡ã‚’è¨ˆç®—
                from kazoo.features.feature_extractor import FeatureExtractor

                feature_extractor = FeatureExtractor(self.config)

                # é–‹ç™ºè€…æƒ…å ±ã‚’å–å¾—
                developer = self.developers[agent_id]

                # ç‰¹å¾´é‡ã‚’è¨ˆç®—
                features = feature_extractor.get_features(task, developer, self)

                # IRLã§å­¦ç¿’ã—ãŸé‡ã¿ã§å ±é…¬ã‚’è¨ˆç®—
                reward = float(np.dot(self.reward_weights, features))

                # GNNã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ç”¨ã«ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¨˜éŒ²
                if (
                    hasattr(feature_extractor, "gnn_extractor")
                    and feature_extractor.gnn_extractor
                ):
                    feature_extractor.gnn_extractor.record_interaction(
                        task, developer, reward, action_type
                    )

                print(f"[IRL Reward] {agent_id} -> {task.title}: {reward:.3f}")
                return reward

            except Exception as e:
                print(f"Warning: Failed to calculate IRL reward: {e}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå ±é…¬ã‚’ä½¿ç”¨
                pass

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå ±é…¬
        if action_type == "COMPLETE":
            reward = 1.0
        else:
            reward = 0.0

        # GNNã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ç”¨ã«ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¨˜éŒ²
        try:
            developer = self.developers[agent_id]

            if hasattr(self, "feature_extractor") and hasattr(
                self.feature_extractor, "gnn_extractor"
            ):
                if self.feature_extractor.gnn_extractor:
                    self.feature_extractor.gnn_extractor.record_interaction(
                        task,
                        developer,
                        reward,
                        action_type,
                        simulation_time=self.current_time,
                    )
        except Exception as e:
            # ãƒ‡ãƒãƒƒã‚°ç”¨ã«ã‚¨ãƒ©ãƒ¼ã‚’è¡¨ç¤º
            # print(f"Debug: GNN interaction recording failed: {e}")
            pass  # GNNãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—

        return reward

    def step(self, actions):
        self.current_time += self.time_step
        rewards = {agent_id: 0.0 for agent_id in self.agent_ids}

        for agent_id, action_val in actions.items():
            NO_OP_ACTION = len(self.initial_backlog)
            if action_val == NO_OP_ACTION or action_val >= len(self.backlog):
                continue

            developer = self.developers[agent_id]
            selected_task = self.backlog.pop(action_val)

            self.assignments[agent_id].add(selected_task.id)
            selected_task.assigned_to = agent_id
            self.dev_action_history[agent_id].append(self.current_time)
            self.tasks_in_progress[selected_task.id] = selected_task
            selected_task.status = "in_progress"
            print(
                f"Time {self.current_time.date()}: {agent_id} started {selected_task.title}"
            )

        completed_this_step = []
        for task in list(self.tasks_in_progress.values()):
            if np.random.rand() < 0.1:
                task.status = "done"
                completed_this_step.append(task)

                completing_agent = getattr(task, "assigned_to", None)
                if completing_agent and completing_agent in self.assignments:
                    if task.id in self.assignments[completing_agent]:
                        self.assignments[completing_agent].remove(task.id)
                    rewards[completing_agent] += self._calculate_reward(
                        completing_agent, task, "COMPLETE"
                    )

                    # GNNã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³è¨˜éŒ²ã®ç¢ºèª
                    if hasattr(self, "feature_extractor") and hasattr(
                        self.feature_extractor, "gnn_extractor"
                    ):
                        if self.feature_extractor.gnn_extractor:
                            buffer_size = len(
                                self.feature_extractor.gnn_extractor.interaction_buffer
                            )
                            print(f"    ğŸ“Š GNN interaction buffer size: {buffer_size}")

                print(
                    f"Time {self.current_time.date()}: {task.title} completed by {completing_agent}!"
                )

        for task in completed_this_step:
            if task.id in self.tasks_in_progress:
                del self.tasks_in_progress[task.id]
            self.completed_tasks.append(task)

        for dev_name in self.dev_action_history:
            self.dev_action_history[dev_name] = [
                ts
                for ts in self.dev_action_history[dev_name]
                if self.current_time - ts < self.activity_window
            ]

        observations = self._get_observations()
        is_done = not self.backlog and not self.tasks_in_progress
        terminateds = {agent_id: is_done for agent_id in self.agent_ids}

        rl_config = self.config.get("rl", {})
        max_steps = rl_config.get("max_steps", 365 * 3)  # ä»®
        is_truncated = (
            self.current_time - self.start_time
        ).total_seconds() / self.time_step.total_seconds() >= max_steps
        truncateds = {agent_id: is_truncated for agent_id in self.agent_ids}
        infos = self._get_infos()

        return observations, rewards, terminateds, truncateds, infos

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)

        self.current_time = self.start_time
        self.dev_action_history = defaultdict(list)
        self.assignments = defaultdict(set)

        self.backlog = [Task.from_dict(t) for t in self.initial_backlog]
        self.tasks_in_progress = {}
        self.completed_tasks = []

        observations = self._get_observations()
        infos = self._get_infos()

        return observations, infos

    def _get_observations(self):
        task_states = []
        initial_task_ids_ordered = [t["id"] for t in self.initial_backlog]

        for task_id in initial_task_ids_ordered:
            status_val = 0
            if task_id in self.tasks_in_progress:
                status_val = 1
            elif any(ct.id == task_id for ct in self.completed_tasks):
                status_val = 2

            # complexity, deadline ã¯å›ºå®šå€¤ã¨ä»®å®šã€‚å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—ã™ã‚‹ã®ãŒæœ›ã¾ã—ã„ã€‚
            task_states.extend([status_val, 0, 0])
        obs_vector = np.array(task_states, dtype=np.float32)

        # --- GNNã«ã‚ˆã‚‹ç‰¹å¾´é‡ã‚’è¨ˆç®— ---
        # graph_dataãŒNoneã®å ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        if self.graph_data is None:
            print("Warning: graph_data is None. Using empty embeddings.")
            gnn_embeddings = np.zeros((0, 64))  # ç©ºã®åŸ‹ã‚è¾¼ã¿
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‹ã‚‰é–‹å§‹
            gnn_embeddings = np.zeros((self.graph_data.num_nodes, 64))

            if self.gnn_model and self.graph_data:
                try:
                    # ç¾åœ¨ã®ã‚¿ã‚¹ã‚¯ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãªã©ã‚’ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã«åæ˜ 
                    updated_graph_data = self._update_graph_features(self.graph_data)

                    with torch.no_grad():
                        # GNNã®ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã‚’å®Ÿè¡Œã—ã¦æœ€æ–°ã®ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã‚’å–å¾—
                        embeddings_dict = self.gnn_model(
                            updated_graph_data.x_dict,
                            updated_graph_data.edge_index_dict,
                        )

                        # é–‹ç™ºè€…ã¨ã‚¿ã‚¹ã‚¯ã®åŸ‹ã‚è¾¼ã¿ã‚’çµåˆ
                        dev_embeddings = embeddings_dict["dev"].cpu().numpy()
                        task_embeddings = embeddings_dict["task"].cpu().numpy()

                        # çµåˆã—ã¦64æ¬¡å…ƒã«èª¿æ•´
                        combined_embeddings = np.concatenate(
                            [dev_embeddings, task_embeddings], axis=0
                        )

                        # å¿…è¦ã«å¿œã˜ã¦ã‚µã‚¤ã‚ºèª¿æ•´
                        if combined_embeddings.shape[0] >= self.graph_data.num_nodes:
                            gnn_embeddings = combined_embeddings[
                                : self.graph_data.num_nodes, :32
                            ]
                            # 32æ¬¡å…ƒã‚’64æ¬¡å…ƒã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
                            gnn_embeddings = np.pad(
                                gnn_embeddings, ((0, 0), (0, 32)), mode="constant"
                            )

                        print(
                            f"[OSSSimpleEnv] Successfully computed GNN embeddings: {gnn_embeddings.shape}"
                        )

                except Exception as e:
                    print(f"Warning: Failed to compute GNN embeddings: {e}")
                    gnn_embeddings = np.zeros((self.graph_data.num_nodes, 64))

        # --- è¾æ›¸å½¢å¼ã§è¦³æ¸¬ã‚’ã¾ã¨ã‚ã‚‹ ---
        observations = {}

        # GNNåŸ‹ã‚è¾¼ã¿ã‚’ãƒ—ãƒ¼ãƒ«ï¼ˆGlobal Average Poolingï¼‰
        if gnn_embeddings.shape[0] > 0:
            pooled_gnn = np.mean(gnn_embeddings, axis=0)  # (64,)
        else:
            pooled_gnn = np.zeros(64)  # ç©ºã®å ´åˆã¯ã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«

        # å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å¯¾ã—ã¦åˆ†é›¢ã•ã‚ŒãŸè¦³æ¸¬ã‚’ä½œæˆ
        for agent_id in self.agent_ids:
            observations[agent_id] = {
                "simple_obs": obs_vector.astype(np.float32),
                "gnn_embeddings": pooled_gnn.astype(np.float32),
            }

        return observations

    def _get_infos(self):
        full_state_info = {
            "current_time": self.current_time,
            "assignments": self.assignments,
            "dev_action_history": self.dev_action_history,
            "backlog": self.backlog,
            "developers": self.developers,
            "tasks_in_progress": self.tasks_in_progress,
        }
        return {agent_id: full_state_info for agent_id in self.agent_ids}

    def _update_graph_features(self, graph_data):
        """
        ç¾åœ¨ã®ç’°å¢ƒçŠ¶æ…‹ã«åŸºã¥ã„ã¦ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´é‡ã‚’æ›´æ–°
        """
        try:
            # ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼
            updated_data = graph_data.clone()

            # ã‚¿ã‚¹ã‚¯ã®çŠ¶æ…‹ã‚’æ›´æ–°
            if hasattr(updated_data, "x_dict") and "task" in updated_data.x_dict:
                task_features = updated_data.x_dict["task"].clone()

                # å„ã‚¿ã‚¹ã‚¯ã®çŠ¶æ…‹ã‚’æ›´æ–°
                for i, task_dict in enumerate(self.initial_backlog):
                    task_id = task_dict["id"]

                    # ã‚¿ã‚¹ã‚¯ã®ç¾åœ¨ã®çŠ¶æ…‹ã‚’å–å¾—
                    if task_id in self.tasks_in_progress:
                        status = 1.0  # é€²è¡Œä¸­
                    elif any(ct.id == task_id for ct in self.completed_tasks):
                        status = 2.0  # å®Œäº†
                    else:
                        status = 0.0  # æœªç€æ‰‹

                    # ç‰¹å¾´é‡ã®æœ€åˆã®æ¬¡å…ƒã«ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¨­å®š
                    if i < task_features.shape[0]:
                        task_features[i, 0] = status

                updated_data.x_dict["task"] = task_features

            # é–‹ç™ºè€…ã®çŠ¶æ…‹ã‚’æ›´æ–°
            if hasattr(updated_data, "x_dict") and "dev" in updated_data.x_dict:
                dev_features = updated_data.x_dict["dev"].clone()

                # é–‹ç™ºè€…ã®æ´»å‹•çŠ¶æ³ã‚’æ›´æ–°
                for i, (dev_id, dev_info) in enumerate(self.developers.items()):
                    if i < dev_features.shape[0]:
                        # ç¾åœ¨ã®ä½œæ¥­è² è·
                        workload = len(self.assignments.get(dev_id, set()))
                        dev_features[i, 0] = float(workload)

                        # æœ€è¿‘ã®æ´»å‹•æ•°
                        recent_activity = len(self.dev_action_history.get(dev_id, []))
                        dev_features[i, 1] = float(recent_activity)

                updated_data.x_dict["dev"] = dev_features

            return updated_data

        except Exception as e:
            print(f"Warning: Failed to update graph features: {e}")
            return graph_data
